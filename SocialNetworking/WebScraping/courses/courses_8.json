[
  {
    "url": "https://www.coursera.org/learn/cybersecurity-assessment-comptia-security-cysa",
    "name": "Cybersecurity Assessment: CompTIA Security+ & CYSA+",
    "what_you_learn": "Get CompTIA Security+ and CompTIA CySA+ exam-ready with study tips and rigorous exam-day preparation techniques\nGet CompTIA Security+ and CompTIA CySA+ exam-ready with study tips and rigorous exam-day preparation techniques\nValidate your exam readiness with practice tests and timed mock exams\nValidate your exam readiness with practice tests and timed mock exams\nEnsure you’re familiar with the domains covered in each exam and how they are marked\nEnsure you’re familiar with the domains covered in each exam and how they are marked\nUnderstand the certification process for each exam, including sign-up and testing procedures\nUnderstand the certification process for each exam, including sign-up and testing procedures",
    "skills": "Vulnerability Management, Network Architecture, Incident Response, Security Testing, Cyber Security Assessment, Cyber Risk, Cybersecurity",
    "instructors": [
      "manish-kumar",
      "ibm-skills-network",
      "~117578874"
    ],
    "content": "Forbes specifically recommends the CompTIA Security+ certification for career starters seeking to validate their cybersecurity skills.  Many job roles require CompTIA Security + and CySA+ certifications, and certified applicants catch the eye of employers (CompTIA)!During this two-week intensive short course, you’ll prepare for both the foundational CompTIA Security+ and advanced CySA+ exams. First, explore the vital CompTIA Security+ exam details, including exam eligibility, the five exam domains, tips for effective study, and additional exam preparation resources. Then, explore the CompTIA CYSA+ exam structure with four exam domains, exam eligibility, study strategies, and recommendations for extra study resources.  \n \nFor both certification exams, assess your readiness using ungraded practice tests. Prepare for the “day of” texting experience with the rigorous, full-length, realistically-timed mock exams and optimize your exam-day performance. When you’re ready for the next steps, use the links provided to purchase your exam voucher and schedule your exam. \n   \nKickstart your cybersecurity career with the certifications employers look for, and ENROLL TODAY!"
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-awareness-essentials-for-employees",
    "name": "Cybersecurity Awareness Essentials for Employees",
    "what_you_learn": "",
    "skills": "Cyber Security Policies, Remote Access Systems, Artificial Intelligence, Data Security, Multi-Factor Authentication, Identity and Access Management, Mobile Security",
    "instructors": [
      "keith-gibson"
    ],
    "content": "Defend yourself against cyber-threats like phishing, ransomware, and social engineering with the essential knowledge taught in this course. This course is for everyone, regardless of experience level in Cybersecurity! You can even use it as your Annual Cybersecurity Awareness Training.Cyber-attacks are becoming more frequent, more complex, and harder to detect. There are a variety of greats tools and programs designed to help prevent these attacks, but your best defense will always be awareness. Attackers always target the least suspecting victims, hoping that their ignorance will give the attacker an edge. \n\nTake the advantage back by understanding these three simple ideas: \n- WHO these attackers are \n- WHY they are attacking \n- HOW they design these attacks \n\nWhat You’ll Learn:\n- Spot phishing emails and social engineering tactics\n- Manage passwords and multi-factor authentication securely\n- Understand insider threats and how to prevent them\n- Protect devices, cloud accounts, and remote work setups\n- Recognize malware and ransomware delivery methods\n- Apply safe practices on social media and mobile devices\n- Explore how AI is shaping cybersecurity risks and defences\n\nWhat Makes This Course Unique\n✅ Microlearning format—complete in under 2 hours\n✅ Designed for non-technical employees\n✅ Covers both personal and workplace digital safety\n✅ Includes real-world examples and interactive assessments\n✅ Final assessment to validate your cybersecurity readiness\n✅ Certificate of completion for your resume or LinkedIn profile\n\nMost importantly, our microlearning videos are designed with the busy information worker in mind, making this course easy to fit into your daily schedule."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-best-practices",
    "name": "Cybersecurity Best Practices",
    "what_you_learn": "",
    "skills": "Cyber Security Strategy, Data Integrity, Data Security, Cybersecurity, Network Security, Security Awareness, Cyber Security Policies, Cyber Risk, Incident Response, Security Controls, Threat Management, Threat Detection, Enterprise Security, Information Assurance, Computer Security Awareness Training, View all skills",
    "instructors": [
      "andryrakotomalala"
    ],
    "content": "\"Cybersecurity Best Practices\" is a transformative course designed for any learners whether they are just getting started with cybersecurity or are seasoned professionals looking for a refresher. This course uses real world examples and explains cybersecurity concepts in relatable ways to make it accessible for anyone while still challenging seasoned professionals to think of these concepts with a different lens. We dive into the fundamental structure of cybersecurity and demystify its complexity using core everyday concepts. Not only will this help with organizational compliance training, but individuals will better know how they can protect themselves in their personal lives as well. For the employees looking to see ways on how they can protect their organization, this course also covers industry standard checklists that they can use to make sure they are properly hardened. By using real world examples, proven industry practices, and emerging cybersecurity concepts, learners will emerge with a better understanding of cybersecurity as a whole and how they can leverage these to protect themselves and their organization."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-case-studies-capstone-project",
    "name": "Cybersecurity Case Studies and Capstone Project",
    "what_you_learn": "Hands-on experience in analyzing cybersecurity case studies to identify threat tactics and assess vulnerabilities you can talk about in interviews\nHands-on experience in analyzing cybersecurity case studies to identify threat tactics and assess vulnerabilities you can talk about in interviews\nDemonstrable, practical skills for applying response frameworks and forensic techniques to real-world breach scenarios\nDemonstrable, practical skills for applying response frameworks and forensic techniques to real-world breach scenarios\nExpertise in penetration testing and compliance analysis to evaluate organizational security regarding compliance successes and failures\nExpertise in penetration testing and compliance analysis to evaluate organizational security regarding compliance successes and failures\nHands-on experience with researching real-world data breach scenarios and analyzing them to propose recommendations\nHands-on experience with researching real-world data breach scenarios and analyzing them to propose recommendations",
    "skills": "Malware Protection, Cybersecurity, Artificial Intelligence, Computer Security Incident Management, Exploitation techniques, Threat Modeling, Distributed Denial-Of-Service (DDoS) Attacks, Network Security, Security Awareness, Email Security, Fraud detection, Cyber Threat Intelligence, Incident Response, Vulnerability Assessments, Threat Detection, Data Security, Penetration Testing, View all skills",
    "instructors": [
      "ibm-skills-network",
      "~117578874"
    ],
    "content": "Gain the real-world experience of cybersecurity analysis employers look for with this hands-on capstone course.In this course, you’ll analyze real-life breach response case studies in areas such as phishing, vishing, point of sale (PoS) breaches, insider threats, AI-related breaches, and ransomware attacks. \n\nYou’ll discover how attackers exploit vulnerabilities and how organizations respond and prevent future incidents.\n\nAdditionally, you’ll gain expertise in incident response, digital forensics, penetration testing, and compliance through engaging case study analysis. You’ll complete several hands-on activities to assess response strategies and propose improvements. \n\nThe course concludes with a final project, where you’ll select a real-world data breach, identify vulnerabilities, and assess the root cause, actions taken, and response strategies. Plus, a structured template will guide you to critically record observations and propose actionable improvements for breach management. This capstone course is a fantastic experience to talk about in interviews!\n\nIf you’re keen to add practical cybersecurity experience to your resume, enroll today to complete this valuable capstone project in just six weeks!"
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-compliance-framework-standards-regulations",
    "name": "Cybersecurity Compliance Framework, Standards & Regulations",
    "what_you_learn": "Define fundamental concepts of cybersecurity, including governance, risk management, compliance, AI ethics, and the audit process.\nDefine fundamental concepts of cybersecurity, including governance, risk management, compliance, AI ethics, and the audit process.\nIdentify cybersecurity laws and regulations, both at a national and international level and comprehend their implications for organizations.\nIdentify cybersecurity laws and regulations, both at a national and international level and comprehend their implications for organizations.\nExplore industry standards and their significance in cybersecurity practices and gain insights into the COBIT framework and SOC reports.\nExplore industry standards and their significance in cybersecurity practices and gain insights into the COBIT framework and SOC reports.\nApply cybersecurity industry standards and best practices to mitigate risks, enhance security, and ensure compliance through audit processes.\nApply cybersecurity industry standards and best practices to mitigate risks, enhance security, and ensure compliance through audit processes.",
    "skills": "Risk Management, IT Service Management, Auditing, Payment Card Industry (PCI) Data Security Standards, Control Objectives for Information and Related Technology (COBIT), General Data Protection Regulation (GDPR), Compliance Management, Data Ethics, ISO/IEC 27001, Artificial Intelligence, Regulatory Compliance, Cybersecurity, NIST 800-53, Security Controls, Information Technology Infrastructure Library, Information Technology, Open Web Application Security Project (OWASP), Governance Risk Management and Compliance, View all skills",
    "instructors": [
      "ibm-skills-network",
      "~117578874"
    ],
    "content": "Cyber threats present a constant challenge today, costing billions and affecting everyone, from governments to small businesses. Are you ready to contribute to the solution?This course will provide you with a deep understanding of cybersecurity principles, industry standards, regulations, and audit processes. You will explore the fundamental concepts of information security and compliance, covering topics such as governance, risk, compliance, cybersecurity frameworks, and process management.\n\nYou will also learn about IT service management and explore the NIST risk management framework and AI ethical considerations. You will gain insights into cybersecurity laws and regulations, focusing on both US and global perspectives, including HIPPA, GDPR, and PCI DSS. Additionally, you will familiarize yourself with the audit processes using the COBIT framework and SOC reports. You will also explore prominent standards such as OWASP, ISO, and IEEE, learning how to apply them effectively.\n\nThroughout this five-module self-paced course, you will engage in interactive activities to apply your knowledge in real-world scenarios. You will also complete a final project to test your skills and showcase your understanding.\n\nJoin us on this cybersecurity journey!"
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-for-everyone",
    "name": "Cybersecurity for Everyone",
    "what_you_learn": "",
    "skills": "Infrastructure Security, Threat Modeling, Cyber Security Strategy, Cybersecurity, Security Management, Governance, Cyber Security Policies, Computer Security, Data Security, Vulnerability, Public Safety and National Security, Threat Detection, Cyber Risk, Cyber Attacks, Telecommunications, Security Awareness, Enterprise Security, Cyber Governance, General Networking, Risk Management, View all skills",
    "instructors": [
      "~78436469"
    ],
    "content": "Cybersecurity affects everyone, including in the delivery of basic products and services. If you or your organization want to better understand how to address your cybersecurity, this is the course for you and your colleagues to take -- from seasoned professionals to your non-technical colleagues.Your instructor, Dr. Charles Harry, has served on the front lines with the NSA (National Security Agency) and as an expert advising corporate and institutional leaders on managing cybersecurity risk. And he brings a rare and engaging perspective to help you learn cybersecurity from the ground up.\n\nCybersecurity for Everyone lays the groundwork to understand and explore the key issues facing policy makers attempting to manage the problem of cybersecurity, from its technical foundations to the domestic and international policy considerations surrounding governance, privacy, and risk management, to applications for achieving the goals of an enterprise, an institution, or a nation. This course is designed for students with some or no background in information technology, whether a novice or active in the cybersecurity field (engineers and computer scientists will learn the broader context and business aspects of cybersecurity), and will provide the principles to understand the current debates shaping a rapidly evolving security landscape."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-for-tech-professionals",
    "name": "Cybersecurity for Tech Professionals",
    "what_you_learn": "Conocerás los riesgos de la era digital y cómo las personas u organizaciones podemos evitar incidentes de seguridad (o minimizar sus consecuencias).\nConocerás los riesgos de la era digital y cómo las personas u organizaciones podemos evitar incidentes de seguridad (o minimizar sus consecuencias).",
    "skills": "Security Awareness, Cyber Attacks, Network Security, Threat Detection, Identity and Access Management, Authentications, Email Security, Payment Systems, Cybersecurity, Fraud detection, Computer Security Incident Management, Incident Management, Mobile Security, Security Information and Event Management (SIEM), View all skills",
    "instructors": [
      "~103719571"
    ],
    "content": "Como integrantes del mundo empresarial, los profesionales de la tecnología suelen ser el principal objetivo de un ciberataque, ya que tienen acceso a información confidencial, a cuentas o a los sistemas de una empresa. Aunque sean conocedores de los riesgos a los que están sometidos las organizaciones en las que trabajan, es importante tener un amplio y consolidado conocimiento en materia de ciberseguridad para poder prevenir los ataques.Por ello, en este curso trataremos las temáticas más relevantes en el ámbito de la ciberseguridad que debes conocer. Desde los riesgos a los que estamos expuestos, pasando por la importancia de la securización de las operaciones y hasta cómo las organizaciones deben gestionar las crisis de seguridad, sin olvidarnos de la gestión de los incidentes y del fraude.\n\nAnímate a adentrarte en el mundo de la ciberseguridad de la mano de este curso diseñado especialmente para profesionales en la tecnología. ¡Adelante!"
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-fundamentals",
    "name": "Introduction to Penetration Testing and Ethical Hacking",
    "what_you_learn": "Conduct penetration tests using industry-standard methodologies like PTES.\nConduct penetration tests using industry-standard methodologies like PTES.\nCraft professional penetration testing reports and executive summaries.\nCraft professional penetration testing reports and executive summaries.\nUnderstand and apply cryptographic principles, including PKI and secret key encryption.\nUnderstand and apply cryptographic principles, including PKI and secret key encryption.\nMaster social engineering and analyze cyberattacks with the MITRE ATT&CK Framework.\nMaster social engineering and analyze cyberattacks with the MITRE ATT&CK Framework.",
    "skills": "Cryptography, Vulnerability Scanning, Human Factors (Security), Test Tools, Cyber Security Assessment, Encryption, Public Key Infrastructure, Cybersecurity, Security Testing, Penetration Testing, Technical Writing, MITRE ATT&CK Framework, Threat Modeling, Exploitation techniques, View all skills",
    "instructors": [
      "~165144142"
    ],
    "content": "This Advanced Penetration Testing and Ethical Hacking course offers a deep dive into key cybersecurity concepts, providing you with hands-on experience in areas like penetration testing, cryptography, and social engineering. Through engaging modules, you will learn to conduct penetration tests using industry-standard methodologies, such as the Penetration Testing Execution Standard (PTES), and effectively communicate findings through professional reports and executive summaries. You’ll also gain a solid understanding of cryptographic principles, including public key infrastructure (PKI), while mastering techniques for ethical hacking and countering cryptographic attacks. Additionally, the course covers the art of information gathering and social engineering, equipping you to conduct reconnaissance and craft spear phishing attacks. With practical labs and real-world scenarios, this course will help you build the skills needed to protect mission-critical infrastructures and advance your career in cybersecurity."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-identity-access-solutions-azure-ad",
    "name": "Cybersecurity Identity and Access Solutions with Azure AD",
    "what_you_learn": "Explain the concept of Active Directory\nExplain the concept of Active Directory\nDescribe Authentication methods\nDescribe Authentication methods\nDiscuss access management\nDiscuss access management",
    "skills": "Authorization (Computing), Microsoft Azure, Active Directory, Identity and Access Management, Enterprise Security, Authentications, Cloud Services, Multi-Factor Authentication, Role-Based Access Control (RBAC), Azure Active Directory, User Accounts, Security Controls, Single Sign-On (SSO), View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you’ll explore the world of authorization and authentication, and understand the concepts of two-step authentication and single sign-on policies. You’ll also become familiar with the features and capabilities of Azure Active Directory (Azure AD), particularly those relating to the benefits of using Azure AD to manage an enterprise’s security requirements including access management, identity governance, and management. This course will take you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-identity-and-access-solutions-with-azure-ad",
    "name": "Cybersecurity Identity and Access Solutions using Azure AD",
    "what_you_learn": "",
    "skills": "Role-Based Access Control (RBAC), Identity and Access Management, Active Directory, Azure Active Directory, Multi-Factor Authentication, Microsoft Azure, Single Sign-On (SSO), Software As A Service, Cloud Services, Enterprise Security, User Accounts, Authorization (Computing), Authentications, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "Upon completing the first three courses of the Professional Certificate, you should have some foundational knowledge about computers, operating systems, networking, and cyberthreats, all of which put you in a good position to explore cybersecurity in greater detail.In this course, you’ll explore the world of authorization and authentication, and understand the concepts of two-step authentication and single sign-on policies. You’ll also become familiar with the features and capabilities of Azure Active Directory (Azure AD), particularly those relating to the benefits of using Azure AD to manage an enterprise’s security requirements including access management, identity governance, and management. This course will take you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience.\n\nAfter completing this course, you’ll be able to:  \n\n•\tExplain the concept of Active Directory  \n•\tDescribe Authentication methods \n•\tDiscuss access management\n \nThis is also a great way to prepare for the Microsoft SC-900 exam. By passing the SC-900 exam, you’ll earn the Microsoft Security, Compliance, and Identity Fundamentals Certification."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-in-healthcare",
    "name": "Cybersecurity in Healthcare (Hospitals & Care Centres)",
    "what_you_learn": "You will gain an understanding of the role of digitalisation and cybersecurity in the healthcare context\nYou will gain an understanding of the role of digitalisation and cybersecurity in the healthcare context\nYou will learn about the opportunities and threats that the healthcare sector faces due to digitalisation and the proliferation of (medical) data\nYou will learn about the opportunities and threats that the healthcare sector faces due to digitalisation and the proliferation of (medical) data\nYou will learn about different ways to improve and maintain cybersecurity, highlighting the interaction between technology and human behaviour\nYou will learn about different ways to improve and maintain cybersecurity, highlighting the interaction between technology and human behaviour\nYou will discover how a positive cybersecurity culture is an important influence on an organisation's level of cybersecurity\nYou will discover how a positive cybersecurity culture is an important influence on an organisation's level of cybersecurity",
    "skills": "Data Security, Patient Safety, Information Privacy, Malware Protection, Security Awareness, Cyber Attacks, Cyber Security Policies, Email Security, Cyber Risk, Encryption, Digital Communications, Health Technology, Computer Security Awareness Training, Cybersecurity, Human Factors (Security), View all skills",
    "instructors": [
      "tessaoomen",
      "jasonpridmore"
    ],
    "content": "The Cybersecurity in Healthcare MOOC was developed as part the SecureHospitals.eu project. This project has received funding from the European Union’s Horizon 2020 Coordination Research and Innovation Action under Grant Agreement No. 826497.The course \"Cybersecurity in Healthcare\" has been developed to raise awareness and understanding the role of cybersecurity in healthcare (e.g., hospitals, care centres, clinics, other medical or social care institutions and service organisations) and the challenges that surround it. In this course, we will cover both theoretical and practical aspects of cybersecurity. We look at both social aspects as technical aspects that come into play. Furthermore, we offer helpful resources that cover different aspects of cybersecurity. Even if you are not active in the healthcare domain, you will find helpful tips and insights to deal with cybersecurity challenges within any other organisation or in personal contexts as well.\n\nThis course begins by introducing the opportunities and challenges that digitalisation of healthcare services has created. It explains how the rise of technologies and proliferation of (medical) data has become an attractive target to cybercriminals, which is essential in understanding  why  adequate cybersecurity measures are critical within the healthcare environment. In later modules, course contents cover the threats, both inside and outside of healthcare organisations like e.g. social engineering and hacking. Module 4 on Cyber Hygiene describes how to improve cybersecurity within healthcare organisations in practical ways.  Module 5 looks deeper into how organisational culture affects cybersecurity, the cybersecurity culture, focusing on the interaction between human behaviour and technology and how organisational factors can boost or diminish the level and attention to cybersecurity in healthcare.\n\nDo you work for a hospital, clinic, medical practice, care centre, care provider, social care organisation, or nursing home? Do you want to improve your personal or your organisation’s cybersecurity (cyber security, IT security, information security, network security, computer security, awareness)? Then please visit https://www.securehospitals.eu to gain access to a range of resources. You can also join the Security providers and Trainers platform (see: https://www.securehospitals.eu/for-providers-and-trainers/) or our Community of Practice (see: https://www.securehospitals.eu/community/)."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-job-search-resume-and-interview-prep",
    "name": "Cybersecurity Job Search, Resume, and Interview Prep",
    "what_you_learn": "Explain cybersecurity roles, titles, responsibilities, and required skills and competencies, and explore the NICE framework\nExplain cybersecurity roles, titles, responsibilities, and required skills and competencies, and explore the NICE framework\nCreate a resume, portfolio, elevator pitch, and cover letter and apply best practices to prepare for a cybersecurity job interview\nCreate a resume, portfolio, elevator pitch, and cover letter and apply best practices to prepare for a cybersecurity job interview\nRespond effectively to various cybersecurity interview questions, including industry, skills, experience, and behavioral\nRespond effectively to various cybersecurity interview questions, including industry, skills, experience, and behavioral\nDiscuss post-interview actions required to position yourself for success  and apply tips to help during salary negotiation\nDiscuss post-interview actions required to position yourself for success  and apply tips to help during salary negotiation",
    "skills": "Cybersecurity, Applicant Tracking Systems, Professional Networking, Portfolio Management, Recruitment Strategies, Interviewing Skills, LinkedIn, Recruitment, Writing, Compensation Strategy, Job Analysis, Presentations, Communication, Social Media, Negotiation, Market Research, Business Research, View all skills",
    "instructors": [
      "manish-kumar",
      "ibm-skills-network"
    ],
    "content": "With the digital and AI disruption, cybersecurity professionals are in even higher demand around the world, and the trend shows no sign of slowing. There are also several great candidates. How can you get the edge in such a competitive field?This course will prepare you to enter the job market as a great candidate for an entry-level cybersecurity position. You will be equipped with practical techniques to create job-related documents, such as a resume, a portfolio, a cover letter, and an elevator pitch. You will learn how to find and assess prospective job positions, apply to them, and lay the groundwork for interviewing. You will learn about the different types of questions typically asked during cybersecurity interviews and witness mock interviews.\n\nThroughout this four-module self-paced course, you will hear from various cybersecurity experts who discuss their own career paths and talk about what they have learned about networking, interviewing, solving coding problems, and fielding other questions you may encounter as a candidate. You will also have the opportunity to practice what you learn and test your understanding.\n\nCome join us on this job search journey!"
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-management-and-compliance",
    "name": "Cybersecurity Management and Compliance",
    "what_you_learn": "Learn about data and record management, Information security, standards and policy formation, and implementation.\nLearn about data and record management, Information security, standards and policy formation, and implementation.\nExplore cloud adoption frameworks and regulatory compliance frameworks.\nExplore cloud adoption frameworks and regulatory compliance frameworks.\nLearn how to use available tools for compliance management.\nLearn how to use available tools for compliance management.",
    "skills": "Data Management, Microsoft Azure, Security Management, Threat Management, Disaster Recovery, Data Governance, Records Management, General Data Protection Regulation (GDPR), Cyber Security Policies, Security Controls, Information Privacy, Cloud Security, Cloud Computing, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you’ll learn about data and record management, Information security, standards and policy formation, and implementation. You’ll also explore cloud adoption frameworks and regulatory compliance frameworks. This course will take you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience.After completing this course, you'll be able to:  \n\n•  Explain the principles of cloud security planning \n•  Identify security requirements for cloud architecture\n•  Explain Microsoft's privacy principles\n•  Use available tools for compliance management\n\nThis is also a great way to prepare for the Microsoft SC-900 exam. By passing the SC-900 exam, you’ll earn the Microsoft Security, Compliance, and Identity Fundamentals Certification."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-policy-aviation-internet",
    "name": "Cybersecurity Policy for Aviation and Internet Infrastructures",
    "what_you_learn": "",
    "skills": "Infrastructure Security, Cyber Security Policies, Cyber Security Strategy, Mobile Security, Infrastructure Architecture, Transportation Operations, Cyber Risk, Network Infrastructure, Cybersecurity, Technology Roadmaps, Cyber Security Assessment, Risk Management Framework, View all skills",
    "instructors": [
      "~21251837"
    ],
    "content": "In this course we will examine the aviation and Internet infrastructures, and various policies that have been developed to help guide and strengthen their cybersecurity programs.  The aviation and Internet infrastructures are also considered \"lifeline infrastructure\" as part of the transportation and communications sectors. Both subsectors are overseen by the Department of Homeland Security National Protection and Programs Directorate which manages the DHS National Infrastructure Protection Program. SSA responsibility for the aviation subsector is shared between the Transportation Security Administration and Federal Aviation Administration under the auspices of the Department of Homeland Security and Department of Transportation respectively.  The Department of Homeland Security retains sole responsibility as the Sector-Specific Agency for the Internet subsector.  While TSA and FAA have regulatory over the aviation subsector, DHS has no regulatory authority whatsoever over the Internet. In response to Executive Order 13636 issued by President Obama in February 2013, both sets of SSAs recommended continuing with voluntary cybersecurity measures. TSA and FAA reported they were working to implement the Transportation Roadmap across all transportation subsectors, including aviation. DHS reported that it was working with Internet providers to implement the Cyber Assessment Risk Management Approach. Despite some differences, the Transportation Roadmap and CARMA are very similar to the NIST Cybersecrity Framework and ES-C2M2 examined previously.  That is to say, they are predicated on a continuous improvement process that engages the whole organization in identifying and implementing incremental changes to enhance cybersecurity practices based on prevailing standards. This module will examine both the aviation and Internet lifeline infrastructure subsectors, and elements and application of the Transportation Roadmap and CARMA."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-policy-water-electricity",
    "name": "Cybersecurity Policy for Water and Electricity Infrastructures",
    "what_you_learn": "",
    "skills": "Infrastructure Security, Cybersecurity, Risk Management Framework, Security Strategy, Cyber Risk, Security Management, NIST 800-53, Cyber Security Strategy, Cyber Security Policies, System Monitoring, View all skills",
    "instructors": [
      "~21251837"
    ],
    "content": "This course will examine the drinking water and electricity infrastructures, and various policies that have been developed to help guide and strengthen their cybersecurity programs.  The drinking water and electricity infrastructures are two of fourteen subsectors comprising what are known as \"lifeline infrastructure\". The 2013 National Infrastructure Protection Plan identifies four lifeline infrastructure sectors: 1) water, 2) energy, 3) transportation, and 4) communications. These sectors are designated \"lifeline\" because many other infrastructures depend upon them.  The drinking water subsector is part of the water sector, and the electricity subsector is part of the energy sector.  Both subsectors are overseen by the Department of Homeland Security National Protection and Programs Directorate which manages the DHS National Infrastructure Protection Program. The NIPP employs a five-step continuous improvement program called the Risk Management Framework. NIPP implementation is overseen by DHS-designated Sector-Specific Agencies staffed by various Federal departments. The Sector-Specific Agencies work in voluntary cooperation with industry representatives to apply the Risk Management Framework and document results in corresponding Sector-Specific Plans.  The program began in 2007 and the most recent Sector-Specific Plans were published in 2016. In February 2013, President Obama issued Executive 13636 directing the National Institute of Standards and Technology to develop a voluntary set of recommendations for strengthening infrastructure cybersecurity measures. EO13636 also asked Federal agencies with regulating authority to make a recommendation whether the NIST Cybersecurity Framework should be made mandatory. The Environmental Protection Agency who is both the SSA and regulatory authority for the drinking water subsector recommended voluntary application of the NIST Cybersecurity Framework. The Department of Energy who is both the SSA and regulatory authority for the electricity subsector replied that it was already implementing the Electricity Subsector Cybersecurity Capability Maturity Model, which indeed was what the NIST Cybersecurity Framework was based on.  The Department of Energy, though, recommended voluntary application of the ES-C2M2. This module will examine both the drinking water and electricity lifeline infrastructure subsectors, and elements and application of the NIST Cybersecurity Framework and ES-C2M2."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-solutions-and-microsoft-defender",
    "name": "Cybersecurity Solutions and Microsoft Defender",
    "what_you_learn": "",
    "skills": "Identity and Access Management, Firewall, Virtual Machines, Malware Protection, Distributed Denial-Of-Service (DDoS) Attacks, Cloud Security, Security Information and Event Management (SIEM), Event Management, Network Security, Threat Detection, Encryption, Microsoft Azure, Cybersecurity, Security Controls, Threat Management, Cyber Security Policies, Endpoint Security, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you’ll learn about the types of cloud security policies that protect against DDoS Attacks, Firewall Breaches, and Unauthorized Access. Explore tools like MS Defender for cloud, security information and event management (SICM) and security orchestration, automation, and response (SOAR).You’ll gain an understanding of security features available in Azure and best practices for protecting Azure resources, as well as Azure security standards and compliance. You’ll also learn how to protect your organization’s assets from various types of threats, including malware, phishing, and identity-based attacks. This course will take you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience.\n\nAfter completing this course, you’ll be able to:\n•\tExplain cloud-based security concepts\n•\tDiscuss security information and event management (SIEM)\n•\tDefine 365 Defender capabilities\n\nThis is also a great way to prepare for the Microsoft SC-900 exam. By passing the SC-900 exam, you’ll earn the Microsoft Security, Compliance, and Identity Fundamentals Certification."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-threat-vectors-and-mitigation",
    "name": "Cybersecurity Threat Vectors and Mitigation",
    "what_you_learn": "Gain a comprehensive understanding of the constantly evolving world of cyber threats, including the types of attacks and vulnerabilities that exist.\nGain a comprehensive understanding of the constantly evolving world of cyber threats, including the types of attacks and vulnerabilities that exist.\nExplore different encryption algorithms and their various applications, as well as the strengths and weaknesses of each type.\nExplore different encryption algorithms and their various applications, as well as the strengths and weaknesses of each type.\nGain an understanding of key concepts in security and compliance, such as risk assessment, defense models, and regulatory requirements.\nGain an understanding of key concepts in security and compliance, such as risk assessment, defense models, and regulatory requirements.",
    "skills": "Security Strategy, Firewall, Active Directory, Authorization (Computing), Cyber Attacks, Multi-Factor Authentication, Encryption, Network Security, Cryptography, Authentications, Identity and Access Management, Data Security, Threat Detection, Cybersecurity, Threat Management, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course provides a comprehensive overview of threat vectors and the strategies for mitigating them, and aims to equip you with the necessary skills and knowledge to safeguard against cyber threats.You’ll gain a deep understanding of the threat vectors used by attackers, discover encryption techniques, and explore different compliance concepts. This course will get you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience. \n\nAfter completing this course, you’ll be able to:    \n\n•\tDescribe the active threat landscape  \n•\tDescribe common types of cyber attacks  \n•\tClassify different types of encryption algorithms   \n•\tExplain security and compliance concepts \n\nThis is also a great way to prepare for the Microsoft SC-900 exam. By passing the SC-900 exam, you’ll earn the Microsoft Security, Compliance, and Identity Fundamentals Certification."
  },
  {
    "url": "https://www.coursera.org/learn/cybersecurity-tools-and-technologies",
    "name": "Cybersecurity Tools and Technologies",
    "what_you_learn": "How to work with the tools associated with security testing within a cloud environment.\nHow to work with the tools associated with security testing within a cloud environment.\nHow to execute penetration testing on a cloud platform.\nHow to execute penetration testing on a cloud platform.\nHow to create a penetration test plan.\nHow to create a penetration test plan.",
    "skills": "Microsoft Azure, Network Security, System Testing, Penetration Testing, Exploitation techniques, Vulnerability Assessments, Intrusion Detection and Prevention, Security Testing, Cybersecurity, Firewall, Cloud Security, Virtual Private Networks (VPN), Vulnerability Management, Vulnerability Scanning, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course engages you in the world of cybersecurity attack and defense, dealing with both sides and working with the tools associated with security testing within a cloud environment.You’ll gain knowledge on the penetration testing strategies employed by the industry to assess the integrity of their network. You’ll also interpret the results of security scans and deal with mitigation strategies such as vulnerability management. This course will take you one step closer to the Microsoft Cybersecurity Analyst Professional Certificate, which requires no degree or prior experience.\n\nAfter completing this course, you’ll be able to:   \n\n•\tExplain the concept of system testing\n•\tCreate a penetration test plan\n•\tExecute penetration testing on a cloud platform\n\nThis is also a great way to prepare for the Microsoft SC-900 exam. By passing the SC-900 exam, you’ll earn the Microsoft Security, Compliance, and Identity Fundamentals Certification."
  },
  {
    "url": "https://www.coursera.org/learn/d4h-gender-equity-health-data",
    "name": "Gender Foundations in Health Data: A Data for Health Course",
    "what_you_learn": "",
    "skills": "Social Determinants Of Health, Health Disparities, Health Equity, Public Health, Data Analysis, Health Policy, Data Collection, Research, Health Informatics, Surveys",
    "instructors": [
      "~117295425",
      "~6948042"
    ],
    "content": "Welcome to Gender Foundations in Health Data: A Data for Health course.  This course was developed from an online seminar series of the same name, that was hosted by Johns Hopkins University Bloomberg School of Health in 2021-22. The course instructors are Drs. Michelle Kaufman and Tahilin Sanchez Karver.This course will raise learners' awareness of the necessity of utilizing a gender lens in global public health data, policy, and practice, feature how-tos and key examples of integration of gender in data collection, analysis, and use from Data for Health partners\n\nTechnical Specifications\nThis course uses a third-party app called Articulate Rise to deliver the course materials. You will need to click-through a few screens (Articulate Rise, pop-up blockers) to enter and exit each Module. Please be sure to turn off pop-up blockers to access the materials. \n\nTo post in the discussion forums, you will need to exit the Modules in Articulate Rise and go back to Coursera. Please feel free to reach out to teamgenderhealth@jh.edu with any questions, including technology concerns. We hope you have a good experience learning about gender integration in your health data work."
  },
  {
    "url": "https://www.coursera.org/learn/da-xue-hua-xue",
    "name": "大学化学",
    "what_you_learn": "",
    "skills": "Physical Science, Engineering, Chemistry, Experimentation, Materials science, Molecular, Cellular, and Microbiology",
    "instructors": [
      "bianj"
    ],
    "content": "本课程是北京大学开设的一门在线大学化学基础课，主要面向具有大学水平的化学初学者。课程内容基本涵盖全部基础化学概念。"
  },
  {
    "url": "https://www.coursera.org/learn/dairy-economics-maximizing-profits-through-milk-quality",
    "name": "Dairy Economics: Maximizing Profits through Milk Quality",
    "what_you_learn": "Describe the immune mechanisms involved in intramammary infections.\nDescribe the immune mechanisms involved in intramammary infections.\nAnalyze the economic impact of mastitis and evaluate treatment decisions using decision trees and cost models.\nAnalyze the economic impact of mastitis and evaluate treatment decisions using decision trees and cost models.\nApply diagnostic tools such as somatic cell counts and on-farm culturing.\nApply diagnostic tools such as somatic cell counts and on-farm culturing.\nIdentify common mastitis-causing pathogens and their characteristics.\nIdentify common mastitis-causing pathogens and their characteristics.",
    "skills": "Laboratory Testing, Infectious Diseases, Cost Benefit Analysis, Decision Making, Cost Management, Immunology, Data-Driven Decision-Making, Preventative Care, Microbiology, Diagnostic Tests",
    "instructors": [
      "~174528895"
    ],
    "content": "This course provides an in-depth look at mastitis in dairy cows, focusing on the immune response, diagnostic tools, and economic considerations. Learners will explore the cellular and microbial basis of intramammary infections, practical tools for on-farm diagnosis, and the financial impact of mastitis on dairy operations. Through a systems-thinking approach, students will gain the knowledge needed to make informed decisions about mastitis prevention and treatment strategies.This course is part of the College of ACES suite of online programs. To learn more about online programs from the College of ACES and explore ways to apply your Coursera work toward a degree program at the University of Illinois, visit: https://aces.illinois.edu/online."
  },
  {
    "url": "https://www.coursera.org/learn/dairy-nutrition-and-health-analyzing-cow-wellness",
    "name": "Dairy Nutrition & Health: Analyzing Cow Wellness",
    "what_you_learn": "Understand the physiological changes around calving and their impact on dairy cow health and nutrient needs.\nUnderstand the physiological changes around calving and their impact on dairy cow health and nutrient needs.\nIdentify key biomarkers of health and disease and their roles in metabolism, immune function, and liver function.\nIdentify key biomarkers of health and disease and their roles in metabolism, immune function, and liver function.\nDiagnose and manage common health problems in dairy cows using metabolic and immune biomarkers.\nDiagnose and manage common health problems in dairy cows using metabolic and immune biomarkers.\nApply a systems approach to nutritional management for optimal cow health and productivity.\nApply a systems approach to nutritional management for optimal cow health and productivity.",
    "skills": "Health Assessment, Diagnostic Tests, Nutritional Assessment, Nutrition and Diet, Molecular Biology, Systems Analysis, Physiology, Endocrinology, Clinical Nutrition, Biology, Pathology, Laboratory Testing, Biochemistry, View all skills",
    "instructors": [
      "~175612643"
    ],
    "content": "This course offers a comprehensive exploration of dairy cow health and nutrition, focusing on physiological changes around calving and their impact on nutrient needs. Students will learn about production diseases, major metabolic changes, and key biomarkers of health and disease. The course addresses common health problems in dairy cows and the role of biomarkers in diagnosis and management. A systems approach to nutritional management is emphasized, exploring how genetics, cellular networks, and dietary components influence cow health and productivity. Expert instructors will guide learners through practical applications to optimize dairy cow health and productionThis course is part of the College of ACES suite of online programs, including the graduate certificate, \"Dairy Nutrition for Udder Success\" that can be stacked toward an advanced degree in the College of ACES. To learn more about online programs from the College of ACES and explore ways to apply your Coursera work toward a degree program at the University of Illinois, visit ACES Online @ aces.illinois.edu/online."
  },
  {
    "url": "https://www.coursera.org/learn/dairy-production",
    "name": "Dairy Production and Management",
    "what_you_learn": "",
    "skills": "Market Dynamics, Biotechnology, Water Resource Management, Nutrition and Diet, Production Management, Environmental Management Systems, Climate Change Mitigation, Sustainability Standards, Business Economics, Manufacturing and Production, View all skills",
    "instructors": [
      "gwr",
      "rjv10",
      "tlo12",
      "kjr101",
      "cdd1",
      "jwd6",
      "lah7",
      "bmj3",
      "anh13",
      "gvarga88"
    ],
    "content": "With the world's first MOOOOO-C, you will gain a broad and comprehensive understanding of all aspects of dairy management such as genetics, nutrition, reproduction, animal health, farm economics, and sustainability of dairy production systems. There's something here for everyone whether you are just looking for the basics or have years of experience in the dairy industry.This is an eight-week course. Each week consists of four to nine video lectures, additional reading materials, and a multiple-choice questions quiz. Estimated study time is between three and five hours per week. Learners have the option to purchase a Course Certificate for 49.00 USD. The certificate can be purchased at any time, but you must verify your identify before taking the course quizzes in order to be eligible. For those who cannot afford the certificate fee, financial aid is available through Coursera.\n\nWhy is producing milk efficiently and sustainably so important? \n\nMilk provides humans with over 16 essential nutrients, such as: Energy, Protein and Essential Amino acids, Vitamin A, Vitamin D, several B vitamins, including B12, Pantothenic and Folic acids, and essential minerals such as Calcium, Magnesium, Phosphorus, Potassium, Zinc, as well as other minerals. Did you know that one glass of milk provides a 5-year old child with 21% of his/her daily protein requirements and 8% of their energy needs?\n\nMost milk in the world, about 85%, is produced from cattle. However, water buffaloes, goats, sheep, and camel are also dairy animals. The United States, India, the European Union, Brazil, and New Zealand are among the largest dairy producers in the world. Yet among these dairy-producing countries there are varied methods to generate milk with highly variable productivity and efficiency. Dairy production is vital for the survival of billions of people. Globally, around 150 million small-scale dairy households, equivalent to 750 million people, are engaged in milk production. The number and size of dairy farms varies among countries, but in India alone, there are estimated 78 million dairy farms! In the United States, one of the leading milk-producing countries in the world, total milk production has been steadily increasing in the last decades, reaching over 205 billion pounds (93 billion kilograms) in 2014. This was accompanied by a steady increase in average milk yield per cow, reaching 22,260 lb (over 10,100 kg) per lactation in 2014. How has this efficiency been achieved? What methods are necessary to ensure production of high quality milk? How do we balance milk production efficiency with animal health and environmental protection? This course will provide the student with information to better understand dairy production systems and their role in feeding the world population.\n\nIn this MOOOOO-C, you will learn about the dairy enterprise from internationally recognized dairy science professors who have delivered highly regarded dairy education programs within the United States and internationally.\n\nCourse lectures are translated into Portuguese and Chinese; PDF files of these translations can be found under each course week. The Dairy MOOC team thanks Dr. Antonio Branco (Universidade Estadual de Maringá, Brazil) and Ms. Yuanyuan Zhang (Pennsylvania State University) for translating the lecture materials.\n\nCourse Sponsors\n\nThis course was supported by the generous contributions of Innovation Center for US Dairy at Silver Level and Pancosma North America, RP Nutrients, Inc. and Arm and Hammer, which provided funding support at a Bronze Level.  The Pennsylvania State University has final responsibility for the academic content of this course."
  },
  {
    "url": "https://www.coursera.org/learn/dangdai-yingyong-xinli-xue",
    "name": "当代应用心理学",
    "what_you_learn": "",
    "skills": "Professional Development, Leadership, Psychology, Criminal Investigation and Forensics, Decision Making, Mental Health, Organizational Effectiveness, Consumer Behaviour, Industrial and Organizational Psychology, Psychological Evaluations, Human Factors, Relationship Building, Marketing Psychology, View all skills",
    "instructors": [
      "liuwt"
    ],
    "content": "【课程介绍】《当代应用心理学》是由云林科技大学 刘威德教授主讲的一门应用心理学课程\n                               并由云林科技大学 惠龙博士担任总顾问\n\n课程将精选八项心理学与日常生活息息相关的应用议题，藉由生活对象设计(人因心理学)、消费行为、领导管理、性格分析、犯罪行为、心理保健与心理测验、人际关系等方面运用生活知能、个体行为与态度、测验诊断加以说明诠释应用心理学之奥妙。例如:自行车设计动向、民众购车消费行为、便利商店兑币代换机制、组织领导策略、关注情绪管理、人格特质透析、以及如何经营成功良好的职场与人际关系等事例，深入浅出探讨来应用心理学的理论与实际生活经验分析概念。\n\n【课程大纲】\n探讨从众/群众心理、消费行为模式、成功营销的法则、消费者的觉察-广告营销的心理法则、广告营销心理实例探讨、探讨领导管理的现象、管理组织的策略、成功领导者的特质、组织人事的经营管理、探讨人格特质分析、人格的形成和发展、性格的影响因素、性格的常态与偏态、探讨犯罪心理、偏差行为发展脉络分析、法律与生活的关系、犯罪与偏差行为的预防-罢凌行为的心理探讨、探讨心理保健层面、情绪管理、快乐心理、落实小区心理保健、个别心理特质的差异、心理测验的原理、探讨如何藉由心理测验及诊断工具了解个别特质的差异、心理测验的迷思概念、探讨人际关系互动网络、人际关系的影响因素、成功职场心理的经营、职场的求职陷阱以及以上各内容之实例。\n\n第1周：心理学原理概述Introduction\n第2周：人因心理学原理简介及实例探讨Human Factors and Ergonomics\n第3周：消费者心理学原理简介及实例探讨Consumer Psychology\n第4周：组织及领导心理学原理简介及实例探讨Leadership Psychology\n第5周：性格心理学原理简介及实例探讨Personality Psychology\n第6周：法律与犯罪心理学原理简介及实例探讨 Law and Criminal Psychology\n第7周：身心健康与适应心理原理简介及实例探讨Mental Health Psychology\n第8周：心理测验与个别特质差异的原理简介及实例探讨Psychological Testing\n第9周：人际与职场心理的原理简介及实例探讨Human Relationship and Career Psychology\n\n【学习目标】\n心理学是一门探讨人性的科学，剖析个体的内隐心理历程和外显行为反应。涉及范围广泛，涵括有认知、情绪、人格、人际、和领导等多方领域，同时也和日常生活息息相关如婚姻、消费、家庭、对象设计等密不可分，心理学的影响层面扩及到教育、社会、科学、医学、生物等层面。因此，探讨分析心理学所产生的生理行为间接亦或直接影响到个人心智，运用大脑运作模式来解释个人行为，应用层面在日常生活中比比皆是。本课程之目标在于探讨心理学的科学理论基础原理、以心理学的观点检视剖析周遭生活中的个人与社会行为现象，并进而能够觉察与改变个人的心理历程与行为模式，终而能够经营圆满合谐而健康的人生。\n\n【学习要求】\n本课程的在线教材将以较短的课程长度实施9周，每周2小时，共18小时，每周规划一主题(topic)，每一个主题分为若干节(section)或讲次(lecture)，以及符合学习专注力时间长度的上课内容（15分钟小单元），透过在线学习平台，由教师制作提供主题明确且长度适中的单元教学影片，辅以测验及作业，让学生依自己学习步调在线自我学习，并藉由教师设计安排的学习互动，与老师及同侪于虚拟平台或实体空间进行探索讨论。教学互动及评量回馈，提升在线学习的质量及效能，期能建立华文课程品牌。\n\n【教材教参】\nSternberg, Robert J. (2004). Psychology 4th.C.A. Thomson Wadsworth.\nBekerian, D. A. &Levey, A. B. (2005). Applied Psychology. Oxford.\nCascio, W. F. &Aguinis, H. (2005). Applied Psychology in Human Resource Management. Pearson Prentice Hall.\n美国心理学会(American Psychology Association, APA)资源\n张春兴(1991).现代心理学。台北：东华书局。\n张春兴(2003).心理学原理。台北：东华书局。\n张春兴主编.世纪心理学丛书。东华书局(繁体字版)。浙江教育出版社(简体字版)。"
  },
  {
    "url": "https://www.coursera.org/learn/daojiao",
    "name": "品读道家的智慧",
    "what_you_learn": "",
    "skills": "Ancient History, Political Sciences, Liberal Arts, Culture, Cultural Diversity, Social Studies",
    "instructors": [
      "~11044721"
    ],
    "content": "儒家和道家，都是中国文化的主流。儒家塑造着国人的社会人格，道家则成就着国人的自然人格。道家的智慧，博大精深，学理深奥，以“道”为核心，以“自然”与“无为”为基本范畴，对为人处事与政治哲学有着深远的影响，具有重要的现代价值。本课程主要分三大部分：道家的渊源和宗旨；老子其人其书其道；庄子其人其书其道。着重阐述了道家的渊源和宗旨，老子和庄子的智慧精要及其现代价值。"
  },
  {
    "url": "https://www.coursera.org/learn/daoyan-siwei-weiyingren",
    "name": "导演思维：微影人的自我修养",
    "what_you_learn": "",
    "skills": "Writing, Performing Arts, Storytelling, Creativity, Editing, Video Production, Storyboarding",
    "instructors": [
      "xiaoxiao"
    ],
    "content": "拍微电影，没什么必须要走的路，可以从任何地方起步。但起步之前，首先要形成对微电影的正确认知。本门课程以情景再现的方式，结合理论与实践，打通技术与叙事，简明扼要地还原微电影创作的全历程，以期传达这样的理念：微电影创作，需要怀着敬畏之心，以更天真的姿态去对抗这个模式化的世界，从而达致自由的境界。生命最切肤之处，就是电影开始的地方。"
  },
  {
    "url": "https://www.coursera.org/learn/darwin-origen-evolucionismo-moderno",
    "name": "Charles Darwin: El origen del evolucionismo moderno",
    "what_you_learn": "Introducir a los alumnos en el estudio de la evolución biológica y mostrar la relevancia de Charles Darwin en relación con el evolucionismo moderno.\nIntroducir a los alumnos en el estudio de la evolución biológica y mostrar la relevancia de Charles Darwin en relación con el evolucionismo moderno.",
    "skills": "Specimen Collection, European History, Biology, Life Sciences, Taxonomy, Scientific Methods",
    "instructors": [
      "~39497823"
    ],
    "content": "Este curso está dirigido a cualquier persona que desee conocer de manera general qué es y cómo se ha explicado la evolución de las especies. Será de gran interés para alumnos, profesores y profesionales del área de ciencias biológicas y de la salud que deseen conocer los antecedentes históricos, así como los fundamentos centrales de la teoría de Charles Darwin, que configuraron el pensamiento evolutivo moderno."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-and-visualization-with-power-bi",
    "name": "Data Analysis and Visualization with Power BI",
    "what_you_learn": "How to add visualizations to reports and dashboards.\nHow to add visualizations to reports and dashboards.\nHow to design accessible reports and dashboards.\nHow to design accessible reports and dashboards.\nHow to use visualizations to perform data analysis.\nHow to use visualizations to perform data analysis.",
    "skills": "Data Visualization, Data Visualization Software, Data Storytelling, Dashboard, Microsoft Power Platform, Statistical Reporting, Data Analysis, Data-Driven Decision-Making, Web Content Accessibility Guidelines, Power BI, Advanced Analytics, Data Presentation, Interactive Data Visualization, Time Series Analysis and Forecasting, Business Intelligence, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course forms part of the Microsoft Power BI Analyst Professional Certificate. This Professional Certificate consists of a series of courses that offers a good starting point for a career in data analysis using Microsoft Power BI.In this course, you will learn report design and formatting in Power BI, which offers extraordinary visuals for building reports and dashboards. Additionally, you will learn how to use report navigation to tell a compelling, data-driven story in Power BI. You will explore how to get a statistical summary for your data and how to create and export reports in Power BI. You will also perform advanced analytics in Power BI to get deeper and more meaningful data insights. \n\nAfter completing this course, you'll be able to:  \n\n●\tRecognize the different types of visualizations in Power BI \n●\tAdd visualizations to reports and dashboards \n●\tApply formatting choices to visuals \n●\tAdd useful navigation techniques to the Power BI report \n●\tDesign accessible reports and dashboards \n●\tUse visualizations to perform data analysis \n\nThis is also a great way to prepare for the Microsoft PL-300 exam. By passing the PL-300 exam, you’ll earn the Microsoft Power BI Data Analyst certification."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-project-pwc",
    "name": "Data Analysis and Presentation Skills: the PwC Approach Final Project",
    "what_you_learn": "",
    "skills": "Data Analysis, Presentations, Data Visualization, Constructive Feedback, Dashboard, Business Analysis, Microsoft PowerPoint, Data Storytelling, Customer Analysis, Microsoft Excel, Pivot Tables And Charts, Business Consulting, Target Audience, Data Presentation, View all skills",
    "instructors": [
      "~19932496"
    ],
    "content": "In this Capstone Project, you'll bring together all the new skills and insights you've learned through the four courses. You'll be given a 'mock' client problem and a data set. You'll need to analyze the data to gain business insights, research the client's domain area, and create recommendations. You'll then need to visualize the data in a client-facing presentation. You'll bring it all together in a recorded video presentation.This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-python",
    "name": "Data Analysis Using Python",
    "what_you_learn": "Apply basic data science techniques using Python\nApply basic data science techniques using Python\nUnderstand and apply core concepts like Data Frames and joining data, and use data analysis libraries like pandas, numpy, and matplotlib\nUnderstand and apply core concepts like Data Frames and joining data, and use data analysis libraries like pandas, numpy, and matplotlib\nDemonstrate how to load, inspect, and query real-world data, and answer basic questions about that data\nDemonstrate how to load, inspect, and query real-world data, and answer basic questions about that data\nAnalyze data further by applying learned skills in data aggregation and summarization, as well as basic data visualization\nAnalyze data further by applying learned skills in data aggregation and summarization, as well as basic data visualization",
    "skills": "Pandas (Python Package), Scatter Plots, Data Science, Histogram, Data Validation, Pivot Tables And Charts, Matplotlib, Data Visualization, Data Structures, Data Import/Export, NumPy, Data Cleansing, Data Analysis, Data Visualization Software, Scripting Languages, Programming Principles, Data Transformation, Python Programming, Jupyter, Data Manipulation, View all skills",
    "instructors": [
      "brandonkrakowsky"
    ],
    "content": "This course provides an introduction to basic data science techniques using Python.  Students are introduced to core concepts like Data Frames and joining data, and learn how to use data analysis libraries like pandas, numpy, and matplotlib.  This course provides an overview of loading, inspecting, and querying real-world data, and how to answer basic questions about that data.  Students will gain skills in data aggregation and summarization, as well as basic data visualization."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-r",
    "name": "Data Analysis with R Programming",
    "what_you_learn": "Describe the R programming language and its programming environment.\nDescribe the R programming language and its programming environment.\nExplain the fundamental concepts associated with programming in R including functions, variables, data types, pipes, and vectors.\nExplain the fundamental concepts associated with programming in R including functions, variables, data types, pipes, and vectors.\nDescribe the options for generating visualizations in R.\nDescribe the options for generating visualizations in R.\nDemonstrate an understanding of the basic formatting in R Markdown to create structure and emphasize content.\nDemonstrate an understanding of the basic formatting in R Markdown to create structure and emphasize content.",
    "skills": "Package and Software Management, Ggplot2, Data Import/Export, R (Software), Data Visualization Software, R Programming, Data Analysis, Tidyverse (R Package), Data Manipulation, Data Visualization, Data Structures, Data Cleansing, Statistical Programming, Rmarkdown, View all skills",
    "instructors": [
      "google-career-certificates"
    ],
    "content": "This course is the seventh course in the Google Data Analytics Certificate. In this course, you’ll learn about the programming language known as R. You’ll find out how to use RStudio, the environment that allows you to work with R, and the software applications and tools that are unique to R, such as R packages. You’ll discover how R lets you clean, organize, analyze, visualize, and report data in new and more powerful ways. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.\n\nBy the end of this course, learners will:\n- Examine the benefits of using the R programming language.\n- Discover how to use RStudio to apply R to your analysis. \n- Explore the fundamental concepts associated with programming in R. \n- Understand the contents and components of R packages including the Tidyverse package.\n- Gain an understanding of dataframes and their use in R.\n- Discover the options for generating visualizations in R.\n- Learn about R Markdown for documenting R programming."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-sql",
    "name": "Data Analysis Using SQL",
    "what_you_learn": "Extract relevant data from the database in a time efficient manner\nExtract relevant data from the database in a time efficient manner\nBuild powerful SQL queries to derive insights\nBuild powerful SQL queries to derive insights\nAnalyse and manage large datasets, and derive inferences from complex relational database\nAnalyse and manage large datasets, and derive inferences from complex relational database\nEnable students to create and modify databases for relevant business problems\nEnable students to create and modify databases for relevant business problems",
    "skills": "SQL, Relational Databases, Data Transformation, Data Cleansing, Data Integrity, Database Design, Data Analysis, Query Languages, Databases, Data Manipulation, Database Management, MySQL Workbench",
    "instructors": [
      "~118019277"
    ],
    "content": "In this comprehensive course, you will embark on a transformative journey to master the art of analyzing data through SQL.SQL is a powerful tool used for managing and manipulating data in relational databases. Throughout this course, you will acquire the essential skills to efficiently extract relevant data from databases, empowering you to navigate through vast amounts of information with ease. \n\nWith a focus on practical application, you will delve into the world of data analysis, discovering how to derive meaningful insights from large datasets housed within complex relational databases. By the end of this course, you will \nGain skills to create and modify databases, equipping you with the ability to solve real-world business problems. \n Learn to filter and clean datasets, ensuring the accuracy and reliability of your analysis. \n\nWhether you aspire to be a data analyst, a business intelligence professional, or a decision-maker relying on data-driven insights, this course will provide you with the necessary tools and knowledge to succeed."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-visualization-and-communication-with-copilot",
    "name": "Data Analysis, Visualization, and Communication with Copilot",
    "what_you_learn": "Utilize Microsoft Copilot and other AI tools for in-depth data analysis and forecasting.\nUtilize Microsoft Copilot and other AI tools for in-depth data analysis and forecasting.\nGenerate clear, engaging, and inclusive data visualizations with Copilot's assistance.\nGenerate clear, engaging, and inclusive data visualizations with Copilot's assistance.\nCraft persuasive reports and presentations tailored for both technical and non-technical stakeholders.\nCraft persuasive reports and presentations tailored for both technical and non-technical stakeholders.\nDevelop comprehensive communication strategies that drive data-informed decision-making.\nDevelop comprehensive communication strategies that drive data-informed decision-making.",
    "skills": "Advanced Analytics, Data Visualization, Data Analysis, Communication, Interactive Data Visualization, Generative AI, Data Visualization Software, Microsoft Copilot, Data Storytelling, Strategic Communication, Technical Communication, Big Data, Artificial Intelligence, Responsible AI, Data-Driven Decision-Making, Natural Language Processing, Presentations, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course will help you to transform complex data into actionable insights and compelling stories using Microsoft Copilot. You'll learn cutting-edge generative AI techniques for data analysis, visualization, and communication, enabling you to uncover hidden patterns, create impactful visuals, and effectively convey your findings to diverse audiences.Required Course Materials: A Copilot license is required to complete this course. If you don’t have a Microsoft 365 Personal or Family license, you can start a free 30-day trial using the link provided in the course."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-visualization-foundations-assessment",
    "name": "Assessment for Data Analysis and Visualization Foundations",
    "what_you_learn": "Demonstrate readiness for performing foundational data analysis and data visualization tasks and key steps in the Data Analytics process.\nDemonstrate readiness for performing foundational data analysis and data visualization tasks and key steps in the Data Analytics process.\nDifferentiate between the roles different data professionals play in a modern data ecosystem.\nDifferentiate between the roles different data professionals play in a modern data ecosystem.\nPerform basic Excel tasks for Data Analysis including data quality and data preparation skills.\nPerform basic Excel tasks for Data Analysis including data quality and data preparation skills.\nExhibit abilities in visualizing data using Excel and proficiency in creating dashboards using Excel and Cognos Analytics.\nExhibit abilities in visualizing data using Excel and proficiency in creating dashboards using Excel and Cognos Analytics.",
    "skills": "Data Quality, IBM Cognos Analytics, Dashboard, Data Analysis, Exploratory Data Analysis, Data Mining, Pivot Tables And Charts, Data Cleansing, Data Visualization Software, Microsoft Excel, Data Collection, Data Wrangling, View all skills",
    "instructors": [
      "ibm-skills-network"
    ],
    "content": "This course is the final step in the Data Analysis and Visualization Foundations Specialization. It contains a graded final examination that covers content from three courses: Introduction to Data Analytics, Excel Basics for Data Analysis, and Data Visualization and Dashboards with Excel and Cognos.From the Introduction to Data Analytics course, your understanding will be assessed on topics like the data ecosystem and the fundamentals of data analysis, covering tools for data gathering and data mining. Moving on to the Excel Basics for Data Analysis course, expect questions focusing on the use of Excel spreadsheets in data analytics, proficiency in data cleansing and wrangling, and skills in working with pivot tables. Finally, from the Data Visualization and Dashboards with Excel and Cognos course, you will demonstrate your knowledge of IBM Cognos basics and your ability to use Excel for effective data visualization."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-with-python",
    "name": "Data Analysis with Python",
    "what_you_learn": "Construct Python programs to clean and prepare data for analysis by addressing missing values, formatting inconsistencies, normalization, and binning\nConstruct Python programs to clean and prepare data for analysis by addressing missing values, formatting inconsistencies, normalization, and binning\nAnalyze real-world datasets through exploratory data analysis (EDA) using libraries such as Pandas, NumPy, and SciPy to uncover patterns and insights\nAnalyze real-world datasets through exploratory data analysis (EDA) using libraries such as Pandas, NumPy, and SciPy to uncover patterns and insights\nApply data operation techniques using dataframes to organize, summarize, and interpret data distributions, correlation analysis, and data pipelines\nApply data operation techniques using dataframes to organize, summarize, and interpret data distributions, correlation analysis, and data pipelines\nDevelop and evaluate regression models using Scikit-learn, and use these models to generate predictions and support data-driven decision-making\nDevelop and evaluate regression models using Scikit-learn, and use these models to generate predictions and support data-driven decision-making",
    "skills": "Data Import/Export, Data-Driven Decision-Making, Regression Analysis, Data Transformation, Data Analysis, Feature Engineering, Data Pipelines, Scikit Learn (Machine Learning Library), Data Cleansing, Data Manipulation, Predictive Modeling, Data Wrangling, Matplotlib, Statistical Analysis, Data Visualization, Pandas (Python Package), Exploratory Data Analysis, NumPy, Python Programming, View all skills",
    "instructors": [
      "~28511493"
    ],
    "content": "Analyzing data with Python is a key skill for aspiring Data Scientists and Analysts!This course takes you from the basics of importing and cleaning data to building and evaluating predictive models. You’ll learn how to collect data from various sources, wrangle and format it, perform exploratory data analysis (EDA), and create effective visualizations. As you progress, you’ll build linear, multiple, and polynomial regression models, construct data pipelines, and refine your models for better accuracy. \n\nThrough hands-on labs and projects, you’ll gain practical experience using popular Python libraries such as Pandas, NumPy, Matplotlib, Seaborn, SciPy, and Scikit-learn. These tools will help you manipulate data, create insights, and make predictions.\n\nBy completing this course, you’ll not only develop strong data analysis skills but also earn a Coursera certificate and an IBM digital badge to showcase your achievement."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-with-r",
    "name": "Data Analysis with R",
    "what_you_learn": "Prepare data for analysis by handling missing values, formatting and normalizing data, binning, and turning categorical values into numeric values.\nPrepare data for analysis by handling missing values, formatting and normalizing data, binning, and turning categorical values into numeric values.\nCompare and contrast predictive models using simple linear, multiple linear, and polynomial regression methods.\nCompare and contrast predictive models using simple linear, multiple linear, and polynomial regression methods.\nExamine data using descriptive statistics, data grouping, analysis of variance (ANOVA), and correlation statistics.\nExamine data using descriptive statistics, data grouping, analysis of variance (ANOVA), and correlation statistics.\nEvaluate a model for overfitting and underfitting conditions and tune its performance using regularization and grid search.\nEvaluate a model for overfitting and underfitting conditions and tune its performance using regularization and grid search.",
    "skills": "Exploratory Data Analysis, Regression Analysis, Data Manipulation, Statistical Modeling, R Programming, Predictive Analytics, Machine Learning Methods, Predictive Modeling, Feature Engineering, Data Visualization, Data Wrangling, Data Analysis, Statistical Analysis, Data Science, View all skills",
    "instructors": [
      "tiffanyzhu",
      "gabrieladequeiroz",
      "yiwenli"
    ],
    "content": "The R programming language is purpose-built for data analysis. R is the key that opens the door between the problems that you want to solve with data and the answers you need to meet your objectives.  This course starts with a question and then walks you through the process of answering it through data. You will first learn important techniques for preparing (or wrangling) your data for analysis. You will then learn how to gain a better understanding of your data through exploratory data analysis, helping you to summarize your data and identify relevant relationships between variables that can lead to insights. Once your data is ready to analyze, you will learn how to develop your model and evaluate and tune its performance. By following this process, you can be sure that your data analysis performs to the standards that you have set, and you can have confidence in the results.You will build hands-on experience by playing the role of a data analyst who is analyzing airline departure and arrival data to predict flight delays. Using an Airline Reporting Carrier On-Time Performance Dataset, you will practice reading data files, preprocessing data, creating models, improving models, and evaluating them to ultimately choose the best model. \n\nWatch the videos, work through the labs, and add to your portfolio. Good luck!\n\nNote: The pre-requisite for this course is basic R programming skills. For example, ensure that you have completed a course like Introduction to R Programming for Data Science from IBM."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-with-spreadsheets-and-sql",
    "name": "Data Analysis with Spreadsheets and SQL",
    "what_you_learn": "Clean data with spreadsheets and use common spreadsheet formulas to calculate summary statistics\nClean data with spreadsheets and use common spreadsheet formulas to calculate summary statistics\nWrite foundational SQL statements and queries to extract data in spreadsheets\nWrite foundational SQL statements and queries to extract data in spreadsheets\nCreate charts in Google Sheets and use Tableau to visualize data and use dashboards to create data visualizations\nCreate charts in Google Sheets and use Tableau to visualize data and use dashboards to create data visualizations",
    "skills": "Tableau Software, Data Manipulation, Data Cleansing, Data Visualization Software, Data Visualization, Marketing Analytics, Statistical Analysis, Data Storytelling, Descriptive Statistics, Pivot Tables And Charts, Exploratory Data Analysis, Google Sheets, SQL, Spreadsheet Software, Correlation Analysis, Data Analysis, Dashboard, View all skills",
    "instructors": [
      "~115843034"
    ],
    "content": "This course introduces you to how to use spreadsheets and SQL queries to analyze and extract data. You will learn how to practically apply the OSEMN data analysis framework and spreadsheet functions to clean data, calculate summary statistics, evaluate correlations, and more. You’ll also dive into common data visualization techniques and learn how to use dashboards to tell a story with your data.By the end of this course you will be able to:\n• Clean data with spreadsheets\n• Use common spreadsheet formulas to calculate summary statistics\n• Identify data trends and patterns\n• Write foundational SQL statements and queries to extract data in spreadsheets\n• Create charts in Google Sheets and use Tableau to visualize data\n• Use dashboards to create data visualizations\n\nYou don't need marketing or data analysis experience, but should have basic internet navigation skills and be eager to participate. Ideally you have already completed course 1: Marketing Analytics Foundation and course 2: Introduction to Data Analytics in this program."
  },
  {
    "url": "https://www.coursera.org/learn/data-analysis-with-tableau-public",
    "name": "Data Analysis with Tableau",
    "what_you_learn": "Apply Tableau techniques to manipulate and prepare data for analysis.\nApply Tableau techniques to manipulate and prepare data for analysis.\nPerform exploratory data analysis using Tableau and report insights using descriptive statistics and visualizations.\nPerform exploratory data analysis using Tableau and report insights using descriptive statistics and visualizations.\nIdentify the benefits of the analytics feature in Tableau by utilizing this tool versus manually calculating the analytics.\nIdentify the benefits of the analytics feature in Tableau by utilizing this tool versus manually calculating the analytics.",
    "skills": "Business Analytics, Histogram, Regression Analysis, Box Plots, Predictive Analytics, Scatter Plots, Data Analysis, Descriptive Statistics, Data Cleansing, Data Visualization, Statistical Methods, Data Manipulation, Trend Analysis, Statistical Analysis, Data Processing, Exploratory Data Analysis, Analytics, Tableau Software, Data Visualization Software, View all skills",
    "instructors": [
      "~136272031"
    ],
    "content": "The Data Analysis with Tableau Course will teach you how to manipulate and prepare data for analysis and reporting. You will also learn how to use the analytics features in Tableau to more effectively calculate analytics versus manual calculations. In this course, you will perform exploratory data analysis as well as create reports using descriptive statistics and visualizations.This course is for anyone who is curious about entry-level roles that demand fundamental Tableau skills, such as business intelligence analyst or data reporting analyst roles. It is recommended (but not required) that you have some experience with Tableau Public, but even if you're new to Tableau Public, you can still be successful in this program.\n\nBy the end of the course, you will be able to:\n-Apply Tableau Public techniques to manipulate and prepare data for analysis.\n-Perform exploratory data analysis using Tableau and report insights using descriptive statistics and visualizations.\n-Identify the benefits of the analytics feature in Tableau by utilizing this tool versus manually calculating the analytics."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-and-databases-aws",
    "name": "Data Analytics and Databases on AWS",
    "what_you_learn": "Key data types and structures\nKey data types and structures\nAWS services for the ETL process\nAWS services for the ETL process\nHands-on skills for Amazon API Gateway and Amazon QuickSight\nHands-on skills for Amazon API Gateway and Amazon QuickSight",
    "skills": "NoSQL, Data Architecture, Data Analysis, Data Processing, Data Warehousing, Data Visualization Software, Databases, SQL, Big Data, Data Pipelines, Extract, Transform, Load, Cloud API, Data-Driven Decision-Making, Amazon Web Services, Data Transformation, Unstructured Data, Business Analytics, Relational Databases, Data Storage, View all skills",
    "instructors": [
      "bobeirasa",
      "~92822012"
    ],
    "content": "Data is everywhere. If you or your company don't know what data you have and what insights you can uncover through your data, you are at a competitive disadvantage. In this course, you'll get introduced to data analytics and the upside of data-driven decisions. You'll learn about the omnipresence of data in today's world and what it takes to start thinking and acting like a data analyst. Week 1 concludes by comparing and contrasting ETL (Extract, Transform, Load) and ELT(Extract, Load, Transform) and where data is transformed and how data warehouses retain data. Week 2 kicks off with an overview of data workflow and database foundations. The four vs (volume, velocity, variety and veracity) of data are explained along with walk-throughs of collecting, processing, and storing data. In the course's final week, you'll get briefed on some of the AWS services that can be leveraged for ETL. You'll extract data with Amazon API Gateway, process data with AWS Lambda, load data with Amazon RDS, and visualize data with Amazon QuickSight. There's the right tool for each unique data analysis task."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-business",
    "name": "Introduction to Data Analytics for Business",
    "what_you_learn": "Describe the information lifecycle from events in the real world to business actions\nDescribe the information lifecycle from events in the real world to business actions\nRecognize the types of events and characteristics that are often used in business analytics\nRecognize the types of events and characteristics that are often used in business analytics\nExplain how the data is captured by source systems and stored using both traditional and emergent technologies\nExplain how the data is captured by source systems and stored using both traditional and emergent technologies\nGain familiarity with relational databases and learn how to use a simple but powerful language called SQL to extract analytical data sets of interest\nGain familiarity with relational databases and learn how to use a simple but powerful language called SQL to extract analytical data sets of interest",
    "skills": "SQL, Data Governance, Business Analytics, Databases, Data Storage Technologies, Cloud Computing, Data Analysis, Relational Databases, Analytics, Business Intelligence, Data Quality, Data Storage, Organizational Structure, Big Data, View all skills",
    "instructors": [
      "dave-torgerson"
    ],
    "content": "This course will expose you to the data analytics practices executed in the business world. We will explore such key areas as the analytical process, how data is created, stored, accessed, and how the organization works with data and creates the environment in which analytics can flourish.What you learn in this course will give you a strong foundation in all the areas that support analytics and will help you to better position yourself for success within your organization. You’ll develop skills and a perspective that will make you more productive faster and allow you to become a valuable asset to your organization.\n\nThis course also provides a basis for going deeper into advanced investigative and computational methods, which you have an opportunity to explore in future courses of the Data Analytics for Business specialization."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-business-capstone",
    "name": "Advanced Business Analytics Capstone",
    "what_you_learn": "Create a well-structured and compelling presentation that showcases the most relevant and impactful insights from the analytics project\nCreate a well-structured and compelling presentation that showcases the most relevant and impactful insights from the analytics project\nDesign and customize predictive analytics models for loan classification and loss prediction\nDesign and customize predictive analytics models for loan classification and loss prediction\nDevise investment fund allocation recommendations based on clustering and simulation-based optimization techniques\nDevise investment fund allocation recommendations based on clustering and simulation-based optimization techniques",
    "skills": "Data Storytelling, Statistical Modeling, Data Manipulation, Predictive Analytics, Portfolio Management, Business Analytics, Investment Management, Data Quality, Regression Analysis, Data Transformation, Advanced Analytics, Feature Engineering, Data Presentation, Predictive Modeling, Data Analysis, Data Cleansing, Analytics, Data Processing, Technical Communication, Financial Analysis, View all skills",
    "instructors": [
      "dan-zhang",
      "dave-torgerson",
      "manuel-laguna"
    ],
    "content": "The analytics process is a collection of interrelated activities that lead to better decisions and to a higher business performance. The capstone of this specialization is designed with the goal of allowing you to experience this process. The capstone project will take you from data to analysis and models, and ultimately to presentation of insights.In this capstone project, you will analyze the data on financial loans to help with the investment decisions of an investment company. You will go through all typical steps of a data analytics project, including data understanding and cleanup, data analysis, and presentation of analytical results. \nFor the first week, the goal is to understand the data and prepare the data for analysis. As we discussed  in this specialization, data preprocessing and cleanup is often the first step in data analytics projects. Needless to say, this step is crucial for the success of this project.  \n\nIn the second week, you will perform some predictive analytics tasks, including classifying loans and predicting losses from defaulted loans. You will try a variety of tools and techniques  this week, as the predictive accuracy of different tools can vary quite a bit. It is rarely the case that the default model produced by ASP is the best model possible. Therefore, it is important for you to tune the different models in order to improve the performance.\n\nBeginning in the third week, we turn our attention to prescriptive analytics, where you will provide some concrete suggestions on how to allocate investment funds using analytics tools, including clustering and simulation based optimization. You will see that allocating funds wisely is crucial for the financial return of the investment portfolio.\n\nIn the last week, you are expected to present your analytics results to your clients. Since you will obtain many results in your project, it is important for you to judiciously choose what to include in your presentation. You are also expected to follow the principles we covered in the courses in preparing your presentation."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-course-with-generative-ai",
    "name": "Data Analytics Course with Generative AI",
    "what_you_learn": "Automate ETL workflows and generate synthetic data using GenAI tools\nAutomate ETL workflows and generate synthetic data using GenAI tools\nPerform exploratory data analysis and visualize insights with AI platforms\nPerform exploratory data analysis and visualize insights with AI platforms\nBuild predictive models and conduct risk analysis through simulations\nBuild predictive models and conduct risk analysis through simulations\nApply GenAI across real-world analytics projects for strategic impact\nApply GenAI across real-world analytics projects for strategic impact",
    "skills": "Data Integration, Risk Analysis, Predictive Modeling, Data Analysis, Predictive Analytics, Data Visualization, Data Modeling, Extract, Transform, Load, Forecasting, Data-Driven Decision-Making, Exploratory Data Analysis, Analytics, Descriptive Analytics, Generative AI, Data Transformation, View all skills",
    "instructors": [
      "~176758635"
    ],
    "content": "This comprehensive Generative AI in Data Analytics course equips you with the skills to optimize data workflows, automate analysis, and generate actionable insights using AI. Begin by mastering the four types of analytics, descriptive, diagnostic, predictive, and prescriptive, and explore how GenAI enhances each stage. Learn to automate ETL processes, generate synthetic data with tools like ChatGPT-4 and MOSTLY AI, and perform EDA using Julius AI and Tableau Pulse. Progress to building predictive models, forecasting trends, and conducting risk analysis through real-world simulations. Understand performance metrics, address integration challenges, and apply GenAI in practical business scenarios.You should have a basic understanding of data analysis, statistics, and familiarity with tools like Excel, SQL, or BI platforms.\n\nBy the end of this course, you will be able to:\n\n- Automate Data: Streamline ETL and generate synthetic data using GenAI\n- Analyze Insights: Perform EDA and visualize data with AI-powered tools\n- Predict Outcomes: Build models and simulate risk for better decisions\n- Apply GenAI: Use GenAI across real-world analytics with measurable impact\n\nIdeal for analysts, data professionals, and business leaders advancing data strategy with AI."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-for-lean-six-sigma",
    "name": "Data Analytics for Lean Six Sigma",
    "what_you_learn": "",
    "skills": "Statistics, Statistical Hypothesis Testing, Descriptive Statistics, Variance Analysis, Regression Analysis, Statistical Analysis, Correlation Analysis, Lean Six Sigma, Probability Distribution, Process Improvement, Data Visualization Software, Minitab, Data Analysis, View all skills",
    "instructors": [
      "inez-zwetsloot"
    ],
    "content": "Welcome to this course on Data Analytics for Lean Six Sigma.In this course you will learn data analytics techniques that are typically useful within Lean Six Sigma improvement projects. At the end of this course you are able to analyse and interpret data gathered within such a project. You will be able to use Minitab to analyse the data. I will also briefly explain what Lean Six Sigma is.\n\nI will emphasize on use of data analytics tools and the interpretation of the outcome. I will use many different examples from actual Lean Six Sigma projects to illustrate all tools. I will not discuss any mathematical background. \n\nThe setting we chose for our data example is a Lean Six Sigma improvement project. However data analytics tools are very widely applicable. So you will find that you will learn techniques that you can use in a broader setting apart from improvement projects. \n\nI hope that you enjoy this course and good luck!\nDr. Inez Zwetsloot & the IBIS UvA team"
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-foundations",
    "name": "Data Analytics Foundations",
    "what_you_learn": "",
    "skills": "Data Visualization Software, Data Literacy, Business Analysis, Data Storytelling, Google Sheets, Large Language Modeling, Trend Analysis, Data-Driven Decision-Making, Exploratory Data Analysis, Data Visualization, Requirements Analysis, Spreadsheet Software, Analytics, Data Analysis, View all skills",
    "instructors": [
      "seanbarnes"
    ],
    "content": "In this course, you’ll learn to harness the volume & complexity of information to help businesses make better decisions. This is data analytics, and it powers insights across almost every industry, even ones you might not think of: from fashion and government, to tech, sports and healthcare.This course is the first in a series designed to prepare you for an entry level data analyst role. You don’t need any prior experience with analytics software, programming, or even data to succeed in this course.\n\nWhether you’re looking to start a career in data analytics or level up in your current role, this course is for you. It’s designed to take you from no prior experience to leading your own end to end projects. And, if you’re already working as a data analyst or in a similar role, you’ll find new strategies and insights to continue growing in your career. \n\nStarting out, you’ll learn what data is & the many forms it can take. Then, you’ll get hands on with spreadsheets, a powerful tool for analyzing and visualizing data. You’ll explore real-world datasets throughout the video demos and the interactive labs, including hotel bookings, baby names, and home sales. Finally, you’ll learn a structured approach for data analytics projects that works across industries.\n\nPlus, throughout this course, you’ll get hands-on with large language models, which are changing the nature of work. They are not a replacement for your perspective, but they can augment your skills, serving as a thought partner for your practice. In this course, you’ll use LLMs to interpret data visualizations, run analyses, and more.\n\nData analytics is both analytical and creative. While you will crunch numbers, and that’s fun in its own right, you’ll also craft compelling stories to inspire action. You’ll discover new things every day, work with people from all backgrounds, and see the real world impacts of your expertise."
  },
  {
    "url": "https://www.coursera.org/learn/data-analytics-introduction",
    "name": "Introduction to Data Analytics",
    "what_you_learn": "Apply the data analysis process OSEMN to marketing data\nApply the data analysis process OSEMN to marketing data\nCompare and contrast various data formats and their applications across different scenarios\nCompare and contrast various data formats and their applications across different scenarios\nIdentify data gaps and articulate the strengths and weaknesses of collected data\nIdentify data gaps and articulate the strengths and weaknesses of collected data",
    "skills": "Generative AI, Analytical Skills, Data Literacy, Exploratory Data Analysis, Data Collection, Key Performance Indicators (KPIs), Data Modeling, Data Cleansing, Data Quality, Data Visualization, Data Management, Business Metrics, Analytics, Business Analysis, Data Storytelling, Data Manipulation, Data Analysis, Marketing, View all skills",
    "instructors": [
      "anke"
    ],
    "content": "This course provides a practical understanding and framework for basic analytics tasks, including data extraction, cleaning, manipulation, and analysis. It introduces the OSEMN cycle for managing analytics projects and you'll examine real-world examples of how companies use data insights to improve decision-making.By the end of this course you will be able to:\n• Formulate business goals, KPIs and associated metrics\n• Apply a data analysis process using the OSEMN framework\n• Identify and define the relevant data to be collected for marketing\n• Compare and contrast various data formats and their applications across different scenarios\n• Identify data gaps and articulate the strengths and weaknesses of collected data\n\nYou don't need marketing or data analysis experience, but should have basic internet navigation skills and be eager to participate. Ideally you have already completed course 1: Marketing Analytics Foundation in this program."
  },
  {
    "url": "https://www.coursera.org/learn/data-and-business-process-modeling-with-microsoft-visio",
    "name": "Data and Business Process Modeling with Microsoft Visio",
    "what_you_learn": "Learn to identify and navigate the user interface of Microsoft Visio.\nLearn to identify and navigate the user interface of Microsoft Visio.\nGain insight into how to use Microsoft Visio for creating diagrams effectively.\nGain insight into how to use Microsoft Visio for creating diagrams effectively.\nComprehend business process and data modeling roles in analysis, applying concepts via Microsoft Visio models.\nComprehend business process and data modeling roles in analysis, applying concepts via Microsoft Visio models.",
    "skills": "Process Mapping, Business Process Modeling, Microsoft Visio, Business Analysis, Data Modeling, Business Process, Process Flow Diagrams, Dataflow",
    "instructors": [
      "microsoft"
    ],
    "content": "This course is designed to equip you with essential skills in business process and data modeling using Microsoft Visio. Throughout this program, you will delve into various facets of business analysis and data modeling. Using Microsoft Visio learners will create insightful business processes and data models, and apply these skills to enhance your capabilities in business analysis.After completing this course, you’ll be able to: \n\n•\tIdentify and navigate the user interface of Microsoft Visio\n•\tExplain how to use Microsoft Visio to create diagrams\n•\tExplain the role of business activity and process modeling in a business analysis context\n•\tCreate business process and activity models in Microsoft Visio\n•\tExplain the role of data modeling in a business analysis context\n•\tCreate data models in Microsoft Visio"
  },
  {
    "url": "https://www.coursera.org/learn/data-and-electronic-health-records",
    "name": "Data and Electronic Health Records",
    "what_you_learn": "",
    "skills": "Patient Registration, Electronic Medical Record, Data Integrity, Data Security, Computerized Physician Order Entry, Practice Management Software, Health Information Management, Health Insurance Portability And Accountability Act (HIPAA) Compliance, Medical Records, Health Informatics, Health Care, Data Quality, Data Analysis, Clinical Documentation, Data Management, View all skills",
    "instructors": [
      "~36923802",
      "~145177945"
    ],
    "content": "Welcome to the Data and EHRs in Ambulatory Healthcare Management course! In this course, you will explore the crucial role of data and electronic health records (EHRs) in the realm of ambulatory healthcare management. This course provides you with a comprehensive understanding of healthcare data basics, data integrity and management, HIPAA regulations, and the utilization of EHRs in various aspects of healthcare operations. This course is designed for those with little to no background in healthcare, and is perfect for beginners and those interested in learning more about this field.By the end of this course, you will have a comprehensive understanding of healthcare data fundamentals, data integrity and management principles, HIPAA regulations, and the utilization of EHRs in ambulatory healthcare management. Start your journey to enhancing your knowledge and skills in leveraging data and EHRs to drive improved patient care, operational efficiency, and data-driven decision-making in ambulatory healthcare settings."
  },
  {
    "url": "https://www.coursera.org/learn/data-architect-capstone-project",
    "name": "Data Architect Capstone Project",
    "what_you_learn": "Gain hands-on experience working with data architecture that you can showcase in your portfolio and talk about in interviews.\nGain hands-on experience working with data architecture that you can showcase in your portfolio and talk about in interviews.\nAnalyze and assess existing data architecture in alignment with business objectives.\nAnalyze and assess existing data architecture in alignment with business objectives.\nImplement data migration and integration solutions, including building data pipelines.\nImplement data migration and integration solutions, including building data pipelines.\nApply data governance and security protocols, ensuring compliance and data protection.\nApply data governance and security protocols, ensuring compliance and data protection.",
    "skills": "Data Integration, Data Migration, Enterprise Architecture, Compliance Management, Case Studies, Data Integrity",
    "instructors": [
      "~75088416",
      "skillup"
    ],
    "content": "Gain practical, real-world experience in data architecture through this hands-on capstone project course, developing skills highly valued by employers.During this course, you’ll apply all that you’ve learned throughout the Data Architecture Professional \nCertificate. As you work through the course, you’ll evaluate, design, migrate, and integrate enterprise data systems through a case study.  \n\nIn the capstone project, you will assess the current data architectures of two organizations, highlighting their strengths and identifying areas for improvement. Based on this analysis, you will design and implement a unified and efficient architecture for the newly merged entity, aligning with business goals. The project includes working with both RDBMS and NoSQL databases and developing ETL pipelines to ensure smooth data integration and flow. Additionally, you will create a data governance plan that addresses regulatory compliance and outlines strategies for data protection.\n\nOverall, this real-world inspired scenario will give you plenty to talk about implementing an architecture and managing a system transition in interviews. \n\nIf you’re keen to add practical experience to your portfolio that employers look for, enroll today!"
  },
  {
    "url": "https://www.coursera.org/learn/data-augmented-technology-assisted-medical-decision-making",
    "name": "Data Augmented Technology Assisted Medical Decision Making",
    "what_you_learn": "Describe the crucial role, strengths, limitations of AI and ML in evidence-based medical decision making\nDescribe the crucial role, strengths, limitations of AI and ML in evidence-based medical decision making\nEvaluate machine learning studies for bias and systematic error to enhance diagnostic decisions.\nEvaluate machine learning studies for bias and systematic error to enhance diagnostic decisions.\nApply the results of machine learning studies and outputs to diagnostic decisions.\nApply the results of machine learning studies and outputs to diagnostic decisions.\nIdentify legal and ethical issues and best practices for AI and ML use in healthcare settings\nIdentify legal and ethical issues and best practices for AI and ML use in healthcare settings",
    "skills": "Clinical Assessment, Artificial Intelligence and Machine Learning (AI/ML), Probability & Statistics, Health Policy, Health Informatics, Diagnostic Tests, Responsible AI, Statistical Methods, Clinical Research, Patient Communication, Health Disparities, Healthcare Industry Knowledge, Healthcare Ethics, View all skills",
    "instructors": [
      "~79709221"
    ],
    "content": "Artificial intelligence (AI) and machine learning (ML) have the potential to increase diagnostic accuracy, decrease diagnostic errors, and improve patient outcomes. The Data Augmented, Technology Assisted Medical Decision Making (DATA-MD) course will teach you how to use AI to augment your diagnostic decision-making. The National Academy of Medicine (NAM) recommends ensuring that clinicians can effectively use technology - including AI -  to improve the diagnostic process. To use these technologies effectively in your clinical practice, you will need to determine when use of AI is appropriate, interpret the outputs of AI, read medical literature about AI, and explain to patients the role that AI plays in their care. In this course, you’ll explore the ethical considerations and potential biases when making medical decisions informed by AI/ML-based technologies. DATA-MD is a one of a kind curriculum designed to provide an introduction to the use of AI in the diagnostic process.This course was created with the needs of medical students, residents, fellows, practicing physicians, advanced practice providers, and registered nurses in mind. Others, like educators, computer programmers, and data scientists, may also find value in the course.\n\nContinuing Medical Education Information:\n\nThis activity is released for CME credit on 07/30/2024 and expires 06/31/2027.\nThe University of Michigan Medical School is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.\nThe University of Michigan Medical School designates this enduring material for a maximum of 3.5 AMA PRA Category 1 Credit(s)™. Physicians should claim only the credit commensurate with the extent of their participation in the activity.\n\nDr. Cornelius James and Jessica Virzi, planner and co-planner for this educational activity, have no relevant financial relationship(s) with ineligible companies to disclose.\n\nMaggie Makar, Benjamin Li, and Nicholson Price, presenters of this educational activity, have no relevant financial relationship(s) with ineligible companies to disclose. Karandeep Singh, presenter for this educational activity, was a consultant for Flatiron Health. The relevant financial relationship listed for this individual has been mitigated. Cheri Breadon and Jessica Virzi are the coordinators for this activity.\n\nAfter this activity, participants will be able to\n-Use AI to augment your diagnostic clinical decision-making\n-Describe the strengths and limitations of AI/ML-based technology in the diagnostic process\n-Interpret statistical measures frequently used to evaluate the performance of ML models\n-Critically appraise studies that include AI/ML and determine the applicability of study results in clinical practice\n\n If you would like to earn CME credit for participating in this course, please review the information, including expected results, presenters, their disclosures, and CME credit at this website prior to beginning the activity: https://umich.cloud-cme.com/course/courseoverview?P=0&EID=61826"
  },
  {
    "url": "https://www.coursera.org/learn/data-center-security-management-with-microsoft-system-center",
    "name": "Data Center Security Management with Microsoft System Center",
    "what_you_learn": "Comprehensive understanding of data center security principles and regulatory compliance requirements\nComprehensive understanding of data center security principles and regulatory compliance requirements\nProficiency in Microsoft System Center Suite functionalities for IT infrastructure management, including configuration and deployment\nProficiency in Microsoft System Center Suite functionalities for IT infrastructure management, including configuration and deployment\nSkills in incident response, threat detection, compliance management, and integration of security into DevOps processes\nSkills in incident response, threat detection, compliance management, and integration of security into DevOps processes",
    "skills": "Microsoft Servers, Incident Response, Virtual Machines, Threat Detection, Data Centers, System Monitoring, IT Infrastructure, IT Automation, Security Testing, Security Management, Disaster Recovery, Windows Servers, Configuration Management, Security Information and Event Management (SIEM), Information Systems Security, DevSecOps, Payment Card Industry (PCI) Data Security Standards, View all skills",
    "instructors": [
      "~136048342"
    ],
    "content": "This comprehensive course equips learners with a deep understanding of modern security principles and practices within IT infrastructure management. Participants explore critical modules covering data center security, compliance management, incident response, and DevSecOps integration. Through theoretical knowledge and practical exercises, learners develop proficiency in designing, implementing, and managing secure IT infrastructures while ensuring regulatory compliance. By course completion, participants possess the skills and expertise necessary to secure, monitor, and maintain robust IT environments against evolving cybersecurity threats.Learning Outcomes:\n\n1) Gain a comprehensive understanding of data center security management principles, including Microsoft Security Management Systems.\n2) Develop proficiency in identifying and mitigating common security threats affecting data centers.\n3) Understand regulatory and compliance requirements governing data center security practices.\n4) Master Microsoft System Center Suite functionalities for IT infrastructure management.\n5) Implement data center security policies using Microsoft System Center Suite.\n6) Acquire skills in incident response, remediation strategies, and real-time threat detection.\n7) Learn security monitoring fundamentals and advanced techniques for proactive threat mitigation.\n8) Design effective security architectures and respond effectively to security incidents.\n9) Understand compliance frameworks and standards such as PCI DSS and HIPAA.\n10) Configure compliance policies with System Center Configuration Manager (SCCM).\n11) Prepare for audits, conduct internal security audits, and manage audit responses effectively.\n12) Explore automation and DevSecOps principles for enhancing security in development processes.\n\nUnique Features:\n1) In-depth coverage of Microsoft System Center Suite functionalities.\n2) Emphasis on real-world application and industry-relevant skills.\n3) Comprehensive exploration of compliance management and audit preparation.\n4) Integration of automation and DevSecOps principles for enhanced security practices.\n\nTarget Learners:\n1) IT professionals involved in data center management and security.\n2) Security analysts, administrators, and architects.\n3) Compliance officers and auditors.\n4) DevOps engineers and developers.\n\nPre-requisites:\n1) Basic understanding of IT infrastructure and security concepts.\n2) Familiarity with Microsoft System Center Suite is beneficial but not mandatory."
  },
  {
    "url": "https://www.coursera.org/learn/data-cleaning",
    "name": "Getting and Cleaning Data",
    "what_you_learn": "Understand common data storage systems\nUnderstand common data storage systems\nApply data cleaning basics to make data \"tidy\"\nApply data cleaning basics to make data \"tidy\"\nUse R for text and date manipulation\nUse R for text and date manipulation\nObtain usable data from the web, APIs, and databases\nObtain usable data from the web, APIs, and databases",
    "skills": "Data Manipulation, Data Management, MySQL, Data Cleansing, Data Wrangling, Web Scraping, Data Collection, SQL, Application Programming Interface (API), Data Import/Export, R Programming",
    "instructors": [
      "~694443",
      "rdpeng",
      "~688901"
    ],
    "content": "Before you can work with data you have to get some. This course will cover the basic ways that data can be obtained. The course will cover obtaining data from the web, from APIs, from databases and from colleagues in various formats. It will also cover the basics of data cleaning and how to make data “tidy”. Tidy data dramatically speed downstream data analysis tasks. The course will also cover the components of a complete data set including raw data, processing instructions, codebooks, and processed data. The course will cover the basics needed for collecting, cleaning, and sharing data."
  },
  {
    "url": "https://www.coursera.org/learn/data-cleaning-and-processing-with-copilot-in-excel",
    "name": "Data Cleaning & Processing with Copilot in Excel",
    "what_you_learn": "Identify and address common data errors using Copilot in Excel.\nIdentify and address common data errors using Copilot in Excel.\nApply comprehensive data cleaning techniques to prepare datasets for analysis.\nApply comprehensive data cleaning techniques to prepare datasets for analysis.\nManipulate and transform data efficiently with Copilot.\nManipulate and transform data efficiently with Copilot.\nImplement data organization strategies for improved analysis readiness.\nImplement data organization strategies for improved analysis readiness.",
    "skills": "Data Validation, Data Integrity, Data Processing, Excel Formulas, Data Manipulation, Data Wrangling, Microsoft Copilot, Microsoft Excel, Data Quality, Data Cleansing, Data Transformation, Data Analysis, Prompt Engineering, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course focuses on data cleaning and processing using Copilot in Excel. It empowers you to identify and correct data errors, handle missing values and duplicates, and standardize data types. You will explore advanced text manipulation, column operations, and external data integration, leveraging Copilot for efficient data transformation. Additionally, you will design structured data workflows by developing effective prompts for Copilot, enabling you to pose clear questions that guide your analysis. Through practical modules, you’ll develop skills in data organization, error identification, and cleaning strategies. By the end of this course, you will enhance data accuracy and reliability, ensuring your datasets are analysis-ready. Elevate your data processing capabilities and gain a competitive edge in data-driven decision-making.By the end of the course, you’ll be able to:\n- Identify and address common data errors using Copilot in Excel.\n- Apply comprehensive data cleaning techniques to prepare datasets for analysis.\n- Manipulate and transform data efficiently with Copilot.\n- Implement data organization strategies for improved analysis readiness.\n\nTools you’ll use:\n- Microsoft Excel\n- Copilot in Excel\n\nRequired Course Materials: A Copilot license is required to complete this course. If you don’t have a Microsoft 365 Personal or Family license, you can start a free 30-day trial using the link provided in the course."
  },
  {
    "url": "https://www.coursera.org/learn/data-collection-framework",
    "name": "Framework for Data Collection and Analysis",
    "what_you_learn": "",
    "skills": "Data Analysis, Data Validation, Surveys, Data Quality, Sampling (Statistics), Big Data, Data Collection, Statistical Methods, Research Design",
    "instructors": [
      "~11399392",
      "fkreuter"
    ],
    "content": "This course will provide you with an overview over existing data products and a good understanding of the data collection landscape. With the help of various examples you will learn how to identify which data sources likely matches your research question, how to turn your research question into measurable pieces, and how to think about an analysis plan. Furthermore this course will provide you with a general framework that allows you to not only understand each step required for a successful data collection and analysis, but also help you to identify errors associated with different data sources. You will learn some metrics to quantify each potential error, and thus you will have tools at hand to describe the quality of a data source. Finally we will introduce different large scale data collection efforts done by private industry and government agencies, and review the learned concepts through these examples. This course is suitable for beginners as well as those that know about one particular data source, but not others, and are looking for a general framework to evaluate data products."
  },
  {
    "url": "https://www.coursera.org/learn/data-collection-methods",
    "name": "Data Collection: Online, Telephone and Face-to-face",
    "what_you_learn": "Appricate and compare the pros and cons of self-administered modes and interviews\nAppricate and compare the pros and cons of self-administered modes and interviews\nExplore the emerging modes and data sources such as mobile web surveys and social media data\nExplore the emerging modes and data sources such as mobile web surveys and social media data\nUnderstand  the key concepts about survey data collection methods\nUnderstand  the key concepts about survey data collection methods",
    "skills": "Qualitative Research, Surveys, Unstructured Data, Text Mining, Research Methodologies, Sampling (Statistics), Interviewing Skills, Data Collection, Data Validation, Data Quality",
    "instructors": [
      "fredconrad"
    ],
    "content": "This course presents research conducted to increase our understanding of how data collection decisions affect survey errors. This is not a “how–to-do-it” course on data collection, but instead reviews the literature on survey design decisions and data quality in order to sensitize learners to how alternative survey designs might impact the data obtained from those surveys.The course reviews a range of survey data collection methods that are both interview-based (face-to-face and telephone) and self-administered (paper questionnaires that are mailed and those that are implemented online, i.e. as web surveys). Mixed mode designs are also covered as well as several hybrid modes for collecting sensitive information e.g., self-administering the sensitive questions in what is otherwise a face-to-face interview. The course also covers newer methods such as mobile web and SMS (text message) interviews, and examines alternative data sources such as social media. It concentrates on the impact these techniques have on the quality of survey data, including error from measurement, nonresponse, and coverage, and assesses the tradeoffs between these error sources when researchers choose a mode or survey design."
  },
  {
    "url": "https://www.coursera.org/learn/data-collection-processing-python",
    "name": "Data Collection and Processing with Python",
    "what_you_learn": "Fetch and process data from Internet services effectively.\nFetch and process data from Internet services effectively.\nMaster Python list comprehensions for data extraction and processing.\nMaster Python list comprehensions for data extraction and processing.\nUtilize the Python requests module to interact with REST APIs and navigate API documentation.\nUtilize the Python requests module to interact with REST APIs and navigate API documentation.",
    "skills": "Data Collection, Data Transformation, Restful API, Web Scraping, Data Structures, Python Programming, Application Programming Interface (API), Data Manipulation, Data Processing, JSON",
    "instructors": [
      "presnick"
    ],
    "content": "This course teaches you to fetch and process data from services on the Internet. It covers Python list comprehensions and provides opportunities to practice extracting from and processing deeply nested data. You'll also learn how to use the Python requests module to interact with REST APIs and what to look for in documentation of those APIs. For the final project, you will construct a “tag recommender” for the flickr photo sharing site.The course is well-suited for you if you have already taken the \"Python Basics\" and \"Python Functions, Files, and Dictionaries\" courses (courses 1 and 2 of the Python 3 Programming Specialization). If you are already familiar with Python fundamentals but want practice at retrieving and processing complex nested data from Internet services, you can also benefit from this course without taking the previous two.\n\nThis is the third of five courses in the Python 3 Programming Specialization."
  },
  {
    "url": "https://www.coursera.org/learn/data-cybersecurity",
    "name": "Data & Cybersecurity",
    "what_you_learn": "Conocerás los riesgos de la era digital y cómo las personas u organizaciones podemos evitar incidentes de seguridad (o minimizar sus consecuencias).\nConocerás los riesgos de la era digital y cómo las personas u organizaciones podemos evitar incidentes de seguridad (o minimizar sus consecuencias).",
    "skills": "Data Analysis, Cyber Operations, Security Information and Event Management (SIEM), Authentications, Data Security, Data Science, Time Series Analysis and Forecasting, Data Processing, Anomaly Detection, Cyber Attacks, Crisis Management, Security Awareness, Cybersecurity, Incident Management, View all skills",
    "instructors": [
      "~103719571"
    ],
    "content": "Como integrantes del mundo empresarial, los especialistas en el tratamiento de datos suelen ser uno de los principales objetivos de un ciberataque, ya que tienen acceso a información confidencial de una empresa. Aunque sean conocedores de los riesgos a los que están sometidas las organizaciones en las que trabajan, es importante tener un amplio y consolidado conocimiento en materia de ciberseguridad para poder prevenir los ataques; y en el caso de que ocurran, mitigar los riesgos que afecten a la seguridad, reduciendo en la medida de lo posible su alcance.Por ello, en este curso trataremos las temáticas más relevantes en el ámbito de la ciberseguridad que debes conocer. Desde los riesgos a los que estamos expuestos, pasando por la importancia de la securización de las operaciones y hasta cómo las organizaciones deben gestionar las crisis de seguridad, sin olvidarnos de la gestión de los incidentes y del fraude. También veremos qué son las tecnologías de gestión de eventos e información de seguridad (SIEM) y profundizaremos en las funciones que desempeña un científico de datos en distintas áreas, como el tratamiento de logs, la detección de anomalías y las series temporales. \n\nAnímate a adentrarte en el mundo de la ciberseguridad de la mano de este curso diseñado especialmente para especialistas en el tratamiento de datos. ¡Adelante!"
  },
  {
    "url": "https://www.coursera.org/learn/data-driven-decision-making",
    "name": "Data Driven Decision Making",
    "what_you_learn": "Analyze data to answer business and engineering questions.\nAnalyze data to answer business and engineering questions.\nPerform statistical tests to determine changes and differences.\nPerform statistical tests to determine changes and differences.\nPerform statistical tests to determine relationships.\nPerform statistical tests to determine relationships.",
    "skills": "Correlation Analysis, Variance Analysis, Statistical Analysis, Data Analysis, Statistical Inference, Engineering Management, Data Visualization, Statistical Hypothesis Testing, Statistical Visualization, Descriptive Statistics, Analytics, Probability & Statistics, Regression Analysis, Statistical Software, R (Software), View all skills",
    "instructors": [
      "~8162272"
    ],
    "content": "Once we have generated data, we need to answer the research question by performing an appropriate statistical analysis. Engineers and business professionals need to know which test or tests to use. Through this class, you will be able to perform one sample tests for comparison to historical data. You will also be able to determine statistically significant relationships between two variables. You will be able to perform two sample tests for both independent and dependent data. Finally, you will analyze data with more than two groups using the Analysis of Variance.This course can be taken for academic credit as part of CU Boulder’s Master of Engineering in Engineering Management (ME-EM) degree offered on the Coursera platform. The ME-EM is designed to help engineers, scientists, and technical professionals move into leadership and management roles in the engineering and technical sectors. With performance-based admissions and no application process, the ME-EM is ideal for individuals with a broad range of undergraduate education and/or professional experience. Learn more about the ME-EM program at https://www.coursera.org/degrees/me-engineering-management-boulder."
  },
  {
    "url": "https://www.coursera.org/learn/data-ecosystem",
    "name": "Data Ecosystem",
    "what_you_learn": "Describe the purpose and applications of tabular data, databases, data warehouses, data lakes, and ETLs.\nDescribe the purpose and applications of tabular data, databases, data warehouses, data lakes, and ETLs.\nDescribe the importance of data quality and data governance in relation to data management.\nDescribe the importance of data quality and data governance in relation to data management.\nIdentify the principles that form the foundation of modern data architecture.\nIdentify the principles that form the foundation of modern data architecture.",
    "skills": "Business Intelligence, Extract, Transform, Load, Tableau Software, Data Storage, Data Management, Data Ethics, Databases, Spreadsheet Software, Data Architecture, Data Warehousing, Data Quality, Data Integrity, Data Literacy, Data Governance, Data Modeling, Data Lakes, Database Management, Data Infrastructure, Relational Databases, View all skills",
    "instructors": [
      "~136272031"
    ],
    "content": "The Data Ecosystem course will give you a foundational understanding of the entire data ecosystem, including data management. Specifically, this course shows how a business intelligence analyst would organize, access, and use data. You will learn about a variety of data sources along with the use and purpose of each type. Additionally, you’ll learn about the importance of data quality and data governance in relation to effective data management. You’ll also learn about the goals of data management and the principles that form the foundation of modern data architecture. Having a solid understanding of the data ecosystem is important for entry-level roles in business analytics.This course is for anyone who is curious about entry-level roles that demand fundamental Tableau skills, such as business intelligence analyst or data reporting analyst roles. It is recommended (but not required) that you have some experience with Tableau Public, but even if you're new to Tableau Public, you can still be successful in this program.\n\nBy the end of the course, you will be able to:\n-Describe the purpose and applications of tabular data, databases, data warehouses, data lakes, and ETLs.\n-Describe the importance of data quality and data governance in relation to data management.\n-Identify the goals of data management.\n-Identify the principles that form the foundation of modern data architecture."
  },
  {
    "url": "https://www.coursera.org/learn/data-engineering-career-guide-and-interview-preparation",
    "name": "Data Engineering Career Guide and Interview Preparation",
    "what_you_learn": "Describe the role of a data engineer and some career path options as well as the prospective opportunities in the field.\nDescribe the role of a data engineer and some career path options as well as the prospective opportunities in the field.\nExplain how to build a foundation for a job search, including researching job listings, writing a resume, and making a portfolio of work.\nExplain how to build a foundation for a job search, including researching job listings, writing a resume, and making a portfolio of work.\nSummarize what a candidate can expect during a typical job interview cycle, different types of interviews, and how to prepare for interviews.\nSummarize what a candidate can expect during a typical job interview cycle, different types of interviews, and how to prepare for interviews.\nExplain how to give an effective interview, including techniques for answering questions and how to make a professional personal presentation.\nExplain how to give an effective interview, including techniques for answering questions and how to make a professional personal presentation.",
    "skills": "Data Ethics, LinkedIn, Interviewing Skills, Communication Strategies, Verbal Communication Skills, Data Infrastructure, Professional Development, Data Pipelines, Data Strategy, Technical Communication, Professional Networking, View all skills",
    "instructors": [
      "ibm-skills-network"
    ],
    "content": "This course is designed to prepare you to enter the job market as a data engineer. It provides guidance about the regular functions and tasks of data engineers and their place in the data ecosystem, as well as the opportunities of the profession and some options for career development. It explains practical techniques for creating essential job-seeking materials such as a resume and a portfolio, as well as auxiliary tools like a cover letter and an elevator pitch. You will learn how to find and assess prospective job positions, apply to them, and lay the groundwork for interviewing. You will also get inside tips and steps you can use to perform professionally and effectively at interviews. Let seasoned professionals share their experience to help you get ahead of the competition."
  },
  {
    "url": "https://www.coursera.org/learn/data-engineering-pipelines-etl-hadoop",
    "name": "Data Engineering: Pipelines, ETL, Hadoop",
    "what_you_learn": "Analyse the architecture and components of data pipelines to understand their impact on data flow and processing efficiency.\nAnalyse the architecture and components of data pipelines to understand their impact on data flow and processing efficiency.\nImplement robust ETL processes, for scalability and maintainability.\nImplement robust ETL processes, for scalability and maintainability.\nAnalyze big data challenges and introduce Hadoop ecosystem tools (HDFS, MapReduce, Hive, Pig, and Spark) for data processing tasks.\nAnalyze big data challenges and introduce Hadoop ecosystem tools (HDFS, MapReduce, Hive, Pig, and Spark) for data processing tasks.",
    "skills": "Data Strategy, Apache Spark, Data Quality, Apache Hadoop, Data Transformation, Big Data, Data Processing, Data Warehousing, Strategic Decision-Making, Data Integration, Data Management, Apache Hive, Scalability, Data Analysis, Data Pipelines, Data Migration, Business Analytics, Extract, Transform, Load, View all skills",
    "instructors": [
      "~141793623",
      "~148913851"
    ],
    "content": "This course provides a comprehensive guide to mastering data engineering, where you'll learn to build robust data pipelines, delve into ETL (Extract, Transform, Load) processes, and handle large datasets using Hadoop. You will gain expertise in extracting data from various sources, transforming it into a usable format, and loading it into data warehouses or big data platforms. With hands-on experience in Hadoop, the industry-standard framework for handling massive datasets, you’ll learn to manage and process massive datasets efficiently. Whether you're a beginner or an experienced professional, this course equips you with the skills to design, implement, and manage data pipelines, making you a valuable asset in any data-focused organization.This course is ideal for aspiring data engineers, software developers interested in data processing, and IT professionals looking to expand their expertise into data engineering. It is also suitable for business analysts and other professionals who seek a foundational understanding of data handling technologies to improve decision-making capabilities and enhance their roles in data-driven environments. Whether you are just starting your journey in data engineering or looking to strengthen your existing skills, this course will provide the knowledge and tools you need to succeed.\n\nTo get the most out of this course, you should have a basic understanding of programming concepts and some familiarity with database systems. A foundational knowledge of Python programming and SQL will be helpful, as will an understanding of relational database systems. No prior experience with Hadoop is required, but a keen interest in big data and data analytics will greatly enhance your learning experience.\n\nBy the end of this course, you will be able to analyze the architecture and components of data pipelines and understand their impact on data flow and processing efficiency. You will learn how to implement robust ETL processes that are scalable and maintainable, and you will be equipped to handle big data challenges using Hadoop’s ecosystem tools, such as HDFS, MapReduce, Hive, Pig, and Spark. This course will prepare you to design, implement, and manage data solutions that can drive meaningful insights and support strategic decision-making in any organization."
  },
  {
    "url": "https://www.coursera.org/learn/data-engineering-rust",
    "name": "Data Engineering with Rust",
    "what_you_learn": "",
    "skills": "Cloud API, Data Manipulation, Data Pipelines, Data Processing, Rust (Programming Language), Data Structures, Amazon Web Services, Python Programming, Secure Coding, Cryptography, Encryption, Cloud Applications, System Programming, Restful API, Real Time Data, API Gateway, Command-Line Interface, Software Testing, Amazon S3, View all skills",
    "instructors": [
      "~81359500",
      "noahgift"
    ],
    "content": "Are you a data engineer, software developer, or a tech enthusiast with a basic understanding of Rust, seeking to enhance your skills and dive deep into the realm of data engineering with Rust? Or are you a professional from another programming language background, aiming to explore the efficiency, safety, and concurrency features of Rust for data engineering tasks? If so, this course is designed for you.While a fundamental knowledge of Rust is expected, you should ideally be comfortable with the basics of data structures and algorithms, and have a working understanding of databases and data processing. Familiarity with SQL, the command line, and version control with git is advantageous.\n\nThis four-week course focuses on leveraging Rust to create efficient, safe, and concurrent data processing systems. The journey begins with a deep dive into Rust's data structures and collections, followed by exploring Rust's safety and security features in the context of data engineering. In the subsequent week, you'll explore libraries and tools specific to data engineering like Diesel, async, Polars, and Apache Arrow, and learn to interface with data processing systems, REST, gRPC protocols, and AWS SDK for cloud-based data operations. The final week focuses on designing and implementing full-fledged data processing systems using Rust.\n\nBy the end of this course, you will be well-equipped to use Rust for handling large-scale data engineering tasks, solving real-world problems with efficiency and speed. The hands-on labs and projects throughout this course will ensure you gain practical experience, putting your knowledge into action. This course is your gateway to mastering data engineering with Rust, preparing you for the next level in your data engineering journey."
  },
  {
    "url": "https://www.coursera.org/learn/data-engineering-snowflake",
    "name": "Introduction to Modern Data Engineering with Snowflake",
    "what_you_learn": "How to use Snowflake to ingest data at scale, perform data transformations against data, deliver data products, and orchestrate data pipelines\nHow to use Snowflake to ingest data at scale, perform data transformations against data, deliver data products, and orchestrate data pipelines",
    "skills": "Data Engineering, Data Warehousing, Real Time Data, Command-Line Interface, Data Sharing, SQL, Data Processing, Data Integration, Data Pipelines, Extract, Transform, Load, Data Analysis, Stored Procedure, Data Transformation, View all skills",
    "instructors": [
      "~155311909"
    ],
    "content": "This is a technical, hands-on course that teaches learners how to build modern and continuous data pipelines with Snowflake. It focuses specifically on the most practical Snowflake concepts and tools to get learners up and running quickly with building data pipelines.Learners start by learning about the \"Ingestion-Transformation-Delivery\" framework for modern data engineering, and dive deeper into each component of the framework by learning how to:\n\n- Ingest data into Snowflake at scale using a variety of powerful techniques\n\n- Perform data transformations with SQL or Snowpark\n\n- Extend data transformations with user-defined functions, stored procedures, streams, and Snowflake Dynamic Tables\n\n- Deliver valuable data products through Snowflake Marketplace, Streamlit in Snowflake, and Snowflake Native Applications\n\n- Orchestrate pipelines using tasks and DAGs\n\nThroughout the course, learners follow along with the instructor using a combination of Snowflake, Visual Studio Code, GitHub, and the command line. The course is supplemented with readings containing plenty of resources to level up the learner's understanding of specific concepts.\n\nLearners come away understanding how to build end-to-end, continuous data pipelines with Snowflake."
  },
  {
    "url": "https://www.coursera.org/learn/data-enginering-capstone-project",
    "name": "Data Engineering Capstone Project",
    "what_you_learn": "Demonstrate proficiency in skills required for an entry-level data engineering role.\nDemonstrate proficiency in skills required for an entry-level data engineering role.\nDesign and implement various concepts and components in the data engineering lifecycle such as data repositories.\nDesign and implement various concepts and components in the data engineering lifecycle such as data repositories.\nShowcase working knowledge with relational databases, NoSQL data stores, big data engines, data warehouses, and data pipelines.\nShowcase working knowledge with relational databases, NoSQL data stores, big data engines, data warehouses, and data pipelines.\nApply skills in Linux shell scripting, SQL, and Python programming languages to Data Engineering problems.\nApply skills in Linux shell scripting, SQL, and Python programming languages to Data Engineering problems.",
    "skills": "MySQL, Data Infrastructure, PostgreSQL, Apache Spark, Data Architecture, IBM DB2, Data Warehousing, Data Pipelines, IBM Cognos Analytics, Databases, Extract, Transform, Load, Big Data, NoSQL, Relational Databases, SQL, Data Analysis, MongoDB, Applied Machine Learning, Python Programming, Dashboard, View all skills",
    "instructors": [
      "~75088416",
      "ravahuja"
    ],
    "content": "Showcase your skills in this Data Engineering project! In this course you will apply a variety of data engineering skills and techniques you have learned as part of the previous courses in the IBM Data Engineering Professional Certificate.You will demonstrate your knowledge of Data Engineering by assuming the role of a Junior Data Engineer who has recently joined an organization and be presented with a real-world use case that requires architecting and implementing a data analytics platform. \n\nIn this Capstone project you will complete numerous hands-on labs. You will create and query data repositories using relational and NoSQL databases such as MySQL and MongoDB. You’ll also design and populate a data warehouse using PostgreSQL and IBM Db2 and write queries to perform Cube and Rollup operations.  \n\nYou will generate reports from the data in the data warehouse and build a dashboard using Cognos Analytics. You will also show your proficiency in Extract, Transform, and Load (ETL) processes by creating data pipelines for moving data from different repositories. You will perform big data analytics using Apache Spark to make predictions with the help of a machine learning model. \n\nThis course is the final course in the IBM Data Engineering Professional Certificate. It is recommended that you complete all the previous courses in this Professional Certificate before starting this course."
  },
  {
    "url": "https://www.coursera.org/learn/data-entry-in-microsoft-excel",
    "name": "إدخال البيانات في مايكروسوفت إكسل",
    "what_you_learn": "",
    "skills": "Spreadsheet Software, Microsoft Office, Data Import/Export, Data Entry",
    "instructors": [
      "~106946985"
    ],
    "content": "لاستكشاف المزايا المتعددة التي يمتلكها برنامج (Microsoft Excel)، نحتاج في بداية الأمر إلى القيام بإدخال البيانات (Data Entry) المختلفة كي نتمكن من إجراء المعالجات والإعدادات المتعددة كي تظهر بالصورة التي تناسب احتياجاتنا؛ هذا بالإضافة إلى التعرف على الخيارات المختلفة التي يوفرها برنامج (Excel) سواء في المساعدة في الاستكمال التلقائي للبيانات من خلال (Autofill)، أو في إعداد التنسيقات المختلفة لعرض البيانات (Data) بصورة ملائمة ومناسبة.هذه الدورة هي دورة تمهيدية؛ فهي تلقي الضوء على أساسيات الموضوع بشكل عام بهدف التعريف به وبمحاوره الأساسية التي يجب الإلمام بها.\n\nإذا كنت من المهتمين بفهم إدخال البيانات في مايكروسوفت إكسل، أو كان مجال عملك يتطلب توظيف ذلك في سياق عملك، فهذه الدورة ستكون مثالية لإغناء خبرتك وتطوير مهاراتك بشكل فعال ومؤثر.\n\nحيث ستزودك هذه الدورة باطلاع واسع ودقيق على مجموعة من المحاور المتعلقة بهذا الموضوع، مثل: التعرف على أدوات \"البحث واستبدال كلمة أو جملة أو رقم\"، التعرف على تنسيق الأرقام والتاريخ والوقت، التعرف على خيارات \"نسخ وقص ولصق الخلايا\"، إضافة بيانات داخل الخلايا وتعديلها، فهم كيفية استخدام الماوس ولوحة المفاتيح في تحديد الخلايا."
  },
  {
    "url": "https://www.coursera.org/learn/data-extract-transform-and-load-in-power-bi",
    "name": "Data Extract, Transform, and Load in Power BI",
    "what_you_learn": "How to set up a data source and explain and configure storage modes in Power BI.\nHow to set up a data source and explain and configure storage modes in Power BI.\nHow to prepare for data modeling by cleaning and transforming data.\nHow to prepare for data modeling by cleaning and transforming data.\nHow to use profiling tools to identify data anomalies.\nHow to use profiling tools to identify data anomalies.\nHow to reference queries and dataflows and use the Advanced Editor to modify code.\nHow to reference queries and dataflows and use the Advanced Editor to modify code.",
    "skills": "Query Languages, Data Cleansing, Data Modeling, Data Import/Export, Power BI, Data Manipulation, Data Transformation, Data Integration, Data Processing, Data Quality, Data Analysis, Extract, Transform, Load, Data Validation, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you will learn the process of Extract, Transform and Load or ETL. You will identify how to collect data from and configure multiple sources in Power BI and prepare and clean data using Power Query. You’ll also have the opportunity to inspect and analyze ingested data to ensure data integrity.After completing this course, you’ll be able to: \n•\tIdentify, explain and configure multiple data sources in Power BI  \n•\tClean and transform data using Power Query  \n•\tInspect and analyze ingested data to ensure data integrity"
  },
  {
    "url": "https://www.coursera.org/learn/data-for-analysis-with-microsoft-excel",
    "name": "Data for Analysis with Microsoft Excel",
    "what_you_learn": "Create data in Microsoft Excel and prepare it for data analysis.\nCreate data in Microsoft Excel and prepare it for data analysis.\nMake use of common formulas and functions in a worksheet.\nMake use of common formulas and functions in a worksheet.\nPrepare Excel data for analysis in Power BI using functions.\nPrepare Excel data for analysis in Power BI using functions.",
    "skills": "Data Cleansing, Microsoft Excel, Excel Formulas, Data Manipulation, Pivot Tables And Charts, Data Transformation, Power BI, Data Analysis, Data Presentation, Business Mathematics, Timelines, Spreadsheet Software, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you’ll learn how to make use of Excel in business scenarios for data analysis. You’ll also learn how to utilize formulas and functions for data analysis.  Specifically, this course will help you gain knowledge and skills for preparing data for analysis using Microsoft Excel."
  },
  {
    "url": "https://www.coursera.org/learn/data-for-business-analysts-using-microsoft-excel",
    "name": "Data for Business Analysts Using Microsoft Excel",
    "what_you_learn": "Gain insight into the steps involved in preparing data for analysis using Excel functions.\nGain insight into the steps involved in preparing data for analysis using Excel functions.\nLearn to use formulas and functions in Excel for data analysis purposes.\nLearn to use formulas and functions in Excel for data analysis purposes.\nUnderstand how Excel is applied in business scenarios for data analysis and apply these skills to real-world tasks.\nUnderstand how Excel is applied in business scenarios for data analysis and apply these skills to real-world tasks.",
    "skills": "Spreadsheet Software, Data Cleansing, Excel Formulas, Data Manipulation, Data Analysis, Microsoft Excel, Data Presentation, Pivot Tables And Charts, Business Metrics",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you’ll learn how to make use of Excel in business scenarios for data analysis. You’ll also learn how to utilize formulas and functions for data analysis.Specifically, this course will help you gain knowledge and skills for preparing data for analysis using Microsoft Excel and take you one step closer to becoming a Business Analyst. \n\nAfter completing this course, you’ll be able to: \n\n•\tIdentify and explain the steps involved in preparing data for analysis using Excel functions.\n•\tUse formula and functions for Data Analysis\n•\tDescribe how Excel is used in business scenarios for Data Analysis\n•\tApply Excel skills to real-world data preparation tasks."
  },
  {
    "url": "https://www.coursera.org/learn/data-for-effective-policy-making-",
    "name": "Data for Effective Policy Making",
    "what_you_learn": "",
    "skills": "Program Evaluation, Data Quality, Data-Driven Decision-Making, Data Ethics, Policy Development, Research, Statistical Analysis, Data Analysis, Data Collection, Research Design, Surveys, Policy Analysis",
    "instructors": [
      "aleonelli"
    ],
    "content": "In this age of information, data is available everywhere and grows at an exponential rate. How can we make sense of all this data? How do we take advantage of data when making decisions? How do we use data to help us guide the management and planning of our policies?Whether you're a citizen or a policymaker, learning the answers to these questions can benefit you greatly.  \n \nIn this course, you will strengthen your ability to use, understand and interpret data and gain the tools to navigate data, perform and interpret visualizations, and understand the different types of data analysis according to the policy to be implemented.\n\nRelax, it's not a statistics course! However, you will acquire the knowledge necessary to interpret graphs, statistical reports and understand their language. And, most importantly, you will acquire the foundations to be able to base your decisions on verifiable data, beyond intuition."
  },
  {
    "url": "https://www.coursera.org/learn/data-genes-medicine",
    "name": "Big Data, Genes, and Medicine",
    "what_you_learn": "",
    "skills": "Health Informatics, R Programming, Bioinformatics, Molecular Biology, Big Data, Analytics, Network Analysis, Data Processing, Feature Engineering, Statistical Analysis, Unsupervised Learning, Predictive Modeling, Biomedical Technology, Data Mining, View all skills",
    "instructors": [
      "~19890837"
    ],
    "content": "This course distills for you expert knowledge and skills mastered by professionals in Health Big Data Science and Bioinformatics. You will learn exciting facts about the human body biology and chemistry, genetics, and medicine that will be intertwined with the science of Big Data and skills to harness the avalanche of data openly available at your fingertips and which we are just starting to make sense of. We’ll investigate the different steps required to master Big Data analytics on real datasets, including Next Generation Sequencing data, in a healthcare and biological context, from preparing data for analysis to completing the analysis, interpreting the results, visualizing them, and sharing the results.Needless to say, when you master these high-demand skills, you will be well positioned to apply for or move to positions in biomedical data analytics and bioinformatics. No matter what your skill levels are in biomedical or technical areas, you will gain highly valuable new or sharpened skills that will make you stand-out as a professional and want to dive even deeper in biomedical Big Data. It is my hope that this course will spark your interest in the vast possibilities offered by publicly available Big Data to better understand, prevent, and treat diseases."
  },
  {
    "url": "https://www.coursera.org/learn/data-governance-with-databricks-and-aws",
    "name": "Data Governance with Databricks",
    "what_you_learn": "Learn to integrate AWS with Databricks.\nLearn to integrate AWS with Databricks.\nLearn Data Lineage,  Databricks Tags and Data Catalog in Databricks.\nLearn Data Lineage,  Databricks Tags and Data Catalog in Databricks.\nLearn to implement RBAC (Role-Based Access Control) in Databricks.\nLearn to implement RBAC (Role-Based Access Control) in Databricks.",
    "skills": "Data Quality, Extract, Transform, Load, Data Cleansing, Amazon Web Services, Data Architecture, Data Security, Data Warehousing, Role-Based Access Control (RBAC), Metadata Management, Fraud detection, Databricks, Data Pipelines, Data Governance, General Data Protection Regulation (GDPR), Data Lakes, Amazon Redshift, Data Management, Personally Identifiable Information, View all skills",
    "instructors": [
      "~126164860"
    ],
    "content": "Databricks is a cloud-based data engineering tool used to process and transform large amounts of data and explore the data through machine learning models. It combines data warehouses & data lakes into a lakehouse architecture.Data governance is a broad approach that comprises the principles, practices, and tools to manage an organization’s data assets throughout its lifecycle. A data governance strategy allows organizations to make data easily available protecting their data from unauthorized access, and ensuring compliance with regulatory requirements. \n\nThis course provides 4 hours of training videos which are segmented into modules. The course concepts are easy to understand through lab demonstrations. In order to test the understanding of learners, every module includes Assessments in the form of Quizzes and In-Video Questions. A mandatory Graded Questions Quiz is also provided at the end of every module. \n\nCandidate should have hands-on knowledge of the Databricks platform with the basic knowledge of AWS services. This course is tailored for professionals seeking to establish a strong foundation in data governance, fraud detection, and prevention strategies. By the end of this course, you will be able to:\n-Understand the benefits and features of Databricks on AWS. \n-Demonstrate Data Cleansing Pipelines in Databricks.\n-Analyze Data Access Control Models and Data Privacy Regulations.\n-Elaborate Data Lineage and Data Versions in Databricks Pipelines"
  },
  {
    "url": "https://www.coursera.org/learn/data-integration-storage-migration-strategies",
    "name": "Data Integration, Data Storage, & Data Migration",
    "what_you_learn": "Build valuable applied data storage, integration, and migration skills employers need.\nBuild valuable applied data storage, integration, and migration skills employers need.\nGain hands-on experience using industry-specific data tools.\nGain hands-on experience using industry-specific data tools.\nDemonstrate you understand data-related best practices and can apply methodologies through industry-standard processes.\nDemonstrate you understand data-related best practices and can apply methodologies through industry-standard processes.\nShowcase your ability to solve problems related to data processes that you can talk about in interviews.\nShowcase your ability to solve problems related to data processes that you can talk about in interviews.",
    "skills": "Data Migration, Extract, Transform, Load, Cloud Storage, Data Architecture, Data Pipelines, Data Infrastructure, Data Storage, Disaster Recovery, Data Integration, Data Management, Data Security",
    "instructors": [
      "skillup"
    ],
    "content": "Data integration, data storage, and data migration are core skills for a data professionals. With data management projected to grow by 140% by 2030 (IoT Analytics), these skills are in hot demand! As part of the IBM Data Manager Professional Certificate, this Data Integration, Data Storage, and Data Migration Strategies gives aspiring data managers the essential skills employers are looking for.During this course, you’ll learn best practices and processes in these three key areas—data integration, storage, and migration. You’ll investigate data integration and automate  data aggregation from disparate sources into a single view to make it useful for analysis. You’ll explore data storage methods and processes to ensure your data is organized. Plus, you’ll learn data migration processes businesses use to upgrade their legacy systems and infrastructure with minimal disruption to other business operations.  \n\nIf you’re looking to enhance your resume with the essential skills, a data manager needs to catch an employer’s eye, enroll today and boost your career opportunities in just three weeks!"
  },
  {
    "url": "https://www.coursera.org/learn/data-interpretation-and-insight",
    "name": "Data Interpretation & Insights: Exam & Recruitment Prep",
    "what_you_learn": "Solve any Data Interpretation or Data Sufficiency question in competitive tests\nSolve any Data Interpretation or Data Sufficiency question in competitive tests\nAnalyze and compare data quickly with confidence\nAnalyze and compare data quickly with confidence\nApply structured reasoning to interpret business cases or exam scenarios\nApply structured reasoning to interpret business cases or exam scenarios\nSharpen your aptitude scores significantly for test success and job selection\nSharpen your aptitude scores significantly for test success and job selection",
    "skills": "Numerical Analysis, Case Studies, Data Visualization, Data Literacy, Complex Problem Solving, Data Analysis, Analytical Skills, Decision Making, Logical Reasoning, Data-Driven Decision-Making, Deductive Reasoning, Data Presentation, View all skills",
    "instructors": [
      "board-infinity"
    ],
    "content": "Course Overview:Data Interpretation (DI) and logical reasoning are not just exam sections — they’re crucial skills demanded across competitive exams and corporate recruitment tests. This course equips you with the analytical power to decode complex data sets, draw meaningful insights, and make accurate decisions — all within tight time limits.\n\nWhether you're preparing for MBA entrance exams (CAT, XAT, NMAT), banking and government exams (IBPS, SBI PO, SSC), or aptitude rounds of top recruiters, this course ensures you're ready to tackle data-heavy questions with confidence and precision.\n\nWhat You Will Learn:\n- How to interpret and solve problems from tabular, bar, line, and pie charts efficiently\n- Techniques to handle case-based DI scenarios similar to real-world business cases\n- Mastery over Data Sufficiency questions using two or three logical statements\n- Strong grasp of Data Comparison and analytical ranking through numerical reasoning\n\nCourse Structure:\nModule 1: Data Interpretation and Reasoning\nFocuses on building speed and accuracy across core chart types and complex sets:\n- Tabular Charts – Introduction, Easy to Difficult Sets\n- Bar, Line, and Pie Charts – Multiple difficulty levels with progressive learning\n- Case-Based DI – Real-world data scenarios to simulate exam-like environments\n- Data Interpretation - Reading handouts for more practice\n\nModule 2: Data Sufficiency and Reasoning\nDesigned to sharpen decision-making and evaluation skills under uncertainty:\n- Data Sufficiency - Video types covering both two- and three-statement questions\n- Data Sufficiency - Reading handouts for more practice\n\nWho Should Enroll:\n- Students preparing for MBA entrance tests (CAT, XAT, SNAP, MAT, CMAT)\n- Aspirants of government and bank recruitment exams (IBPS PO, SBI Clerk, SSC CGL)\n- Freshers preparing for campus recruitment or aptitude-based job tests\n- Anyone looking to boost their data reasoning and interpretation skills\n\nKey Features:\n- 35+ video lessons progressing from basic to advanced levels\n-Real exam-style DI & DS practice sets\n- Concept explanations + timed-solving strategies\n- Recruitment-relevant question types with expert tips\n- Ideal for non-technical and technical learners alike\n\nOutcome:\nBy the end of this course, you will be able to:\n- Solve any Data Interpretation or Data Sufficiency question in competitive tests\n- Analyze and compare data quickly with confidence\n- Apply structured reasoning to interpret business cases or exam scenarios\n- Sharpen your aptitude scores significantly for test success and job selection\n\nStart today and transform numbers into insights.\nYour preparation for top exams and job roles begins here.\n\nDisclaimer: This is an independent educational resource created by Board Infinity for informational and educational purposes only. This course is not affiliated with, endorsed by, sponsored by, or officially associated with any company, organization, or certification body unless explicitly stated. The content provided is based on industry knowledge and best practices but does not constitute official training material for any specific employer or certification program. All company names, trademarks, service marks, and logos referenced are the property of their respective owners and are used solely for educational identification and comparison purposes."
  },
  {
    "url": "https://www.coursera.org/learn/data-io-and-preprocessing-with-python-and-sql",
    "name": "Data I/O and Preprocessing with Python and SQL",
    "what_you_learn": "You’ll work with real-world data as it exists in practice: messy, unstructured, and spread across sources.\nYou’ll work with real-world data as it exists in practice: messy, unstructured, and spread across sources.\nYou’ll learn to extract data from websites, APIs, and databases, and clean it using both Python and SQL, an essential step in any analysis pipeline.\nYou’ll learn to extract data from websites, APIs, and databases, and clean it using both Python and SQL, an essential step in any analysis pipeline.",
    "skills": "Data Ethics, Data Manipulation, Text Mining, Data Processing, JSON, Unstructured Data, Data Integrity, Pandas (Python Package), Extract, Transform, Load, Application Programming Interface (API), SQL, Generative AI, Data Cleansing, Data Transformation, Data Import/Export, Data Validation, Relational Databases, Web Scraping, View all skills",
    "instructors": [
      "seanbarnes"
    ],
    "content": "Most real-world data isn’t clean, it’s messy, incomplete, and spread across sources like websites, APIs, and databases. In this course, you’ll learn how to collect that data, clean it, and prepare it for analysis using Python and SQL.You’ll start by extracting data from webpages using tools like Pandas and Beautiful Soup, while also learning how to handle unstructured text and apply ethical scraping practices.\n\nNext, you’ll access real-time data through APIs, parse JSON files, and clean numerical data using techniques like normalization and binning. You’ll also learn how to manage authentication with API keys and store them securely.\n\nFinally, you’ll work with databases: Querying and joining tables using SQL, validating results, and understanding when to use SQL versus Python for different preprocessing tasks.\n\nBy the end of the course, you’ll be able to turn raw, real-world data into reliable, analysis-ready inputs—a core skill for any data professional."
  },
  {
    "url": "https://www.coursera.org/learn/data-lakes-data-warehouses-gcp",
    "name": "Modernizing Data Lakes and Data Warehouses with Google Cloud",
    "what_you_learn": "Differentiate between data lakes and data warehouses.\nDifferentiate between data lakes and data warehouses.\nExplore use-cases for each type of storage and the available data lake and warehouse solutions on Google Cloud.\nExplore use-cases for each type of storage and the available data lake and warehouse solutions on Google Cloud.\nDiscuss the role of a data engineer and the benefits of a successful data pipeline to business operations.\nDiscuss the role of a data engineer and the benefits of a successful data pipeline to business operations.\nExamine why data engineering should be done in a cloud environment.\nExamine why data engineering should be done in a cloud environment.",
    "skills": "Data Lakes, Big Data, Cloud Engineering, Scalability, Cloud Storage, Data Infrastructure, Data Warehousing, Data Pipelines, SQL, Google Cloud Platform, Data Processing",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "The two key components of any data pipeline are data lakes and warehouses. This course highlights use-cases for each type of storage and dives into the available data lake and warehouse solutions on Google Cloud in technical detail. Also, this course describes the role of a data engineer, the benefits of a successful data pipeline to business operations, and examines why data engineering should be done in a cloud environment.This is the first course of the Data Engineering on Google Cloud series. After completing this course, enroll in the Building Batch Data Pipelines on Google Cloud course."
  },
  {
    "url": "https://www.coursera.org/learn/data-lakes-data-warehouses-gcp-br",
    "name": "Modernizing Data Lakes and Data Warehouses with GCP em Português Brasileiro",
    "what_you_learn": "Diferenciar data lakes de data warehouses.\nDiferenciar data lakes de data warehouses.\nConhecer os casos de uso para cada tipo de armazenamento e as soluções de data lake e warehouse disponíveis no Google Cloud.\nConhecer os casos de uso para cada tipo de armazenamento e as soluções de data lake e warehouse disponíveis no Google Cloud.\nEntender o papel de um engenheiro de dados e quais os benefícios de um pipeline de dados funcional para as operações comerciais.\nEntender o papel de um engenheiro de dados e quais os benefícios de um pipeline de dados funcional para as operações comerciais.\nAnalisar por que a engenharia de dados deve ser feita em um ambiente na nuvem.\nAnalisar por que a engenharia de dados deve ser feita em um ambiente na nuvem.",
    "skills": "Cloud Solutions, Google Cloud Platform, Data Analysis, Data Lakes, Data Architecture, Data Processing, Data Pipelines, Business Intelligence, SQL, Data Infrastructure, Data Warehousing, Data Transformation, Cloud Storage, View all skills",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "Os dois principais componentes de um pipeline de dados são data lakes e warehouses. Neste curso, destacamos os casos de uso para cada tipo de armazenamento e as soluções de data lake e warehouse disponíveis no Google Cloud de forma detalhada e técnica. Além disso, também descrevemos o papel de um engenheiro de dados, os benefícios de um pipeline de dados funcional para operações comerciais e analisamos por que a engenharia de dados deve ser feita em um ambiente de nuvem.Este é o primeiro curso da série \"\"Data Engineering on Google Cloud\"\". Após a conclusão, recomendamos que você comece o curso \"\"Building Batch Data Pipelines on Google Cloud\"\"."
  },
  {
    "url": "https://www.coursera.org/learn/data-lakes-data-warehouses-gcp-es",
    "name": "Modernizing Data Lakes and Data Warehouses with GCP en Español",
    "what_you_learn": "Distinguir entre data lakes y almacenes de datos.\nDistinguir entre data lakes y almacenes de datos.\nExplorar los casos de uso de cada tipo de almacenamiento y las soluciones de data lakes y almacenes de datos disponibles en Google Cloud.\nExplorar los casos de uso de cada tipo de almacenamiento y las soluciones de data lakes y almacenes de datos disponibles en Google Cloud.\nAnalizar el rol del ingeniero de datos y los beneficios de las canalizaciones de datos exitosas para las operaciones comerciales.\nAnalizar el rol del ingeniero de datos y los beneficios de las canalizaciones de datos exitosas para las operaciones comerciales.\nExaminar por qué la ingeniería de datos se debe realizar en un entorno de nube.\nExaminar por qué la ingeniería de datos se debe realizar en un entorno de nube.",
    "skills": "Data Management, Data Storage Technologies, Data Storage, Cloud Storage, Google Cloud Platform, SQL, Cloud Engineering, Data Lakes, Data Infrastructure, Scalability, Data Warehousing",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "Los dos componentes clave de cualquier canalización de datos son los data lakes y los almacenes de datos. En este curso, se destacan los casos de uso de cada tipo de almacenamiento y se analizan en profundidad las soluciones de data lakes y almacenes disponibles en Google Cloud con detalles técnicos. Además, en este curso, se describen el rol del ingeniero en datos, los beneficios de las canalizaciones de datos exitosas para las operaciones comerciales y por qué la ingeniería de datos debe realizarse en un entorno de nube.Este el primer curso de la serie Data Engineering on Google Cloud. Después de completar este curso, inscríbete en el curso Building Batch Data Pipelines on Google Cloud."
  },
  {
    "url": "https://www.coursera.org/learn/data-lakes-data-warehouses-gcp-jp",
    "name": "Modernizing Data Lakes and Data Warehouses with GCP 日本語版",
    "what_you_learn": "データ パイプラインを構成する 2 つの主要コンポーネントである、データレイクとデータ ウェアハウスの違いを理解する。\nデータ パイプラインを構成する 2 つの主要コンポーネントである、データレイクとデータ ウェアハウスの違いを理解する。\n各ストレージ タイプのユースケースを確認し、Google Cloud で利用可能なデータレイクとデータ ウェアハウスのソリューションについて、技術的な詳細を学習する。\n各ストレージ タイプのユースケースを確認し、Google Cloud で利用可能なデータレイクとデータ ウェアハウスのソリューションについて、技術的な詳細を学習する。\nデータ エンジニアの役割と、効果的なデータパイプラインが事業運営にもたらすメリットについて理解する。\nデータ エンジニアの役割と、効果的なデータパイプラインが事業運営にもたらすメリットについて理解する。\nクラウド環境でデータ エンジニアリングを行うべき理由を確認する。\nクラウド環境でデータ エンジニアリングを行うべき理由を確認する。",
    "skills": "Google Cloud Platform, Data Lakes, Data Architecture, Big Data, Cloud Storage, Cloud Engineering, Data Pipelines, SQL, Data Infrastructure, Scalability, Data Warehousing",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "\"すべてのデータ パイプラインには、データレイクとデータ ウェアハウスという 2 つの主要コンポーネントがあります。このコースでは、各ストレージ タイプのユースケースを紹介し、Google Cloud で利用可能なデータレイクとデータ ウェアハウスのソリューションを技術的に詳しく説明します。また、データ エンジニアの役割や、効果的なデータ パイプラインが事業運営にもたらすメリットについて確認し、クラウド環境でデータ エンジニアリングを行うべき理由を説明します。これは「Data Engineering on Google Cloud」シリーズの最初のコースです。このコースを修了したら、「Building Batch Data Pipelines on Google Cloud」コースに登録してください。\""
  },
  {
    "url": "https://www.coursera.org/learn/data-literacy-capstone-evaluating-research",
    "name": "Data Literacy Capstone – Evaluating Research",
    "what_you_learn": "",
    "skills": "Analytical Skills, Data Analysis, Research, Data Literacy, Research Methodologies, Quantitative Research, Report Writing, Peer Review, Statistical Analysis",
    "instructors": [
      "jennifer-bachner"
    ],
    "content": "This is the final course in the Data Literacy Specialization.  In this capstone course, you'll apply the skills and knowledge you have acquired in the specialization to the critical evaluation of an original quantitative analysis.  The project will first require you to identify and read a piece of high-quality, original, quantitative research on a topic of your choosing.  You’ll then interpret and evaluate the findings as well as the methodological approach.  As part of the project, you’ll also review other students’ submissions.  By the end of the project, you should be empowered to be a critical consumer and user of quantitative research."
  },
  {
    "url": "https://www.coursera.org/learn/data-literacy-what-is-it-and-why-does-it-matter",
    "name": "Data Literacy – What is it and why does it matter?",
    "what_you_learn": "",
    "skills": "Algorithms, Journalism, Information Privacy, Data Ethics, Analytical Skills, Artificial Intelligence and Machine Learning (AI/ML), Law, Regulation, and Compliance, Data Security, Big Data, Data Literacy, Data-Driven Decision-Making, View all skills",
    "instructors": [
      "christian-igel",
      "martin-loebl",
      "sergio-splendore",
      "rasmus-helles",
      "robin-engelhardt",
      "joanna-osiejewicz",
      "morten-misfeldt",
      "irina-shklovski",
      "floriana-gargiulo"
    ],
    "content": "You might already know that data is not neutral. Our values and assumptions are influenced by the data surrounding us - the data we create, the data we collect, and the data we share with each other. Economic needs, social structures, or algorithmic biases can have profound consequences for the way we collect and use data. Most often, the result is an increase of inequity in the world. Data also changes the way we interact. It shapes our thoughts, our feelings, our preferences and actions. It determines what we have access to, and what not. It enables global dissemination of best practices and life improving technologies, as well as the spread of mistrust and radicalization. This is why data literacy matters.A key principle of data literacy is to have a heightened awareness of the risks and opportunities of data-driven technologies and to stay up-to-date with their consequences. In this course, we view data literacy from three perspectives: Data in personal life, data in society, and data in knowledge production.  The aim is threefold: 1. To expand your skills and abilities to identify, understand, and interpret the many roles of digital technologies in daily life. 2. To enable you to discern when data-driven technologies add value to people’s lives, and when they exploit human vulnerabilities or deplete the commons.  3. To cultivate a deeper understanding of how data-driven technologies are shaping knowledge production and how they may be realigned with real human needs and values. \n\nThe course is funded by Erasmus+ and developed by the 4EU+ University Alliance including  Charles University (Univerzita Karlova), Sorbonne Unviersity (Sorbonne Université), University of Copenhagen (Københavns Universitet), University of Milan (Università degli studi di Milano), and University of Warsaw (Uniwersytet Warszawski)."
  },
  {
    "url": "https://www.coursera.org/learn/data-management",
    "name": "Research Data Management and Sharing",
    "what_you_learn": "",
    "skills": "Data Literacy, Data Quality, Data Integrity, Information Management, Data Governance, Document Management, Data Security, Data Sharing, Data Strategy, Metadata Management, Version Control, Data Management, File Management, Data Storage, View all skills",
    "instructors": [
      "~12198831",
      "helen-tibbo"
    ],
    "content": "This course will provide learners with an introduction to research data management and sharing. After completing this course, learners will understand the diversity of data and their management needs across the research data lifecycle, be able to identify the components of good data management plans, and be familiar with best practices for working with data including the organization, documentation, and storage and security of data. Learners will also understand the impetus and importance of archiving and sharing data as well as how to assess the trustworthiness of repositories.Today, an increasing number of funding agencies, journals, and other stakeholders are requiring data producers to share, archive, and plan for the management of their data. In order to respond to these requirements, researchers and information professionals will need the data management and curation knowledge and skills that support the long-term preservation, access, and reuse of data. Effectively managing data can also help optimize research outputs, increase the impact of research, and support open scientific inquiry. After completing this course, learners will be better equipped to manage data throughout the entire research data lifecycle from project planning to the end of the project when data ideally are shared and made available within a trustworthy repository.\n\nThis course was developed by the Curating Research Assets and Data Using Lifecycle Education (CRADLE) Project in collaboration with EDINA at the University of Edinburgh. \n\nThis course was made possible in part by the Institute of Museum and Library Services under award #RE-06-13-0052-13. The views, findings, conclusions or recommendations expressed in this Research Data Management and Sharing MOOC do not necessarily represent those of the Institute of Museum and Library Services.\n\nHashtag: #RDMSmooc"
  },
  {
    "url": "https://www.coursera.org/learn/data-management-and-storage-in-the-cloud",
    "name": "Data Management and Storage in the Cloud",
    "what_you_learn": "Explain how data is defined and structured in BigQuery and Google Cloud Storage.\nExplain how data is defined and structured in BigQuery and Google Cloud Storage.\nIdentify the key components that make up a data lakehouse architecture.\nIdentify the key components that make up a data lakehouse architecture.\nExplain how partitioning can improve query performance and reduce costs.\nExplain how partitioning can improve query performance and reduce costs.\nDefine key components of data governance.\nDefine key components of data governance.",
    "skills": "Data Quality, Database Management, Data Governance, Application Programming Interface (API), NoSQL, Data Management, Cloud Storage, Metadata Management, Data Lakes, Data Architecture, Query Languages, Big Data, Data Warehousing, Data Access, Data Integration, Performance Tuning, Star Schema, View all skills",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "Hi again! This is the second course of the Google Cloud Data Analytics Certificate. Get cozy with the key components of data governance, normalized and star schemas, data catalogs, and data lakehouse architecture."
  },
  {
    "url": "https://www.coursera.org/learn/data-management-capstone-project",
    "name": "Data Management Capstone Project",
    "what_you_learn": "Integrate valuable applied data management skills employers need for a wide range of data-related roles in a culminating project.\nIntegrate valuable applied data management skills employers need for a wide range of data-related roles in a culminating project.\nGain hands-on experience using industry-specific data tools including Excel, SQL, PostgreSQL, Tableau, etc.\nGain hands-on experience using industry-specific data tools including Excel, SQL, PostgreSQL, Tableau, etc.\nDemonstrate best practices and apply those methodologies through industry-standard processes, data design, governance, security, and reporting.\nDemonstrate best practices and apply those methodologies through industry-standard processes, data design, governance, security, and reporting.\nShowcase your ability to solve problems relevant to working with data that you can discuss with colleagues and prospective employers.\nShowcase your ability to solve problems relevant to working with data that you can discuss with colleagues and prospective employers.",
    "skills": "Tableau Software, Microsoft Excel, Data Security, Dashboard, Relational Databases, Data Transformation, Data Management, Data Warehousing, Data Visualization Software, Data Presentation, Data Analysis, MySQL, SQL, Personally Identifiable Information, Database Design, Data Cleansing, Data Visualization, Data Governance, View all skills",
    "instructors": [
      "skillup"
    ],
    "content": "In this capstone course, you’ll demonstrate your ability to solve problems relevant to data-related roles, which you can then showcase in your portfolio and share with prospective employers. You will apply the skills you’ve learned throughout this data management program with this hands-on culminating project.The project provides you the opportunity to solidify your proficiency when working with various aspects of data and integrate them into a single project. You’ll apply many industry-specific tools and industry-standard best practices to a real-world-inspired scenario. As part of this process, you utilize relational databases and SQL queries. You’ll also manipulate data using spreadsheets and BI tools to create visualizations and a dashboard to readily communicate your data insights. \n\nWe recommend that you complete all the previous courses in this Professional Certificate before starting this course."
  },
  {
    "url": "https://www.coursera.org/learn/data-manipulation-and-transactions-in-sql-server",
    "name": "Data Manipulation and Transactions in SQL Server",
    "what_you_learn": "",
    "skills": "SQL, Generative AI, Microsoft SQL Servers, Relational Databases, Transaction Processing, Data Integrity, Database Management, Data Manipulation, Performance Tuning",
    "instructors": [
      "microsoft"
    ],
    "content": "Build on your foundational SQL knowledge by learning data manipulation techniques in SQL Server. This course focuses on using INSERT, UPDATE, and DELETE statements to modify database contents while maintaining data integrity through proper transaction management. You'll learn to implement transaction control mechanisms, understand isolation levels, and prevent common concurrency issues. Through practical examples, you'll implement error handling strategies and explore the principles of ACID compliance essential for reliable database operations. The course also demonstrates how generative AI can help optimize complex SQL operations and troubleshoot transaction issues. By the end, you'll confidently perform data modifications while ensuring database consistency—crucial skills for any database professional."
  },
  {
    "url": "https://www.coursera.org/learn/data-manipulation-in-rpa",
    "name": "Data Manipulation in RPA",
    "what_you_learn": "Variables and Arguments\nVariables and Arguments\nData Manipulation in Studio\nData Manipulation in Studio\nCollection Variables in Studio\nCollection Variables in Studio",
    "skills": "Data Cleansing, Data Management, Automation, Robotic Process Automation, Data Manipulation, Data Integration",
    "instructors": [
      "~124002201"
    ],
    "content": "The Data Manipulation in RPA course will provide knowledge about Variables, Arguments, and Data Manipulation. It will also introduce you to Variables and Arguments, their types, and their application in automation projects.In the later part of the course, you will learn about data manipulation in Studio. You will also learn about the different methods and operations performed on different data types and their usage in automation projects. Building on each concept, there will be demonstration videos that will explain these operations and methods. \n\nThe course has multiple practice exercises that will help strengthen your knowledge and understand the creation of workflows in Studio."
  },
  {
    "url": "https://www.coursera.org/learn/data-mining-in-python",
    "name": "Data Mining in Python",
    "what_you_learn": "Understand basic concepts, tasks, and procedures of data mining.\nUnderstand basic concepts, tasks, and procedures of data mining.\nFormulate real-world information using basic data representations: itemsets, vectors, matrices, sequences, time series, and networks.\nFormulate real-world information using basic data representations: itemsets, vectors, matrices, sequences, time series, and networks.\nUse data mining algorithms to extract patterns and similarities from real-world datasets.\nUse data mining algorithms to extract patterns and similarities from real-world datasets.\nCalculate the importance of patterns and prepare for downstream machine-learning tasks.\nCalculate the importance of patterns and prepare for downstream machine-learning tasks.",
    "skills": "Data Science, Machine Learning Methods, Data Processing, Data Manipulation, Anomaly Detection, Data Mining, Unsupervised Learning, Python Programming",
    "instructors": [
      "~45777986"
    ],
    "content": "In “Data Mining in Python,” you will learn how to extract useful knowledge from large-scale datasets. This course introduces basic concepts and general tasks for data mining. You will explore a wide range of real-world data sets, including grocery store, restaurant reviews, business operations, social media posts, and more.You will learn how to formally describe real-world information with general data representations (e.g., itemsets, vectors, matrices, sequences, and more). You will then learn how to formulate data in the wild with one or more of these representations. \n\nThis course will teach you how to characterize and explain your data by looking for patterns and similarities, which are basic building blocks for advanced analysis and machine learning models. \n\nThis is the first course in “More Applied Data Science with Python,” a four-course series focused on helping you apply advanced data science techniques using Python. It is recommended that all learners complete the Applied Data Science with Python specialization prior to beginning this course."
  },
  {
    "url": "https://www.coursera.org/learn/data-mining-pipeline",
    "name": "Data Mining Pipeline",
    "what_you_learn": "Identify the key components of the data mining pipeline and describe how they're related.\nIdentify the key components of the data mining pipeline and describe how they're related.\nIdentify particular challenges presented by each component of the data mining pipeline.\nIdentify particular challenges presented by each component of the data mining pipeline.\nApply techniques to address challenges in each component of the data mining pipeline.\nApply techniques to address challenges in each component of the data mining pipeline.",
    "skills": "Statistical Modeling, Data Cleansing, Data Pipelines, Data Quality, Data Analysis, Data Warehousing, Data Mining, Data Modeling, Data Science, Data Visualization, Data Transformation, Exploratory Data Analysis, View all skills",
    "instructors": [
      "qin-lv"
    ],
    "content": "This course introduces the key steps involved in the data mining pipeline, including data understanding, data preprocessing, data warehousing, data modeling, interpretation and evaluation, and real-world applications.This course can be taken for academic credit as part of CU Boulder’s MS in Data Science or MS in Computer Science degrees offered on the Coursera platform. These fully accredited graduate degrees offer targeted courses, short 8-week sessions, and pay-as-you-go tuition. Admission is based on performance in three preliminary courses, not academic history. CU degrees on Coursera are ideal for recent graduates or working professionals. Learn more: \n\nMS in Data Science: https://www.coursera.org/degrees/master-of-science-data-science-boulder \n\nMS in Computer Science: https://coursera.org/degrees/ms-computer-science-boulder\n\nCourse logo image courtesy of Francesco Ungaro, available here on Unsplash: https://unsplash.com/photos/C89G61oKDDA"
  },
  {
    "url": "https://www.coursera.org/learn/data-modeling-and-architecture",
    "name": "Data Modeling and Architecture",
    "what_you_learn": "",
    "skills": "Data Governance, Data Quality, Information Privacy, Data Analysis Expressions (DAX), Power BI, Star Schema, Data Architecture, Snowflake Schema, Database Design, Data Security, Data Ethics, Extract, Transform, Load, Data Cleansing, Data Modeling, Data Integrity, Relational Databases, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "Data Modeling and Architecture is designed to provide you with the foundational skills required to create and manage data models in Microsoft Power BI. Throughout this course, you'll explore the intricacies of data relationships, schemas, and the use of Data Analysis Expressions (DAX) to enhance your data models. You'll also explore essential topics like data privacy and security, ensuring that your data models are both effective and compliant with ethical standards. This course is hands-on, offering practical experience in configuring data structures and applying advanced techniques to optimize data models. By the end of this course, you’ll be able to design robust data models that support insightful and ethical data analysis.This program is for anyone interested in data analytics and visualization; there are no prerequisites. To get the most out of the learning experience, it is recommended to follow the courses in sequence, as each one builds on the skills and knowledge gained in the previous ones.  \n\nAt this point, you should have a strong understanding of different types of visualizations and their appropriate use, along with the ability to create cohesive and compelling reports in Power BI. You should also be capable of identifying and addressing common design problems in reports, producing audience-focused reports by understanding business needs.\n\nAdditionally, you should also be comfortable configuring multiple data sources, cleaning and transforming data using Power Query, and ensuring data integrity and quality. These skills will serve as the foundation for more advanced tasks, such as building and maintaining relationships in data models, writing DAX calculations, and managing data privacy and ethics concerns in Power BI."
  },
  {
    "url": "https://www.coursera.org/learn/data-modeling-in-power-bi",
    "name": "Data Modeling in Power BI",
    "what_you_learn": "How to form a model using a Star Schema.\nHow to form a model using a Star Schema.\nHow to write calculations DAX to create elements and analysis in Power BI.\nHow to write calculations DAX to create elements and analysis in Power BI.\nHow to optimize performance in a Power BI model.\nHow to optimize performance in a Power BI model.",
    "skills": "Performance Tuning, Data Transformation, Database Design, Data Visualization, Time Series Analysis and Forecasting, Power BI, Data Analysis, Data Modeling, Star Schema, Data Analysis Expressions (DAX), View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course forms part of the Microsoft Power BI Analyst Professional Certificate. This Professional Certificate consists of a series of courses that offers a good starting point for a career in data analysis using Microsoft Power BI.In this course, you'll learn how to use Power BI to create and maintain relationships in a data model and form a model using multiple Schemas. You'll explore the basics of DAX, Power BI's expression language, and add calculations to your model to create elements and analysis in Power BI. You'll discover how to configure the model to support Power BI features for insightful visualizations, analysis, and optimization. \n\nAfter completing this course you'll be able to:\n\n●\tCreate and maintain relationships in a data model.  \n●\tForm a model using a Star Schema  \n●\tWrite calculations DAX to create elements and analysis in Power BI \n●\tCreate calculated columns and measures in a model \n●\tPerform useful time intelligence calculations in DAX \n●\tOptimize performance in a Power BI model  \n\nThis is also a great way to prepare for the Microsoft PL-300 exam. By passing the PL-300 exam, you’ll earn the Microsoft Power BI Data Analyst certification."
  },
  {
    "url": "https://www.coursera.org/learn/data-modeling-transformation-serving",
    "name": "Data Modeling, Transformation, and Serving",
    "what_you_learn": "Model and transform data based on stakeholder needs to deliver business value\nModel and transform data based on stakeholder needs to deliver business value\nChoose the appropriate data processing tools for your architecture design\nChoose the appropriate data processing tools for your architecture design\nProcess data for batch analytics and machine learning data pipelines using distributed and non-distributed processing frameworks\nProcess data for batch analytics and machine learning data pipelines using distributed and non-distributed processing frameworks",
    "skills": "Data Integrity, Feature Engineering, Data Transformation, Data Processing, Data Modeling, Extract, Transform, Load, Star Schema, Text Mining, Data Pipelines, Data Warehousing, Real Time Data, Apache Hadoop, Apache Spark, Machine Learning, Data Mart, View all skills",
    "instructors": [
      "josephreis"
    ],
    "content": "In this course, you’ll model, transform, and serve data for both analytics and machine learning use cases. You’ll explore various data modeling techniques for batch analytics, including normalization, star schema, data vault, and one big table, and you’ll use dbt to transform a dataset based on a star schema and one big table. You’ll also compare the Inmon vs Kimball data modeling approaches for data warehouses. You’ll model and transform a tabular dataset for machine learning purposes. You’ll also model and transform unstructured image and textual data. You’ll explore distributed processing frameworks such as Hadoop MapReduce and Spark, and perform stream processing. You’ll identify different ways of serving data for analytics and machine learning, including using views and materialized views, and you’ll describe how a semantic layer built on top of your data model can support the business. In the last week of this course, you’ll complete a capstone project where you’ll build an end-to-end data pipeline that encompasses all of the stages of the data engineering lifecycle to serve data that provides business value."
  },
  {
    "url": "https://www.coursera.org/learn/data-oriented-scientific-programming",
    "name": "Data-Oriented C++ in Scientific Programming",
    "what_you_learn": "Software architecture using an object-oriented and a data-oriented approach\nSoftware architecture using an object-oriented and a data-oriented approach\nEfficient programming using language-specific features in C++\nEfficient programming using language-specific features in C++\nGPU and multi-core CPU software development in C++\nGPU and multi-core CPU software development in C++",
    "skills": "Computational Thinking, Data-oriented programming, Operating Systems",
    "instructors": [
      "chopard",
      "falcone",
      "latt"
    ],
    "content": "Learn how to write efficient, maintainable C++ code for data-intensive applications in this hands-on course. Key application areas include scientific simulation software, statistical data processing, and computer graphics.You’ll begin by exploring how modern C++ supports high-efficiency programming and review the principles of a central piece of hardware in data-intensive applications: computer memory.\nNext, the course shifts to software design. You’ll examine performance shortcomings of traditional object-oriented programming and dive into data-oriented perspective, which improves performance by structuring code around the data itself. You’ll learn how this paradigm overcomes bottlenecks and leads to more scalable, high-performance solutions.\n\nFinally, you’ll apply these principles to modern multi-threaded systems. Through hands-on experience you will learn to use C++'s built-in parallel features to target both multi-core CPUs and GPUs."
  },
  {
    "url": "https://www.coursera.org/learn/data-patterns",
    "name": "Pattern Discovery in Data Mining",
    "what_you_learn": "",
    "skills": "Text Mining, Statistical Methods, Advanced Analytics, Image Analysis, Data Mining, Algorithms, Unstructured Data, Anomaly Detection, Big Data, Information Privacy, Spatial Analysis",
    "instructors": [
      "jiaweihan"
    ],
    "content": "Learn the general concepts of data mining along with basic methodologies and applications. Then dive into one subfield in data mining: pattern discovery. Learn in-depth concepts, methods, and applications of pattern discovery in data mining. We will also introduce methods for data-driven phrase mining and some interesting applications of pattern discovery. This course provides you the opportunity to learn skills and content to practice and engage in scalable pattern discovery methods on massive transactional data, discuss pattern evaluation measures, and study methods for mining diverse kinds of patterns, sequential patterns, and sub-graph patterns."
  },
  {
    "url": "https://www.coursera.org/learn/data-pipelines-tensorflow",
    "name": "Data Pipelines with TensorFlow Data Services",
    "what_you_learn": "Perform efficient ETL tasks using Tensorflow Data Services APIs\nPerform efficient ETL tasks using Tensorflow Data Services APIs\nConstruct train/validation/test splits of any dataset - either custom or present in TensorFlow Hub Dataset library - using Splits API\nConstruct train/validation/test splits of any dataset - either custom or present in TensorFlow Hub Dataset library - using Splits API\nUse different modules and functions of the TFDS API to prepare your data for training pipelines\nUse different modules and functions of the TFDS API to prepare your data for training pipelines\nIdentify bottlenecks in your input pipelines and increase your workflow efficiency by input parallelization\nIdentify bottlenecks in your input pipelines and increase your workflow efficiency by input parallelization",
    "skills": "Data Import/Export, Data Pipelines, Data Transformation, Feature Engineering, Performance Tuning, Data Processing, Data Integration, Data Management, Tensorflow, Extract, Transform, Load, Data Sharing",
    "instructors": [
      "lmoroney"
    ],
    "content": "Bringing a machine learning model into the real world involves a lot more than just modeling. This Specialization will teach you how to navigate various deployment scenarios and use data more effectively to train your model.In this third course, you will:\n- Perform streamlined ETL tasks using TensorFlow Data Services\n- Load different datasets and custom feature vectors using TensorFlow Hub and TensorFlow Data Services APIs\n- Create and use pre-built pipelines for generating highly reproducible I/O pipelines for any dataset\n- Optimize data pipelines that become a bottleneck in the training process\n- Publish your own datasets to the TensorFlow Hub library and share standardized data with researchers and developers around the world\n\n\nThis Specialization builds upon our TensorFlow in Practice Specialization. If you are new to TensorFlow, we recommend that you take the TensorFlow in Practice Specialization first. To develop a deeper, foundational understanding of how neural networks work, we recommend that you take the Deep Learning Specialization."
  },
  {
    "url": "https://www.coursera.org/learn/data-preparation",
    "name": "Prepare Data for Exploration",
    "what_you_learn": "Explain what factors to consider when making decisions about data collection.\nExplain what factors to consider when making decisions about data collection.\nDiscuss the difference between biased and unbiased data.\nDiscuss the difference between biased and unbiased data.\nDescribe databases with references to their functions and components.\nDescribe databases with references to their functions and components.\nDescribe best practices for organizing data.\nDescribe best practices for organizing data.",
    "skills": "Data Import/Export, SQL, Data Security, Data Quality, Unstructured Data, Data Storage, Data Collection, Data Literacy, Data Ethics, Data Management, Databases, Google Sheets, Data Analysis, Metadata Management, View all skills",
    "instructors": [
      "google-career-certificates"
    ],
    "content": "This is the third course in the Google Data Analytics Certificate. As you continue to build on your understanding of the topics from the first two courses, you’ll be introduced to new topics that will help you gain practical data analytics skills. You’ll learn how to use tools like spreadsheets and SQL to extract and make use of the right data for your objectives, and how to organize and protect your data. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.\n\nBy the end of this course, learners will:\n- Find out how analysts decide what data to collect for analysis.\n- Learn about structured and unstructured data, data types, and data formats.\n- Discover how to identify different types of bias in data to help ensure data credibility. \n- Explore how analysts use spreadsheets and SQL within databases and data sets.\n- Examine open data and the relationship between, and importance of, data ethics and data privacy.\n- Gain an understanding of how to access databases and extract, filter, and sort the data they contain.\n- Learn best practices for organizing data and keeping it secure."
  },
  {
    "url": "https://www.coursera.org/learn/data-preparation-and-management",
    "name": "Data Preparation and Management",
    "what_you_learn": "",
    "skills": "Data Quality, Power BI, Data Validation, Data Modeling, Data Storage, Data Processing, Data Integration, Data Cleansing, Data Transformation, Data Management, Data Import/Export, Data Wrangling, Extract, Transform, Load, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "Data Preparation and Management is designed to equip you with the essential skills needed to prepare and manage data effectively using Microsoft Power BI. Throughout this course, you'll learn how to connect, clean, and transform data from various sources to ensure its integrity and quality. You will explore the principles of Extract, Transform, Load (ETL) processes, data storage, and the importance of maintaining data accuracy. This course emphasizes practical applications, providing you with hands-on experience in managing real-world data scenarios. By the end of this course, you’ll be ready to confidently handle data preparation tasks and ensure that your data is ready for analysis and visualization.This program is for anyone interested in data analytics and visualization; there are no prerequisites. To get the most out of the learning experience, it is recommended to follow the courses in sequence, as each one builds on the skills and knowledge gained in the previous ones. By the time you begin this course, you should have a strong understanding of different types of visualizations and their appropriate use, along with the ability to create cohesive and compelling reports in Power BI. You should also be capable of identifying and addressing common design problems in reports, producing audience-focused reports by understanding business needs."
  },
  {
    "url": "https://www.coursera.org/learn/data-privacy-and-protection-standards",
    "name": "Data Privacy and Protection Standards",
    "what_you_learn": "Assess Global Data Privacy Regulations and Their Impact on Businesses.\nAssess Global Data Privacy Regulations and Their Impact on Businesses.\nImplement Data Protection Strategies for Security and Breach Prevention.\nImplement Data Protection Strategies for Security and Breach Prevention.\nEstablish Data Privacy Compliance through Assessments and Policies.\nEstablish Data Privacy Compliance through Assessments and Policies.",
    "skills": "Security Strategy, Data Security, Compliance Management, Data Integrity, Data Governance, Data Ethics, General Data Protection Regulation (GDPR), Security Controls, Personally Identifiable Information, Data Loss Prevention, Information Privacy, Regulatory Compliance, Compliance Training, Incident Response, Regulatory Requirements, View all skills",
    "instructors": [
      "~141793623",
      "~139311893"
    ],
    "content": "In today's digital age, Data Privacy and Protection Standards are pivotal for organizations across all sectors to safeguard sensitive information, comply with international regulations, and maintain the trust of clients and customers. This course provides a comprehensive understanding of the foundational principles of data privacy, the latest in protection standards, and practical approaches to implementing robust data protection measures. Participants will explore key regulations such as the GDPR and CCPA, delve into technical and organizational strategies for data security, and learn how to handle data breaches effectively.Through this course, learners will gain insights into the rights of data subjects and the ethical considerations surrounding data protection. Upon completion, participants will be equipped with the knowledge to navigate the complexities of data privacy laws and implement measures that ensure data integrity and confidentiality. This course is designed to empower professionals to build and maintain data protection frameworks that align with global standards and foster a culture of privacy within their organizations.\t \n\nThis course is tailored for privacy and IT professionals, security analysts, compliance officers, and data protection specialists working across various sectors. It is also highly relevant for business leaders, project managers, and legal advisors responsible for managing and safeguarding personal data within their organizations. Additionally, individuals interested in understanding data privacy laws, ethical considerations in data handling, and implementing effective data protection measures might find this course valuable. \n\nNo specific prerequisites are required for this course. A basic understanding of information technology and familiarity with general business operations will be helpful but are not essential. An interest in data privacy, protection standards, and a commitment to ethical data management practices will greatly benefit participants. \n\nAfter completing this course, learners will analyze global data privacy regulations like GDPR, CCPA, and others, gauging their impact on businesses worldwide. They'll apply data protection strategies, employing technical and organizational measures to secure personal data and prevent breaches. Additionally, they'll develop skills in ensuring compliance by conducting data protection impact assessments and implementing necessary policies, establishing a robust framework for ethical data handling and regulatory adherence."
  },
  {
    "url": "https://www.coursera.org/learn/data-privacy-security-governance-risk-and-compliance",
    "name": "Data Privacy, Security, Governance, Risk and Compliance",
    "what_you_learn": "Develop and implement effective data privacy and security strategies.\nDevelop and implement effective data privacy and security strategies.\nUnderstand and apply security measures to protect and govern organizational data.\nUnderstand and apply security measures to protect and govern organizational data.\nConduct risk assessments and implement appropriate risk management practices.\nConduct risk assessments and implement appropriate risk management practices.\nNavigate and comply with relevant legal and regulatory compliance requirements.\nNavigate and comply with relevant legal and regulatory compliance requirements.",
    "skills": "Risk Management, Data Security, Threat Detection, Encryption, Data Quality, Information Privacy, Cybersecurity, Data Integrity, Security Controls, Data Architecture, Compliance Management, Incident Response, Personally Identifiable Information, Data Governance, Law, Regulation, and Compliance, View all skills",
    "instructors": [
      "skillup"
    ],
    "content": "Whether you’re an aspiring data engineer, data architect, business analyst, or data scientist, a strong foundation in data security is crucial for any data management professional. By gaining practical experience and comprehensive knowledge,  you will strengthen your resume and unlock exciting career opportunities in the dynamic field of data security and protection.This course provides insight into data privacy, security, and governance. You will learn to implement effective strategies for protecting sensitive information while identifying and mitigating various cyberthreats. You’ll explore encryption techniques, access control management, and incident response planning. \n\nThe course also covers data architecture and governance, where you will develop frameworks for maintaining data quality and integrity. Additionally, learner will learn about risk management and compliance, focusing on essential regulations to safeguard data and foster organizational trust.  \n\nYou will reinforce the concepts learned in the course through hand-on labs, activities, and case studies. To enhance your resume with the essential skills for a data-oriented career and attracting the attention of potential employers, enroll today!"
  },
  {
    "url": "https://www.coursera.org/learn/data-processing-and-optimization-with-generative-ai",
    "name": "Data Processing and Optimization with Generative AI",
    "what_you_learn": "",
    "skills": "Data Processing, Data Synthesis, Data Transformation, Data Analysis, Data Quality, Generative AI, Data Cleansing, Personally Identifiable Information, Data Ethics, Data Integrity, Data Validation, Feature Engineering, Microsoft Copilot, Responsible AI, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course focuses on advanced methods for data cleaning, preparation, and optimization using AI-assisted tools. You'll learn to generate synthetic data, address privacy concerns and data limitations in your projects. Discover how to leverage AI to identify and resolve complex data quality issues, ensuring your datasets are primed for analysis.Upon completion of this course, you'll be able to:\n\nGenerate synthetic data using generative AI models\n\nImplement advanced data cleaning techniques with AI assistance\n\nOptimize datasets for improved analysis efficiency\n\nApply ethical considerations in data processing and synthetic data generation"
  },
  {
    "url": "https://www.coursera.org/learn/data-products",
    "name": "Developing Data Products",
    "what_you_learn": "Develop basic applications and interactive graphics using GoogleVis\nDevelop basic applications and interactive graphics using GoogleVis\nUse Leaflet to create interactive annotated maps\nUse Leaflet to create interactive annotated maps\nBuild an R Markdown presentation that includes a data visualization\nBuild an R Markdown presentation that includes a data visualization\nCreate a data product that tells a story to a mass audience\nCreate a data product that tells a story to a mass audience",
    "skills": "R (Software), Data Visualization Software, Data Visualization, Data Presentation, Data Mapping, Package and Software Management, R Programming, Rmarkdown, Web Applications, Shiny (R Package), Interactive Data Visualization, Plotly, Statistical Reporting, View all skills",
    "instructors": [
      "~694443",
      "rdpeng",
      "~688901"
    ],
    "content": "A data product is the production output from a statistical analysis. Data products automate complex analysis tasks or use technology to expand the utility of a data informed model, algorithm or inference. This course covers the basics of creating data products using Shiny, R packages, and interactive graphics. The course will focus on the statistical fundamentals of creating a data product that can be used to tell a story about data to a mass audience."
  },
  {
    "url": "https://www.coursera.org/learn/data-public-health",
    "name": "Data and Health Indicators in Public Health Practice",
    "what_you_learn": "",
    "skills": "Public Health, Statistical Methods, Health Policy, Health Care, Health Disparities, Epidemiology, Social Determinants Of Health, Medical Records, Infectious Diseases, Descriptive Analytics",
    "instructors": [
      "~24563706"
    ],
    "content": "Epidemiology is often described as the cornerstone science in public health. Epidemiology in public health practice uses study design and analyses to identify causes in an outbreak situation, guides interventions to improve population health, and evaluates programs and policies.In this course, we'll define the role of the professional epidemiologist as it relates to public health services, functions, and competencies. With that foundation in mind, we'll introduce you to the problem solving methodology and demonstrate how it can be used in a wide variety of settings to identify problems, propose solutions, and evaluate interventions. This methodology depends on the use of reliable data, so we'll take a deep dive into the routine and public health data systems that lie at the heart of epidemiology and then conclude with how you can use that data to calculate measures of disease burden in populations."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-and-scikit-learn-in-python",
    "name": "Introduction to Data Science and scikit-learn in Python",
    "what_you_learn": "Employ artificial intelligence techniques to test hypothesis in Python\nEmploy artificial intelligence techniques to test hypothesis in Python\nApply a machine learning model combining Numpy, Pandas, and Scikit-Learn\nApply a machine learning model combining Numpy, Pandas, and Scikit-Learn",
    "skills": "Pandas (Python Package), Exploratory Data Analysis, Regression Analysis, Data Science, Machine Learning, Feature Engineering, Data Analysis, Predictive Modeling, Data Manipulation, Programming Principles, Classification And Regression Tree (CART), Scikit Learn (Machine Learning Library), Python Programming, NumPy, Data Structures, Statistical Methods, Statistical Hypothesis Testing, Supervised Learning, View all skills",
    "instructors": [
      "~77903726",
      "~77881195",
      "~61317279"
    ],
    "content": "This course will teach you how to leverage the power of Python and artificial intelligence to create and test hypothesis. We'll start for the ground up, learning some basic Python for data science before diving into some of its richer applications to test our created hypothesis. We'll learn some of the most important libraries for exploratory data analysis (EDA) and machine learning such as Numpy, Pandas, and Sci-kit learn. After learning some of the theory (and math) behind linear regression, we'll go through and full pipeline of reading data, cleaning it, and applying a regression model to estimate the progression of diabetes. By the end of the course, you'll apply a classification model to predict the presence/absence of heart disease from a patient's health data."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-as-a-field",
    "name": "Data Science as a Field",
    "what_you_learn": "By taking this course, you will be able explain what data science is and identify the key disciplines involved.\nBy taking this course, you will be able explain what data science is and identify the key disciplines involved.\nYou will be able to use the steps of the data science process to create a reproducible data analysis and identify personal biases.\nYou will be able to use the steps of the data science process to create a reproducible data analysis and identify personal biases.\nYou will be able to identify interesting data science applications, locate jobs in Data Science, and begin developing a professional network.\nYou will be able to identify interesting data science applications, locate jobs in Data Science, and begin developing a professional network.",
    "skills": "Statistical Reporting, Data Analysis, Statistics, Data Visualization, Exploratory Data Analysis, Data-Driven Decision-Making, Data Presentation, Applied Mathematics, Technical Communication, Data Ethics, Data Storytelling, Data Science, Computer Science, View all skills",
    "instructors": [
      "jane-wall"
    ],
    "content": "This course provides a general introduction to the field of Data Science. It has been designed for aspiring data scientists, content experts who work with data scientists, or anyone interested in learning about what Data Science is and what it’s used for. Weekly topics include an overview of the skills needed to be a data scientist; the process and pitfalls involved in data science; and the practice of data science in the professional and academic world. This course is part of CU Boulder’s Master’s of Science in Data Science and was collaboratively designed by both academics and industry professionals to provide learners with an insider’s perspective on this exciting, evolving, and increasingly vital discipline.Data Science as a Field can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-course",
    "name": "A Crash Course in Data Science",
    "what_you_learn": "Describe Data Science’s role in various contexts\nDescribe Data Science’s role in various contexts\nUnderstand how Statistics and Machine Learning affect Data Science\nUnderstand how Statistics and Machine Learning affect Data Science\nUse the key terms used by data scientist\nUse the key terms used by data scientist\nPredict whether a Data Science project will be successful\nPredict whether a Data Science project will be successful",
    "skills": "Project Design, Data Analysis, Data-Driven Decision-Making, Machine Learning, Predictive Modeling, Data Science, Statistical Inference, Software Engineering, Performance Metric, Data Management",
    "instructors": [
      "~694443",
      "rdpeng",
      "~688901"
    ],
    "content": "By now you have definitely heard about data science and big data. In this one-week class, we will provide a crash course in what these terms mean and how they play a role in successful organizations. This class is for anyone who wants to learn what all the data science action is about, including those who will eventually need to manage data scientists. The goal is to get you up to speed as quickly as possible on data science without all the fluff. We've designed this course to be as convenient as possible without sacrificing any of the essentials.This is a focused course designed to rapidly get you up to speed on the field of data science. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.\n\nAfter completing this course you will know. \n\n1. How to describe the role data science plays in various contexts\n2. How statistics, machine learning, and software engineering play a role in data science\n3. How to describe the structure of a data science project\n4. Know the key terms and tools used by data scientists\n5. How to identify a successful and an unsuccessful data science project\n3. The role of a data science manager\n\n\nCourse cover image by r2hox. Creative Commons BY-SA: https://flic.kr/p/gdMuhT"
  },
  {
    "url": "https://www.coursera.org/learn/data-science-ethics",
    "name": "Data Science Ethics",
    "what_you_learn": "Examine the ethical and privacy implications of collecting and managing big data.\nExamine the ethical and privacy implications of collecting and managing big data.\nExplore the broader impact of the data science field on modern society.\nExplore the broader impact of the data science field on modern society.\nUnderstand who owns data, how we value privacy, how to receive informed consent and what it means to be fair.\nUnderstand who owns data, how we value privacy, how to receive informed consent and what it means to be fair.",
    "skills": "Ethical Standards And Conduct, Information Privacy, Sampling (Statistics), Data Security, Data Ethics, Social Studies, Responsible AI, Personally Identifiable Information, Informed Consent, Data Governance, Data Analysis, Big Data, Intellectual Property, View all skills",
    "instructors": [
      "jag"
    ],
    "content": "What are the ethical considerations regarding the privacy and control of consumer information and big data, especially in the aftermath of recent large-scale data breaches?This course provides a framework to analyze these concerns as you examine the ethical and privacy implications of collecting and managing big data. Explore the broader impact of the data science field on modern society and the principles of fairness, accountability and transparency as you gain a deeper understanding of the importance of a shared set of ethical values. You will examine the need for voluntary disclosure when leveraging metadata to inform basic algorithms and/or complex artificial intelligence systems while also learning best practices for responsible data management, understanding the significance of the Fair Information Practices Principles Act and the laws concerning the \"right to be forgotten.\"\n\nThis course will help you answer questions such as who owns data, how do we value privacy, how to receive informed consent and what it means to be fair.\n\nData scientists and anyone beginning to use or expand their use of data will benefit from this course. No particular previous knowledge needed."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-in-rwd-analysis",
    "name": "Data Science with Real World Data in Pharma",
    "what_you_learn": "Explain how real world data/evidence fits into the drug development process\nExplain how real world data/evidence fits into the drug development process\nDescribe the three major types of bias that can be encountered in observational studies\nDescribe the three major types of bias that can be encountered in observational studies\nApply basic survival analysis techniques such as Kaplan-Meier plots and Cox Models to synthetic data.\nApply basic survival analysis techniques such as Kaplan-Meier plots and Cox Models to synthetic data.",
    "skills": "Drug Development, Statistical Analysis, Data Science, Predictive Modeling, Epidemiology, Health Policy, Electronic Medical Record, Data Quality, Healthcare Industry Knowledge, Statistical Methods, Clinical Trials, Data Analysis, Clinical Research, R Programming, View all skills",
    "instructors": [
      "~3700451",
      "~116183378"
    ],
    "content": "This course introduces you to how Real World Data/Evidence can be used for pharmaceutical research and development and how it complements the evidence package for healthcare decision-making. If you are interested in applying data science to pharmaceutical research using data collected as part of routine clinical practice, this course is for you.The course will help you describe what it means to be a Real World Data Scientist in the pharmaceutical industry. You will discover the particularities of the data sources and learn how to generate high quality evidence and how that evidence is used by the stakeholders for decision making purposes.\n\nTo be successful in this course, you should have a background in data analytics, statistics, or other technical fields. No experience in the pharmaceutical industry is expected.\n\nWe thank Hannah Furby and Matt Secrest for her inspirational material."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-inteligencia-artificial-aplicados-a-negocios",
    "name": "Data Science & Inteligencia Artificial aplicados a negocios",
    "what_you_learn": "Principios fundamentales de la IA y su aplicación en entornos empresariales.\nPrincipios fundamentales de la IA y su aplicación en entornos empresariales.\nAspectos éticos y sociales de la implementación de sistemas de inteligencia artificial en entornos empresariales.\nAspectos éticos y sociales de la implementación de sistemas de inteligencia artificial en entornos empresariales.",
    "skills": "Predictive Modeling, Natural Language Processing, Computer Vision, Artificial Intelligence, Data Ethics, Data Science, Innovation, Business Transformation, Machine Learning, Strategic Leadership, Business Ethics, Strategic Decision-Making, Business Analytics, Data-Driven Decision-Making, Business Leadership, Responsible AI, IT Service Management, Organizational Leadership, View all skills",
    "instructors": [
      "~169995567"
    ],
    "content": "En un mundo empresarial cada vez más competitivo y orientado hacia la innovación, el dominio de la inteligencia artificial (IA) y la ciencia de datos se ha convertido en un activo indispensable para el éxito. Este curso te proporcionará una sólida comprensión de los principios fundamentales de la inteligencia artificial y su aplicación práctica en entornos empresariales, con un enfoque especial en la toma de decisiones informadas y éticas.Además de brindarte habilidades técnicas avanzadas, este aprendizaje te permitirá abordar desafíos reales, identificar oportunidades de negocio y resolver problemas complejos, destacándote en un mercado laboral cada vez más exigente y dinámico. La inteligencia artificial, lejos de ser una tecnología futurista, ya transforma la forma en que operan las empresas, y este curso te preparará para liderar esta revolución y aprovechar sus enormes posibilidades."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-k-means-clustering-python",
    "name": "Foundations of Data Science: K-Means Clustering in Python",
    "what_you_learn": "Define and explain the key concepts of data clustering\nDefine and explain the key concepts of data clustering\nDemonstrate understanding of the key constructs and features of the Python language.\nDemonstrate understanding of the key constructs and features of the Python language.\nImplement in Python the principle steps of the K-means algorithm.\nImplement in Python the principle steps of the K-means algorithm.\nDesign and execute a whole data clustering workflow and interpret the outputs.\nDesign and execute a whole data clustering workflow and interpret the outputs.",
    "skills": "Statistics, Machine Learning Algorithms, Data Manipulation, Data Science, Matplotlib, Descriptive Statistics, Data Visualization, NumPy, Machine Learning, Unsupervised Learning, Pandas (Python Package), Data Analysis, Python Programming, Probability & Statistics, View all skills",
    "instructors": [
      "jamie-a-ward",
      "larisa-soldatova",
      "betty-fyn-sydney",
      "matthew-yee-king"
    ],
    "content": "Organisations all around the world are using data to predict behaviours and extract valuable real-world insights to inform decisions. Managing and analysing big data has become an essential part of modern finance, retail, marketing, social science, development and research, medicine and government.This MOOC, designed by an academic team from Goldsmiths, University of London, will quickly introduce you to the core concepts of Data Science to prepare you for intermediate and advanced Data Science courses. It focuses on the basic mathematics, statistics and programming skills that are necessary for typical data analysis tasks. \n\nYou will consider these fundamental concepts on an example data clustering task, and you will use this example to learn basic programming skills that are necessary for mastering Data Science techniques. During the course, you will be asked to do a series of mathematical and programming exercises and a small data clustering project for a given dataset."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-methodology",
    "name": "Data Science Methodology",
    "what_you_learn": "Describe what a data science methodology is and why data scientists need a methodology.\nDescribe what a data science methodology is and why data scientists need a methodology.\nApply the six stages in the Cross-Industry Process for Data Mining (CRISP-DM) methodology to analyze a case study.\nApply the six stages in the Cross-Industry Process for Data Mining (CRISP-DM) methodology to analyze a case study.\nEvaluate which analytic model is appropriate among predictive, descriptive, and classification models used to analyze a case study.\nEvaluate which analytic model is appropriate among predictive, descriptive, and classification models used to analyze a case study.\nDetermine appropriate data sources for your data science analysis methodology.\nDetermine appropriate data sources for your data science analysis methodology.",
    "skills": "Data Analysis, Jupyter, Stakeholder Engagement, Data Cleansing, Data Processing, Data Modeling, Data-Driven Decision-Making, Data Science, Business Analysis, User Feedback, Data Mining, Predictive Modeling, Software Development Methodologies, Business Requirements, Data Collection, Peer Review, Decision Tree Learning, View all skills",
    "instructors": [
      "alexaklson",
      "polong-lin"
    ],
    "content": "If there is a shortcut to becoming a Data Scientist, then learning to think and work like a successful Data Scientist is it. In this course, you will learn and then apply this methodology that you can use to tackle any Data Science scenario. You’ll explore two notable data science methodologies, Foundational Data Science Methodology, and the six-stage CRISP-DM data science methodology, and learn how to apply these data science methodologies. Most established data scientists follow these or similar methodologies for solving data science problems.Begin by learning about forming the business/research problem Learn how data scientists obtain, prepare, and analyze data. Discover how applying data science methodology practices helps ensure that the data used for problem-solving is relevant and properly manipulated to address the question. Next, learn about building the data model, deploying that model, data storytelling, and obtaining feedback You’ll think like a data scientist and develop your data science methodology skills using a real-world inspired scenario through progressive labs hosted within Jupyter Notebooks and using Python."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-patient-centered-research-in-pharma-industry",
    "name": "Data Sciences in Pharma - Patient Centered Outcomes Research",
    "what_you_learn": "How patient experience data is used in the drug lifecycle\nHow patient experience data is used in the drug lifecycle\nDeveloping a patient-centric measurement strategy and using qualitative and quantitative patient experience data as evidence in drug development\nDeveloping a patient-centric measurement strategy and using qualitative and quantitative patient experience data as evidence in drug development\nCommon clinical outcome assessment outputs and considerations when interpreting clinical outcome assessment data\nCommon clinical outcome assessment outputs and considerations when interpreting clinical outcome assessment data",
    "skills": "Drug Development, Statistical Analysis, Data Science, Statistical Methods, Patient-centered Care, Clinical Assessment, Patient Evaluation, Clinical Trials, Quantitative Research, Data Literacy, Pharmaceutical Terminology, View all skills",
    "instructors": [
      "~117913254"
    ],
    "content": "The course is targeted toward people who are interested in how patient experience data and clinical outcome assessment (COA) data can be used as evidence across drug development, in the pharmaceutical industry. By the end of the course you will better understand how this data is collected and analysed to evidence how patients feel, function or survive in the context of a clinical trial. More specifically, the course will cover: i) a background to COAs; ii) a background to patient experience data; iii) how to select, develop/modify and validate COAs using qualitative data (a) and psychometrics (b);  iv) interpreting data on a COA; v) measuring treatment related tolerability via patient reported outcomes; vi) Common COA data outputs.No experience in the pharmaceutical industry is needed for this course, but it is beneficial. This is an introductory course so an interest in qualitative and quantitative data and some basic knowledge in data analytics and statistics will be helpful for some lessons but is not required."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-profession-student-view",
    "name": "The Data Science Profession – Student View",
    "what_you_learn": "In this course you learn how Data Science is applied in the real world, what we mean by data, and what we mean by machine learning.\nIn this course you learn how Data Science is applied in the real world, what we mean by data, and what we mean by machine learning.",
    "skills": "Data Analysis, Machine Learning, Unsupervised Learning, Applied Machine Learning, Big Data, Data Literacy, Data Science",
    "instructors": [
      "robertzimmer"
    ],
    "content": "This course is primarily aimed at individuals who want to learn how Data Science is applied in the real world, what we mean by data, and what we mean by machine learning. The course also covers concepts such as K-means and categorical and numerical data."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-project",
    "name": "Data Science Capstone",
    "what_you_learn": "Create a useful data product for the public\nCreate a useful data product for the public\nApply your exploratory data analysis skills\nApply your exploratory data analysis skills\nBuild an efficient and accurate prediction model\nBuild an efficient and accurate prediction model\nProduce a presentation deck to showcase your findings\nProduce a presentation deck to showcase your findings",
    "skills": "Natural Language Processing, Data Presentation, Predictive Modeling, Data Science, Data Manipulation, Machine Learning, Exploratory Data Analysis, R Programming, Data Analysis, Statistical Analysis, Data Cleansing, Data Collection, Data Storytelling, View all skills",
    "instructors": [
      "~694443",
      "rdpeng",
      "~688901"
    ],
    "content": "The capstone project class will allow students to create a usable/public data product that can be used to show your skills to potential employers. Projects will be drawn from real-world problems and will be conducted with industry, government, and academic partners."
  },
  {
    "url": "https://www.coursera.org/learn/data-science-project-capstone-predicting-bicycle-rental",
    "name": "Data Science Project Capstone: Predicting Bicycle Rental",
    "what_you_learn": "In this course you will tackle a prediction problem: forecasting the number of bicycles that will be rented on a given day.\nIn this course you will tackle a prediction problem: forecasting the number of bicycles that will be rented on a given day.",
    "skills": "Exploratory Data Analysis, Correlation Analysis, Data Collection, Statistical Modeling, Time Series Analysis and Forecasting, Predictive Modeling, Forecasting, Data Analysis, Regression Analysis, Data Science, Data-Driven Decision-Making, View all skills",
    "instructors": [
      "robertzimmer"
    ],
    "content": "This course is the seventh of eight. In this project, we will tackle a prediction problem: forecasting the number of bicycles that will be rented on a given day. Using historical data, we will consider factors such as weather conditions, the day of the week, and other relevant variables to accurately predict daily bicycle rentals. This will help ensure that our bicycle rental service is prepared with the appropriate number of bicycles each day. We will learn specifically about data acquisition and correlation."
  },
  {
    "url": "https://www.coursera.org/learn/data-scientists-tools",
    "name": "The Data Scientist’s Toolbox",
    "what_you_learn": "Set up R, R-Studio, Github and other useful tools\nSet up R, R-Studio, Github and other useful tools\nUnderstand the data, problems, and tools that data analysts use\nUnderstand the data, problems, and tools that data analysts use\nExplain essential study design concepts\nExplain essential study design concepts\nCreate a Github repository\nCreate a Github repository",
    "skills": "Exploratory Data Analysis, Version Control, Statistical Programming, GitHub, R Programming, Data Science, Software Installation, Rmarkdown, Data Literacy, R (Software), Data Analysis",
    "instructors": [
      "~694443",
      "rdpeng",
      "~688901"
    ],
    "content": "In this course you will get an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, and tools that data analysts and data scientists work with. There are two components to this course. The first is a conceptual introduction to the ideas behind turning data into actionable knowledge. The second is a practical introduction to the tools that will be used in the program like version control, markdown, git, GitHub, R, and RStudio."
  },
  {
    "url": "https://www.coursera.org/learn/data-security",
    "name": "Data Security",
    "what_you_learn": "",
    "skills": "Key Management, Cybersecurity, Continuous Monitoring, Encryption, Event Monitoring, Incident Response, Cryptography, Intrusion Detection and Prevention, Threat Detection, Network Security, Network Monitoring, Security Information and Event Management (SIEM), Network Analysis, Data Security, View all skills",
    "instructors": [
      "~102418580"
    ],
    "content": "If you are an associate-level cybersecurity analyst who is working in security operation centers, this course will help you explore data type categories in context to network security analytics.By the end of the course, you will be able to:\t\n• Explain the data that is available to the network security analysis •Describe the various types of data used in monitoring network security \n• Describe the deployment and use of SIEMs to collect, sort, process, prioritize, store, and report alarms \n• Describe the functions of SOAR platforms and features of Cisco SecureX \n•Describe the Security Onion Open Source security monitoring tool\n• Explain how packet capture data is stored in the PCAP format and the storage requirements for full packet capture.\n• Describe packet capture usage and benefits for investigating security incidents • Describe packet captures using tools such as Tcpdump \n• Describe session data content and provide an example of session data\n•Describe transaction data content and provide an example of transaction data z\n• Describe alert data content and provide an example of alert data\n•Describe other types of NSM data (extracted content, statistical data, and metadata)\n•Explain the need to correlate NSM data and provide an example\n•Describe the Information Security CIA triad \n• Understand PII as it relates to information security \n• Describe compliance regulations and their effects on an organization \n• Describe intellectual property and the importance of protecting it \n• Use various tool capabilities of the Security Onion Linux distribution\t\t\n\nTo be successful in this course, you should have the following background: \n1. Skills and knowledge equivalent to those learned in Implementing and Administering Cisco Solutions (CCNA) v1.0 course \n2. Familiarity with Ethernet and TCP/IP networking \n3. Working knowledge of the Windows and Linux operating systems 4. Familiarity with basics of networking security concepts."
  },
  {
    "url": "https://www.coursera.org/learn/data-security-privacy",
    "name": "Data, Security, and Privacy",
    "what_you_learn": "Students will learn digital literacy, how to use the internet as a productivity tool, and how to manage security threats and protect data.\nStudents will learn digital literacy, how to use the internet as a productivity tool, and how to manage security threats and protect data.",
    "skills": "System Design and Implementation, Data Sharing, Cybersecurity, Data Security, Computer Literacy, Data Ethics, Software Development Tools, Safety and Security, Information Technology, Technology Strategies, Information Privacy, View all skills",
    "instructors": [
      "~86182999"
    ],
    "content": "This course provides hands-on experience with technology-based productivity tools, as well as foundational knowledge and understanding of system design and development. The course is designed to integrate concepts of hardware, software, and the Internet. This course also provides an overview of data security, data privacy, and ways to increase productivity and efficiency. Students will also investigate technology career paths and some of the various certifications available in the industry."
  },
  {
    "url": "https://www.coursera.org/learn/data-storage-and-queries",
    "name": "Data Storage and Queries",
    "what_you_learn": "Design storage architectures for various use cases, and select appropriate technologies to implement these architectures\nDesign storage architectures for various use cases, and select appropriate technologies to implement these architectures\nPractice common query patters and identify ways to improve query performance and enhance the value of your data systems\nPractice common query patters and identify ways to improve query performance and enhance the value of your data systems",
    "skills": "Database Systems, Amazon Web Services, Amazon S3, Cloud Storage, Data Storage, Query Languages, Performance Tuning, File Systems, Data Architecture, Data Lakes, Data Warehousing, SQL, Graph Theory, Databases, View all skills",
    "instructors": [
      "josephreis"
    ],
    "content": "In this course, you will learn about the raw ingredients and processes that are used to physically store data on disk and in memory. You’ll explore different storage systems, including object, block, and file storage, as well as databases, that are built on top of these raw ingredients. You’ll also get a chance to use the Cypher language to query a Neo4j graph database, and perform vector similarity search, a key feature behind generative AI and large language models. You will explore the evolution of data storage abstractions, from data warehouses, to data lakes, and data lakehouses, while comparing the advantages and drawbacks of each architectural paradigm. With hands-on practice, you will design a simple data lake using Amazon Glue, and build a data lakehouse using AWS LakeFormation and Apache Iceberg. In the last week of this course, you’ll see how queries work behind the scenes, practice writing more advanced SQL queries, compare the query performance in row vs column-oriented storage, and perform streaming queries using Apache Flink."
  },
  {
    "url": "https://www.coursera.org/learn/data-storytelling-with-power-bi",
    "name": "Data Storytelling with Power BI",
    "what_you_learn": "Demonstrate the ability to connect, transform, model, and visualize data effectively in Power BI.\nDemonstrate the ability to connect, transform, model, and visualize data effectively in Power BI.\nImplement DAX formulas to develop measures, establish relationships, and perform complex calculations.\nImplement DAX formulas to develop measures, establish relationships, and perform complex calculations.\nProduce interactive visuals, dashboards, and reports that meet defined business intelligence needs.\nProduce interactive visuals, dashboards, and reports that meet defined business intelligence needs.\nUtilize Power BI Service features to deploy, protect, and publish reports for scalable insights.\nUtilize Power BI Service features to deploy, protect, and publish reports for scalable insights.",
    "skills": "Spreadsheet Software, Microsoft Excel",
    "instructors": [
      "~136285326"
    ],
    "content": "Welcome to the Data Storytelling with Power BI course, where you'll embark on a journey to acquire practical expertise in data transformation and visualization. Leverage the potential of Power BI to create narratives through structured data, leading to the discovery of more profound insights.Throughout this course, you'll explore the industry-specific applications of Power BI and delve into its various features and functionalities. \n\nBy the end of this course, you’ll be able to:\n- Explain essential concepts in data connectivity, transformation, and modeling using Power BI effectively.\n- Apply DAX formulas and functions to create measures, build relationships, and perform advanced calculations.\n- Design engaging and interactive visuals, reports, and dashboards to address diverse business requirements.\n- Evaluate Power BI Service capabilities to deploy, secure, and publish reports for scalable, data‑driven insights.\n\nThis course is designed for a diverse audience: freshers, data analyst, business analysts, business intelligence analyst and IT professionals who are looking to enhance their data analysis skills through Power BI. \n\nPrior experience with Microsoft Excel or spreadsheet applications can be beneficial when working with Power BI.\n\nEmbark on an educational voyage to master Microsoft Power BI and enhance your skills in creating efficient Reports and Dashboards using the Power BI ecosystem."
  },
  {
    "url": "https://www.coursera.org/learn/data-structures",
    "name": "Data Structures",
    "what_you_learn": "",
    "skills": "C++ (Programming Language), Computer Programming, Java, Data Storage, Algorithms, Data Structures, Programming Principles, File Management, Java Programming",
    "instructors": [
      "~103620247",
      "~46748",
      "dakane",
      "kulikov",
      "38926"
    ],
    "content": "A good algorithm usually comes together with a set of good data structures that allow the algorithm to manipulate the data efficiently. In this online course, we consider the common data structures that are used in various computational problems. You will learn how these data structures are implemented in different programming languages and will practice implementing them in our programming assignments. This will help you to understand what is going on inside a particular built-in implementation of a data structure and what to expect from it. You will also learn typical use cases for these data structures.A few examples of questions that we are going to cover in this class are the following:\n1. What is a good strategy of resizing a dynamic array?\n2. How priority queues are implemented in C++, Java, and Python?\n3. How to implement a hash table so that the amortized running time of all operations is O(1) on average?\n4. What are good strategies to keep a binary tree balanced? \n\nYou will also learn how services like Dropbox manage to upload some large files instantly and to save a lot of storage space!"
  },
  {
    "url": "https://www.coursera.org/learn/data-transformation-in-the-cloud",
    "name": "Data Transformation in the Cloud",
    "what_you_learn": "Describe the steps of the data journey and how they are used to drive data-driven decision making.\nDescribe the steps of the data journey and how they are used to drive data-driven decision making.\nRecognize the role of data transformation in preparing data for analysis.\nRecognize the role of data transformation in preparing data for analysis.\nDescribe the benefits and challenges of transforming data in the cloud.\nDescribe the benefits and challenges of transforming data in the cloud.\nIdentify the key components of a data transformation plan.\nIdentify the key components of a data transformation plan.",
    "skills": "Data Processing, Data Collection, Data Transformation, Data Visualization, Cloud Security, Data Cleansing, Extract, Transform, Load, Cloud Storage, SQL, Data Pipelines, Data Analysis, Data Migration, Cloud Computing, Data Governance, Data Integration, Data Management, View all skills",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "Hi learner! This is the third course of the Google Cloud Data Analytics Certificate. Tap into your creativity as you explore the world of advanced principles of data visualization. You'll discover the benefits and challenges of transforming data in the cloud and the common tools and methods used to collect, process, and store data."
  },
  {
    "url": "https://www.coursera.org/learn/data-urban-governance",
    "name": "Data and Urban Governance",
    "what_you_learn": "",
    "skills": "Data Sharing, Big Data, Information Privacy, Social Sciences, Data Analysis, Computing Platforms, Data Ethics, Data Governance, Data-Driven Decision-Making, Political Sciences, Public Administration, Policy Analysis, Personally Identifiable Information, Governance, Algorithms, View all skills",
    "instructors": [
      "~98469454",
      "~98357099"
    ],
    "content": "Since the beginning of the 2000s, cities have witnessed a massive influx of data, transforming how cities are governed. Data has an impact on how city life is structured, as it influences coalitions, actors, instruments, policies, and forms of regulation.In this MOOC, we will look at this shift more closely: what has the advent of big data done to urban governance? Have platforms disrupted local authorities? How has big data changed local politics? How do we govern using algorithms? What is the place of citizens in the digital city? Is it still possible to be anonymous in the city?\n\nAt the end of this course, you will be able to navigate the landscape of urban governance in the digital era, including its myriad actors and instruments; to decipher what drives ongoing transformations in how local governments are structured and operate; to analyze the contemporary changes in municipal service markets; and to understand what is at stake in terms of the creation and implementation of public policies when data comes to town.\n\nThis MOOC is offered by the Digital Cities Chair of the Urban School of SciencesPo, funded by La Poste, RTE and the Caisse des Dépôts.\n\nVideos are in creative commons license BY NC"
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization",
    "name": "Data Management and Visualization",
    "what_you_learn": "",
    "skills": "Data Manipulation, Python Programming, SAS (Software), Peer Review, Data Management, Descriptive Statistics, Graphing, Data Presentation, Data Analysis, Exploratory Data Analysis, Data Literacy, Research Reports, Statistics, View all skills",
    "instructors": [
      "~1121232"
    ],
    "content": "Whether being used to customize advertising to millions of website visitors or streamline inventory ordering at a small restaurant, data is becoming more integral to success. Too often, we’re not sure how use data to find answers to the questions that will make us more successful in what we do. In this course, you will discover what data is and think about what questions you have that can be answered by the data – even if you’ve never thought about data before. Based on existing data, you will learn to develop a research question, describe the variables and their relationships, calculate basic statistics, and present your results clearly. By the end of the course, you will be able to use powerful data analysis tools – either SAS or Python – to manage and visualize your data, including how to deal with missing data, variable groups, and graphs. Throughout the course, you will share your progress with others to gain valuable feedback, while also learning how your peers use data to answer their own questions."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-capstone",
    "name": "Data Visualization Capstone",
    "what_you_learn": "",
    "skills": "Data Storytelling, Data Manipulation, Storyboarding, Statistical Reporting, Tidyverse (R Package), Statistical Visualization, Data Wrangling, Data Transformation, R Programming, Data Visualization Software, Data Literacy, Data Visualization, Graphing, Data Analysis, Ggplot2, Rmarkdown, Data Import/Export, Data Cleansing, View all skills",
    "instructors": [
      "collinpaschall"
    ],
    "content": "Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.This is the final course in the Specialization \"Data Visualization and Dashboarding in R.\" Learners in this course will enter with a well-developed set of skills making a wide variety of visualizations in R. The focus on this course will applying those skills to a unique project, drawing on publicly available data to tell a compelling story using the data visualization toolkit assembled in the previous courses."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-dashboards-excel-cognos",
    "name": "Data Visualization and Dashboards with Excel and Cognos",
    "what_you_learn": "Create basic visualizations such as line graphs, bar graphs, and pie charts using Excel spreadsheets.\nCreate basic visualizations such as line graphs, bar graphs, and pie charts using Excel spreadsheets.\nExplain the important role charts play in telling a data-driven story.\nExplain the important role charts play in telling a data-driven story.\nConstruct advanced charts and visualizations such as Treemaps, Sparklines, Histogram, Scatter Plots, and Filled Map Charts.\nConstruct advanced charts and visualizations such as Treemaps, Sparklines, Histogram, Scatter Plots, and Filled Map Charts.\nBuild and share interactive dashboards using Excel and Cognos Analytics.\nBuild and share interactive dashboards using Excel and Cognos Analytics.",
    "skills": "Scatter Plots, Histogram, Data Storytelling, Pivot Tables And Charts, IBM Cognos Analytics, Data Visualization, Data Analysis, Data Visualization Software, Microsoft Excel, Dashboard, Tree Maps",
    "instructors": [
      "sandipsahajoy",
      "stever",
      "~74013819"
    ],
    "content": "Learn how to create data visualizations and dashboards using spreadsheets and analytics tools. This course covers some of the first steps for telling a compelling story with your data using various types of charts and graphs. You'll learn the basics of visualizing data with Excel and IBM Cognos Analytics without having to write any code.You'll start by creating simple charts in Excel such as line, pie and bar charts. You will then create more advanced visualizations with Treemaps, Scatter Charts, Histograms, Filled Map Charts, and Sparklines. Next you’ll also work with the Excel PivotChart feature as well as assemble several visualizations in an Excel dashboard.  \n\nThis course also teaches you how to use business intelligence (BI) tools like Cognos Analytics  to create interactive dashboards. By the end of the course you will have an appreciation for the key role that data visualizations play in communicating your data analysis findings, and the ability to effectively create them. \n\nThroughout this course there will be numerous hands-on labs to help you develop practical experience for working with Excel and Cognos. There is also a final project in which you’ll create a set of data visualizations and an interactive dashboard to add to your portfolio, which you can share with peers, professional communities or prospective employers."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-for-genome-biology",
    "name": "Data Visualization for Genome Biology",
    "what_you_learn": "",
    "skills": "Exploratory Data Analysis, Interactive Data Visualization, Heat Maps, Dimensionality Reduction, Scientific Visualization, Statistical Visualization, Statistical Analysis, Molecular Biology, Ggplot2, Bioinformatics, Data Visualization Software, Plot (Graphics), Design Thinking, R Programming, Scatter Plots, Network Analysis, R (Software), View all skills",
    "instructors": [
      "nickprovart"
    ],
    "content": "The past decade has seen a vast increase in the amount of data available to biologists, driven by the dramatic decrease in cost and concomitant rise in throughput of various next-generation sequencing technologies, such that a project unimaginable 10 years ago was recently proposed, the Earth BioGenomes Project, which aims to sequence the genomes of all eukaryotic species on the planet within the next 10 years. So while data are no longer limiting, accessing and interpreting those data has become a bottleneck. One important aspect of interpreting data is data visualization. This course introduces theoretical topics in data visualization through mini-lectures, and applied aspects in the form of hands-on labs. The labs use both web-based tools and R, so students at all computer skill levels can benefit. Syllabus may be viewed at https://tinyurl.com/DataViz4GenomeBio."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-fundamentals",
    "name": "Data Visualization Fundamentals",
    "what_you_learn": "",
    "skills": "Statistical Visualization, Power BI, Data Analysis, Business Intelligence, Scatter Plots, Data Visualization Software, Dashboard, Data-Driven Decision-Making, Data Storytelling, Interactive Data Visualization, Pivot Tables And Charts, Data Visualization, Data Presentation, Histogram, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "Data Visualization Fundamentals is designed to introduce you to the powerful world of data visualization using Power BI. This course will guide you through the basics of creating visually appealing and meaningful reports, charts and graphs. You'll learn how to identify the right visualization for different types of data, and how to use Power BI's tools to build reports that tell compelling stories with data. Whether you're new to data visualization or looking to sharpen your skills, this course provides practical knowledge that you can apply immediately. By the end, you'll be equipped with foundational skills to help drive data-informed decisions."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-fundamentals-in-python",
    "name": "Data Visualization Fundamentals in Python",
    "what_you_learn": "Develop interactive visualizations using Python libraries.\nDevelop interactive visualizations using Python libraries.\nImplement data visualization techniques and plots using Python libraries, such as Matplotlib and Seaborn to tell a compelling story\nImplement data visualization techniques and plots using Python libraries, such as Matplotlib and Seaborn to tell a compelling story\nCustomize visualization features and styles with themes, colors, and chart elements for clear communication.\nCustomize visualization features and styles with themes, colors, and chart elements for clear communication.\nApply human perception principles to enhance the effectiveness and interpretability of your visualizations.\nApply human perception principles to enhance the effectiveness and interpretability of your visualizations.",
    "skills": "Plot (Graphics), Data Visualization Software, Python Programming, Matplotlib, Pandas (Python Package), Seaborn, Data Presentation, Graphic and Visual Design, Interactive Data Visualization, Jupyter, Data Visualization, Data Manipulation, Data Analysis, NumPy, Data Storytelling, View all skills",
    "instructors": [
      "~162614166"
    ],
    "content": "The \"Data Visualization Fundamentals in Python\" course empowers you to transform data into compelling visual narratives. Dive into the principles and best practices of data visualization, blending the art and science to tell impactful data stories using Python.Through this course, you will master creating basic and advanced data visualizations and learn to effectively communicate complex information visually. You will explore Python libraries such as Matplotlib and Seaborn and understand how to customize visual elements to create clear, insightful, and visually appealing data representations.\n\nYou will develop skills to apply fundamental principles, incorporate human perception aspects, customize your plots, and create interactive visualizations ensuring an accurate interpretation of data. This course will equip you with techniques for transforming complex datasets into coherent visuals, optimizing your ability to convey data-driven insights effectively."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-r",
    "name": "Data Visualization with R",
    "what_you_learn": "Create bar charts, histograms, pie charts, scatter plots, line graphs, box plots, and maps using R and related packages.\nCreate bar charts, histograms, pie charts, scatter plots, line graphs, box plots, and maps using R and related packages.\nDesign customized charts and plots using annotations, axis titles, text labels, themes, and faceting.\nDesign customized charts and plots using annotations, axis titles, text labels, themes, and faceting.\nCreate maps using the Leaflet package for R.\nCreate maps using the Leaflet package for R.\nCreate interactive dashboards using the Shiny package for R.\nCreate interactive dashboards using the Shiny package for R.",
    "skills": "Data Visualization Software, Interactive Data Visualization, Data Storytelling, Plot (Graphics), R Programming, Ggplot2, Scatter Plots, Data Science, Data Visualization, Dashboard, Spatial Data Analysis, Leaflet (Software), User Interface (UI), UI Components, Box Plots, Data Analysis, Shiny (R Package), Histogram, View all skills",
    "instructors": [
      "tiffanyzhu",
      "saishruthi-tn",
      "gabrieladequeiroz",
      "yiwenli"
    ],
    "content": "In this course, you will learn the Grammar of Graphics, a system for describing and building graphs, and how the ggplot2 data visualization package for R applies this concept to basic bar charts, histograms, pie charts, scatter plots, line plots, and box plots. You will also learn how to further customize your charts and plots using themes and other techniques. You will then learn how to use another data visualization package for R called Leaflet to create map plots, a unique way to plot data based on geolocation data. Finally, you will be introduced to creating interactive dashboards using the R Shiny package. You will learn how to create and customize Shiny apps, alter the appearance of the apps by adding HTML and image components, and deploy your interactive data apps on the web.You will practice what you learn and build hands-on experience by completing labs in each module and a final project at the end of the course.\n\nWatch the videos, work through the labs, and watch your data science skill grow. Good luck!\n\nNOTE: This course requires knowledge of working with R and data. If you do not have these skills, it is highly recommended that you first take the Introduction to R Programming for Data Science as well as the Data Analysis with R courses from IBM prior to starting this course. Note: The pre-requisite for this course is basic R programming skills."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-science-communication",
    "name": "3D Data Visualization for Science Communication",
    "what_you_learn": "",
    "skills": "Graphical Tools, Spatial Data Analysis, Data Storytelling, Data Literacy, 3D Modeling, Data Presentation, Computer Graphics, Video Production, Data Visualization Software, Scientific Visualization, Visualization (Computer Graphics), View all skills",
    "instructors": [
      "kalina-borkiewicz",
      "aj-christensen"
    ],
    "content": "This course is an introduction to 3D scientific data visualization, with an emphasis on science communication and cinematic design for appealing to broad audiences. You will develop visualization literacy, through being able to interpret/analyze (read) visualizations and create (write) your own visualizations.By the end of this course, you will:\n-Develop visualization literacy.\n-Learn the practicality of working with spatial data.\n-Understand what makes a scientific visualization meaningful.\n-Learn how to create educational visualizations that maintain scientific accuracy.\n-Understand what makes a scientific visualization cinematic.\n-Learn how to create visualizations that appeal to broad audiences.\n-Learn how to work with image-making software. (for those completing the Honors track)"
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-tableau",
    "name": "Fundamentals of Visualization with Tableau",
    "what_you_learn": "Install Tableau Public Software and create a visualization\nInstall Tableau Public Software and create a visualization\nExamine and navigate the Tableau Public workspace\nExamine and navigate the Tableau Public workspace\nPractice and connect to different data sources\nPractice and connect to different data sources\nExamine ways to define your project\nExamine ways to define your project",
    "skills": "Data Storytelling, Tableau Software, Data Manipulation, Data Import/Export, Dashboard, Data Presentation, Interactive Data Visualization, Data Ethics, Visualization (Computer Graphics), Data Visualization, Data Visualization Software, Data Literacy, View all skills",
    "instructors": [
      "alexandra-wilson"
    ],
    "content": "In this first course of this specialization, you will discover what data visualization is, and how we can use it to better see and understand data. Using Tableau Public, we’ll examine the fundamental concepts of data visualization and explore the Tableau interface, identifying and applying the various tools Tableau has to offer. By the end of the course you will be able to prepare and import data into Tableau and explain the relationship between data analytics and data visualization. This course is designed for the learner who has never used Tableau before, or who may need a refresher or want to explore Tableau in more depth. No prior technical or analytical background is required. The course will guide you through the steps necessary to create your first visualization from the beginning based on data context, setting the stage for you to advance to the next course in the Specialization."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-transformation-r",
    "name": "Data Visualization and Transformation with R",
    "what_you_learn": "Transform, visualize, summarize, and analyze data in R, with packages from the Tidyverse, using RStudio\nTransform, visualize, summarize, and analyze data in R, with packages from the Tidyverse, using RStudio\nCarry out analyses in a reproducible and shareable manner with Quarto\nCarry out analyses in a reproducible and shareable manner with Quarto\nLearn to effectively communicate results through an optional written project version controlled with Git and hosted on GitHub\nLearn to effectively communicate results through an optional written project version controlled with Git and hosted on GitHub",
    "skills": "Statistical Analysis, Data Analysis, R (Software), Descriptive Statistics, Statistical Programming, Tidyverse (R Package), Exploratory Data Analysis, Data Science, GitHub, R Programming, Ggplot2, Data Visualization, Probability & Statistics, Git (Version Control System), Statistics, Data Visualization Software, Scatter Plots, Data Transformation, Data-Driven Decision-Making, View all skills",
    "instructors": [
      "minecetinkayarundel",
      "~127290745"
    ],
    "content": "This course is an introduction to data science and statistical thinking. Learners will gain experience with exploring, visualizing, and analyzing data to understand natural phenomena and investigate patterns, model outcomes, and do so in a reproducible and shareable manner. Topics covered include data visualization and transformation for exploratory data analysis. Learners will be introduced to problems and case studies inspired by and based on real-world questions and data via lecture and live coding videos as well as interactive programming exercises. The course will focus on the R statistical computing language with a focus on packages from the Tidyverse, the RStudio integrated development environment, Quarto for reproducible reporting, and Git and GitHub for version control. The skills learners will gain in this course will prepare them for careers in a variety of fields, including data scientist, data analyst, quantitative analyst, statistician, and much more."
  },
  {
    "url": "https://www.coursera.org/learn/data-visualization-with-tableau-public",
    "name": "Data Visualization with Tableau",
    "what_you_learn": "Identify the value and structure of Tableau Public as it applies to data visualization in the industry of business analytics.\nIdentify the value and structure of Tableau Public as it applies to data visualization in the industry of business analytics.\nBuild interactive tables by connecting, preparing, and customizing data in Tableau Public.\nBuild interactive tables by connecting, preparing, and customizing data in Tableau Public.\nCreate data visualizations to communicate analytic insights to the intended audience, such as business stakeholders.\nCreate data visualizations to communicate analytic insights to the intended audience, such as business stakeholders.",
    "skills": "Data Storytelling, Heat Maps, Data Visualization Software, Data Presentation, Tableau Software, Business Analytics, Data Manipulation, Tree Maps, Data Visualization, Data Mapping, Geospatial Mapping, Dashboard, Interactive Data Visualization, View all skills",
    "instructors": [
      "~136272031"
    ],
    "content": "The Data Visualization with Tableau course provides you with a foundational understanding of presenting data through clear and easily comprehensible visuals using Tableau. Throughout the course, you’ll explore a diverse range of visualization types and their ideal applications with the Tableau Public platform. By examining how experts leverage Tableau to create exceptional charts and maps, and acquiring the skills to craft interactive tables, you’ll gain proficiency in essential visualization techniques. Understanding these techniques is crucial for those pursuing entry-level roles in the field of business analytics.This course is for anyone who is curious about entry-level roles that demand fundamental Tableau skills, such as business intelligence analyst or data reporting analyst roles. It is recommended (but not required) that you have some experience with Tableau Public, but even if you're new to Tableau Public, you can still be successful in this program.\n\nBy the end of the course, you will be able to:\n-Identify the value and structure of Tableau Public as it applies to data visualization in the industry of business analytics.\n-Create data visualizations to communicate analytic insights to the intended audience, such as business stakeholders.\n-Build interactive tables by connecting, preparing, and customizing data in Tableau Public."
  },
  {
    "url": "https://www.coursera.org/learn/data-viz-shiny-dashboards",
    "name": "Publishing Visualizations in R with Shiny and flexdashboard",
    "what_you_learn": "",
    "skills": "Interactive Data Visualization, Shiny (R Package), Application Deployment, User Interface (UI), Statistical Visualization, Data Presentation, Application Development, Dashboard, Data Visualization Software, UI Components, Ggplot2, View all skills",
    "instructors": [
      "collinpaschall"
    ],
    "content": "Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.This course is the fourth in the Specialization \"Data Visualization and Dashboarding in R.\" Learners will come to this course with a strong background in making visualization in R using ggplot2. To build on those skills, this course covers creating interactive visualization using Shiny, as well as combining different kinds of figures made in R into interactive dashboards."
  },
  {
    "url": "https://www.coursera.org/learn/data-warehouse-analytics-microsoft-azure",
    "name": "Modern Data Warehouse Analytics in Microsoft Azure",
    "what_you_learn": "Processing options for building data analytics solutions in Azure. You will explore Azure Synapse Analytics, Azure Databricks, and Azure HDInsight.\nProcessing options for building data analytics solutions in Azure. You will explore Azure Synapse Analytics, Azure Databricks, and Azure HDInsight.\nDescribe data ingestion and processing on Azure\nDescribe data ingestion and processing on Azure\nDescribe the components of a modern data warehouse\nDescribe the components of a modern data warehouse\nDescribe data visualization in Microsoft Power BI. Describe analytics workloads.\nDescribe data visualization in Microsoft Power BI. Describe analytics workloads.",
    "skills": "Data Processing, Analytics, Big Data, Data Integration, Cloud Services, Databases, Azure Synapse Analytics, Data Warehousing, Data Lakes, Data Visualization Software, Business Intelligence, Data Architecture, Databricks, Microsoft Azure, Data Visualization, Power BI, Data Pipelines, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "In this course, you will learn the fundamentals of database concepts in a cloud environment, get basic skilling in cloud data services, and build your foundational knowledge of cloud data services within Microsoft Azure. You will explore the processing options available for building data analytics solutions in Azure. You will explore Azure Synapse Analytics, Azure Databricks, and Azure HDInsight.This is the fourth course in a  program of five courses to help prepare you to take the Exam DP-900: Microsoft Azure Data Fundamentals.  so that you can demonstrate that you have a foundational knowledge of the core database concepts in a cloud environment.\n\nThis course is ideal for IT professionals who want to learn the fundamentals of database concepts in a cloud environment, get basic skilling in cloud data services, and build their foundational knowledge of cloud data services within Microsoft Azure with a view to taking up roles as Data Engineers and Database Administrators. It is also suitable for working database professionals looking for additional skills or credentials to showcase expertise in a cloud environment and IT professionals looking to specialize in the specific area of Azure data.\n\nTo be successful in this course, you need to have basic computer literacy and proficiency in the English language. Successful Azure Data Fundamentals students start with some basic awareness of computing and Internet concepts, and an interest in extracting insights from data.  It is an advantage to have experience using a web browser, familiarity with basic data-related concepts, such as working with tables of data in a spreadsheet, and visualizing data using charts."
  },
  {
    "url": "https://www.coursera.org/learn/data-warehouse-fundamentals",
    "name": "Data Warehouse Fundamentals",
    "what_you_learn": "Job-ready data warehousing skills in just 6 weeks, supported by practical experience and an IBM credential.\nJob-ready data warehousing skills in just 6 weeks, supported by practical experience and an IBM credential.\nDesign and populate a data warehouse, and model and query data using CUBE, ROLLUP, and materialized views.\nDesign and populate a data warehouse, and model and query data using CUBE, ROLLUP, and materialized views.\nIdentify popular data analytics and business intelligence tools and vendors and create data visualizations using IBM Cognos Analytics.\nIdentify popular data analytics and business intelligence tools and vendors and create data visualizations using IBM Cognos Analytics.\nHow to design and load data into a data warehouse, write aggregation queries, create materialized query tables, and create an analytics dashboard.\nHow to design and load data into a data warehouse, write aggregation queries, create materialized query tables, and create an analytics dashboard.",
    "skills": "PostgreSQL, Data Modeling, Data Cleansing, Data Lakes, Star Schema, Data Validation, Database Systems, Database Design, Data Quality, SQL, Data Mart, Extract, Transform, Load, Query Languages, Data Warehousing, IBM DB2, Snowflake Schema, Data Integration, Data Architecture, View all skills",
    "instructors": [
      "~75088416",
      "ravahuja"
    ],
    "content": "Whether you’re an aspiring data engineer, data architect, business analyst, or data scientist, strong data warehousing skills are a must. With the hands-on experience and competencies, you gain on this course, your resume will catch the eye of employers and power up your career opportunities.A data warehouse centralizes and organizes data from disparate sources into a single repository, making it easier for data professionals to access, clean, and analyze integrated data efficiently.   \n\n This course teaches you how to design, deploy, load, manage, and query data warehouses, data marts, and data lakes. You’ll dive into designing, modeling, and implementing data warehouses, and explore data warehousing architectures like star and snowflake schemas. You’ll master techniques for populating data warehouses through ETL and ELT processes, and hone your skills in verifying and querying data, and utilizing concepts like cubes, rollups, and materialized views/tables.    \n\nAdditionally, you’ll gain valuable practical experience working on hands-on labs, where you’ll apply your knowledge to real data warehousing tasks. You’ll work with repositories like PostgreSQL and IBM Db2, and complete a project that you can refer to in interviews."
  },
  {
    "url": "https://www.coursera.org/learn/data-warehousing-business-intelligence",
    "name": "Data Warehousing and Business Intelligence",
    "what_you_learn": "Explain different data warehousing architectures and multidimensional data modeling\nExplain different data warehousing architectures and multidimensional data modeling\nDevelop predictive data mining models, including classification and estimation models\nDevelop predictive data mining models, including classification and estimation models\nDevelop explanatory data mining models, including clustering and association models\nDevelop explanatory data mining models, including clustering and association models",
    "skills": "Data-Driven Decision-Making, Predictive Modeling, Market Analysis, Business Intelligence, Snowflake Schema, Star Schema, Cloud Computing, Data Mart, Data Modeling, Big Data, Extract, Transform, Load, Business Analytics, Data Warehousing, Unsupervised Learning, Data Science, Databases, Statistical Methods, Data Mining, Data Architecture, Machine Learning Methods, View all skills",
    "instructors": [
      "~86182999"
    ],
    "content": "This course builds on “The Nature of Data and Relational Database Design” to extend the process of capturing and manipulating data through data warehousing and data mining. Once the transactional data is processed through ETL (Extract, Transform, Load), it is then stored in a data warehouse for use in managerial decision making. Data mining is one of the key enablers in the process of converting data stored in a data warehouse into actionable insight for better and faster decision making.By the end of this course, students will be able to explain data warehousing and how it is used for business intelligence, explain different data warehousing architectures and multidimensional data modeling, and develop predictive data mining models, including classification and estimation models. IN addition, students will be able to develop explanatory data mining models, including clustering and association models."
  },
  {
    "url": "https://www.coursera.org/learn/data-warehousing-essentials-for-analytics-and-ai-support",
    "name": "Data Warehousing Essentials for Analytics and AI Support",
    "what_you_learn": "",
    "skills": "Data-Driven Decision-Making, Extract, Transform, Load, Data Modeling, Snowflake Schema, Database Design, Data Warehousing, Data Analysis, Business Intelligence, Database Architecture and Administration, Data Integrity, Star Schema, Data Visualization, SQL, Databases, Relational Databases, Data Mart, Data Manipulation, View all skills",
    "instructors": [
      "~151652382"
    ],
    "content": "This course will cover various topics in Data Engineering in support of decision support systems, data analytics, data mining, machine learning, and artificial intelligence. You will study on-premises data warehouse architecture, and dimensional modeling of data warehouses."
  },
  {
    "url": "https://www.coursera.org/learn/data-wrangling-analysis-abtesting",
    "name": "SQL Problem Solving",
    "what_you_learn": "Validate and clean a dataset\nValidate and clean a dataset\nAssess and create datasets to answer your questions\nAssess and create datasets to answer your questions\nSolve problems using SQL\nSolve problems using SQL\nBuild a simple testing framework to touch on AB Testing\nBuild a simple testing framework to touch on AB Testing",
    "skills": "Data Visualization, Debugging, Data Transformation, Data Analysis, JSON, Complex Problem Solving, Business Reporting, Forecasting, Exploratory Data Analysis, Data Presentation, Business Metrics, Data Quality, Predictive Analytics, SQL, View all skills",
    "instructors": [
      "katrina-glaeser"
    ],
    "content": "SQL for Problem Solving is designed for learners who already understand the basics of SQL and are ready to apply their skills to real-world data problems. In this hands-on course, you’ll move beyond textbook queries to tackle the challenges data analysts face every day. From diagnosing data quality issues to building rolling metrics and interpreting event data, this course gives you the toolkit to write powerful, efficient SQL queries across different dialects and complex datasets.You’ll learn:\n- Problem-solving strategies used by data professionals\n- Techniques for debugging, improving data quality, and building complex queries\n- How to work with modern data environments, from event logs to denormalized schemas\n- How to communicate business-relevant insights through SQL-based analysis\n\nWhether you're preparing for a data job interview, building dashboards for stakeholders, or leveling up your data chops, this course empowers you with the skills to make SQL your go-to tool for data analysis and problem-solving."
  },
  {
    "url": "https://www.coursera.org/learn/database-clients",
    "name": "Database Clients",
    "what_you_learn": "Utilize Python code to create, populate and manipulate MySQL databases and tables.\nUtilize Python code to create, populate and manipulate MySQL databases and tables.\nCreate a useful Python application capable of administration of a MySQL database.\nCreate a useful Python application capable of administration of a MySQL database.",
    "skills": "Database Application, Python Programming, Databases, MySQL, Data Management, Application Programming Interface (API), SQL, Database Management, Django (Web Framework)",
    "instructors": [
      "~30575670"
    ],
    "content": "Explore how to write database driven applications in Python by creating various types of clients that connect to MySQL databases using Python code and Python-related MySQL features and tools.By the end of this course, you’ll be able to:  \n \n- Utilize Python code to create, populate and manipulate MySQL databases and tables \n- Access advanced functionality in MySQL using custom built Python clients \n- Develop working familiarity with advanced topics in MySQL \n- Apply the principles of advanced MySQL topics to problem solving using Python \n- Develop a working knowledge of the methods by which a MySQL database connects to the web via a Django API \n- Create a useful Python application capable of administration of a MySQL database \n \nYou’ll gain experience with the following tools and software: \n \n- Python code \n- Python-related MySQL features and tools \n- Django REST framework \n- _meta API\n\nTo take this course, you must have completed the previous course Advanced MySQL topics. You must also be eager to continue your journey with coding."
  },
  {
    "url": "https://www.coursera.org/learn/database-clients-es",
    "name": "Clientes de base de datos",
    "what_you_learn": "Utilice código Python para crear, introducir y manipular bases de datos y tablas MySQL.\nUtilice código Python para crear, introducir y manipular bases de datos y tablas MySQL.\nCree una aplicación Python útil capaz de administrar una base de datos MySQL.\nCree una aplicación Python útil capaz de administrar una base de datos MySQL.",
    "skills": "Stored Procedure, Database Management, Databases, Django (Web Framework), Application Programming Interface (API), SQL, Back-End Web Development, Database Design, MySQL, Python Programming",
    "instructors": [
      "~30575670"
    ],
    "content": "Explore cómo escribir aplicaciones basadas en bases de datos en Python al crear varios tipos de clientes que se conectan a bases de datos MySQL mediante código Python y características y herramientas MySQL relacionadas con Python.Al final de este curso, podrá:\n \n- Utilizar código Python para crear, introducir y manipular bases de datos y tablas MySQL\n- Acceder a la funcionalidad avanzada en MySQL utilizando clientes Python personalizados \n- Desarrollar familiaridad de trabajo con temas avanzados en MySQL\n- Aplicar los principios de los temas avanzados de MySQL a la resolución de problemas mediante Python\n- Desarrollar un conocimiento práctico de los métodos por los cuales una base de datos MySQL se conecta a la web a través de una API (Application Protocol Interface, Interfaz de programación de aplicaciones) de Django\n- Crear una aplicación Python útil capaz de administrar una base de datos MySQL \n \nObtendrá experiencia con las siguientes herramientas y software: \n \n- Código Python\n- Características y herramientas de MySQL relacionadas con Python\n- Marco REST de Django\n- API de _meta\n\nPara tomar este curso, debe haber completado los temas avanzados de MySQL del curso anterior."
  },
  {
    "url": "https://www.coursera.org/learn/database-design-postgresql",
    "name": "Database Design and Basic SQL in PostgreSQL",
    "what_you_learn": "Utilize psql and SQL commands to implement CRUD (Create, Read, Update, and Delete) operations for tables in a PostgreSQL database.\nUtilize psql and SQL commands to implement CRUD (Create, Read, Update, and Delete) operations for tables in a PostgreSQL database.\nIdentify and utilize the functions of primary, logical, and foreign keys within a database.\nIdentify and utilize the functions of primary, logical, and foreign keys within a database.\nBuild and differentiate between one-to-many and many-to-many relationships within PostgreSQL.\nBuild and differentiate between one-to-many and many-to-many relationships within PostgreSQL.\nRecall key people, organizations, and innovations that were instrumental to building the SQL standard\nRecall key people, organizations, and innovations that were instrumental to building the SQL standard",
    "skills": "Database Design, PostgreSQL, Data Modeling, SQL, Database Management, Database Theory, Data Integrity, Databases, Relational Databases",
    "instructors": [
      "drchuck"
    ],
    "content": "In this course you will learn more about the historical design of databases and the use of SQL in the PostgreSQL environment. Using SQL techniques and common commands (INSERT INTO, WHERE, ORDER BY, ON DELETE CASCADE, etc) will enable you to create tables, column types and define the schema of your data in PostgreSQL.    You will learn about data modeling and how to represent one-to-many and many-to-many relationships in PostgreSQL.   Students will do hands-on assignments creating tables, inserting data, designing data models, creating relational structures and inserting and querying relational data in tables."
  },
  {
    "url": "https://www.coursera.org/learn/database-engineer-capstone",
    "name": "Database Engineer Capstone",
    "what_you_learn": "Build a MySQL database solution.\nBuild a MySQL database solution.\nDeploy level-up ideas to enhance the scope of a database project.\nDeploy level-up ideas to enhance the scope of a database project.",
    "skills": "MySQL Workbench, Version Control, Project Management, Data Visualization Software, Application Development, Transaction Processing, SQL, Databases, Data Manipulation, Database Application, Stored Procedure, MySQL, Tableau Software, Django (Web Framework), Database Design, Database Management, Data Modeling, Git (Version Control System), Python Programming, Database Development, View all skills",
    "instructors": [
      "~30575670"
    ],
    "content": "In this course you’ll complete a capstone project in which you’ll create a database and client for Little Lemon restaurant.To complete this course, you will need database engineering experience.  \n\nThe Capstone project enables you to demonstrate multiple skills from the Certificate by solving an authentic real-world problem. Each module includes a brief recap of, and links to, content that you have covered in previous courses in this program. \n\nIn this course, you will demonstrate your new skillset by designing and composing a database solution, combining all the skills and technologies you've learned throughout this program to solve the problem at hand. \n\n\nBy the end of this course, you’ll have proven your ability to:\n-Set up a database project,\n-Add sales reports,\n-Create a table booking system,\n-Work with data analytics and visualization,\n-And create a database client.\n\nYou’ll also demonstrate your ability with the following tools and software:\n-Git,\n-MySQL Workbench,\n-Tableau,\n-And Python."
  },
  {
    "url": "https://www.coursera.org/learn/database-engineer-capstone-es",
    "name": "Proyecto final de ingenieros de bases de datos",
    "what_you_learn": "Crear una solución de base de datos MySQL.\nCrear una solución de base de datos MySQL.\nImplementar ideas avanzadas para mejorar el alcance de un proyecto de base de datos.\nImplementar ideas avanzadas para mejorar el alcance de un proyecto de base de datos.",
    "skills": "Data Modeling, Database Design, Database Management, Python Programming, SQL, Stored Procedure, Data Visualization Software, MySQL Workbench, Git (Version Control System), Database Development, Tableau Software, Databases, Database Application, Data Visualization, MySQL, View all skills",
    "instructors": [
      "~30575670"
    ],
    "content": "En este curso, completará un proyecto final donde deberá crear una base de datos y un cliente para el restaurante Little Lemon.Para completar este curso, necesitará experiencia en ingeniería de bases de datos.\n\nEl proyecto final le permite demostrar múltiples habilidades del Certificado mediante la resolución de un auténtico problema del mundo real. Cada módulo incluye un breve resumen y enlaces a contenidos que ya se han tratado en cursos anteriores de este programa.\n\nEn este curso, demostrará su nuevo conjunto de habilidades mediante el diseño y la elaboración de una solución de base de datos, combinando todas las habilidades y tecnologías que aprendió a lo largo de este programa para resolver el problema en cuestión. \n\n\nAl final de este curso, habrá demostrado su capacidad para realizar lo siguiente:\n- Configurar un proyecto de base de datos.\n-Agregar informes de ventas.\n-Crear un sistema para reservar mesas.\n-Trabajar con análisis y visualización de datos.\n-Crear un cliente de base de datos.\n\nTambién demostrará su capacidad con las siguientes herramientas y software: \n-Git,\n-MySQL Workbench,\n-Tableau,\n-Python."
  },
  {
    "url": "https://www.coursera.org/learn/database-essentials-and-vulnerabilities",
    "name": "Database Essentials and Vulnerabilities",
    "what_you_learn": "Job-ready data management skills employers need, including how to implement various data protection techniques to secure sensitive information\nJob-ready data management skills employers need, including how to implement various data protection techniques to secure sensitive information\nHow to configure and manage database user profiles, password policies, privileges, and roles\nHow to configure and manage database user profiles, password policies, privileges, and roles\nHow to identify, analyze, and mitigate database injection vulnerabilities, including OS commands and SQL injection\nHow to identify, analyze, and mitigate database injection vulnerabilities, including OS commands and SQL injection\nHow to design and implement comprehensive database and application auditing models\nHow to design and implement comprehensive database and application auditing models",
    "skills": "Data Manipulation, Database Architecture and Administration, Vulnerability Scanning, User Accounts, Secure Coding, Role-Based Access Control (RBAC), Application Security, Data Security, Relational Databases, Encryption, Databases, Database Management, SQL, NoSQL, View all skills",
    "instructors": [
      "manish-kumar",
      "ibm-skills-network"
    ],
    "content": "The average cost of a data breach is nearly $5 million, with 70% of the affected organizations reporting significant or very significant disruption, according to an IBM report. Hence, businesses are hunting hard for cybersecurity experts who can safeguard against such threats. This course builds critical database security skills that employers are looking for.During the course, you’ll look at key concepts of database management, including relational and non-relational databases. You’ll learn the basics of SQL and databases and practice creating and executing simple SQL statements. You’ll also build foundational knowledge in relational data concepts, such as roles, permissions, and management techniques.   \n\nYou’ll explore database security, including encryption, hashing, masking, tokenization, and permission restrictions. You’ll also review user profiles, password policies, and privileges and learn to design and implement robust database application security and auditing models. In addition, you’ll dive into database injection vulnerabilities, focusing on OS command injection, SQL injection, and more.  \n\nAs you progress, you’ll get hands-on experience in practical labs working on user management and access control, so you have a firm understanding of how to manage, secure, and audit databases effectively.  \n\n  Enroll today to build critical security skills in database management that will capture the attention of employers!  employers!"
  },
  {
    "url": "https://www.coursera.org/learn/database-integration-and-management",
    "name": "Database Integration and Management",
    "what_you_learn": "",
    "skills": "Query Languages, Performance Tuning, Database Design, Relational Databases, Data Security, Data Integrity, Databases, Object-Relational Mapping, Microsoft Copilot, Transaction Processing, Database Management, Data Modeling, SQL, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course covers database integration and management using Entity Framework Core (EF Core) and SQL. You'll learn to set up relational databases, optimize SQL queries, and use Microsoft Copilot to efficiently write, debug, and manage SQL operations.By the end of the course, you will be able to…\n\nDescribe the features and functionalities of Entity Framework Core (EF Core), the structure and principles of relational databases, and performance tuning and optimization techniques for SQL queries.\n\nExplain the steps to set up a relational database, model data using EF Core, retrieve and manipulate data using SQL, and handle transactions and concurrency control in SQL.\n\nDefine the basic syntax and functionalities of SQL, and the principles of advanced query techniques and security best practices for SQL databases.\n\nDevelop practical database operations using Microsoft Copilot, including writing, debugging, and optimizing SQL queries."
  },
  {
    "url": "https://www.coursera.org/learn/database-management-with-java-and-sql",
    "name": "Database Management with Java and SQL",
    "what_you_learn": "Discuss different types of common database configurations.\nDiscuss different types of common database configurations.\nManipulate datasets with Java programming tools and techniques.\nManipulate datasets with Java programming tools and techniques.\nIllustrate the process of data querying and retrieval using SQL with JDBC.\nIllustrate the process of data querying and retrieval using SQL with JDBC.",
    "skills": "Database Application, UI Components, Java Programming, MySQL, Database Management, Query Languages, SQL, Java, User Interface (UI), Relational Databases, Data Access, Software Development, Database Design, Databases, View all skills",
    "instructors": [
      "~163527311"
    ],
    "content": "This is the fourth course in the Amazon Junior Software Developer Professional Certificate. In this course on Introduction to Databases and Basic SQL Queries, you will learn essential knowledge and skills for working with relational databases and querying data using SQL (Structured Query Language). You'll start by understanding fundamental concepts like tables, rows, and columns and learn to write basic SQL queries for operations such as selecting, inserting, updating, and deleting data. You'll interact with the command line to create, populate, and query a simple database. Moving on to SQL Queries, you'll explore advanced topics, including retrieving data from multiple tables using JOINs, filtering data with WHERE clauses, and sorting/grouping data using ORDER BY and GROUP BY clauses, enabling efficient data manipulation within databases. Subsequently, you will delve into JDBC Fundamentals, gaining insights into JDBC (Java Database Connectivity), setting up JDBC drivers and connections, executing SQL queries and commands with JDBC statements, establishing database connections using DriverManager and DataSource, managing database connections effectively, and executing DDL and DML statements for database schema management and data manipulation. By the end of this course, you will be proficient in working with databases, writing SQL queries, and utilizing JDBC to interact with databases in Java applications.After completing this course, you’ll be able to:   \n• Discuss different types of common database configurations.\n• Manipulate datasets with Java programming tools and techniques.\n• Illustrate the process of data querying and retrieval using SQL with JDBC."
  },
  {
    "url": "https://www.coursera.org/learn/database-structures-and-management-with-mysql",
    "name": "Database Structures and Management with MySQL",
    "what_you_learn": "Utilize the MySQL DBMS to build and modify relational databases with SQL.\nUtilize the MySQL DBMS to build and modify relational databases with SQL.\nCreate relationships between tables using primary and foreign keys .\nCreate relationships between tables using primary and foreign keys .",
    "skills": "Relational Databases, Stored Procedure, Data Management, SQL, Database Systems, Data Validation, MySQL, Database Development, Database Management, Database Administration, Data Integrity, Query Languages, Database Design, View all skills",
    "instructors": [
      "~30575670"
    ],
    "content": "Develop a working knowledge of the MySQL database management system (DBMS). Gain DBMS skills such as data creation, querying and manipulation. You’ll gain further experience with SQL statements, clauses and data types.By the end of this course, you’ll be able to: \n \n- Utilize the MySQL DBMS to build and modify relational databases with SQL \n- Add records to a MySQL database \n- Perform intricate queries on database records with filters and groupings \n- Create simple joins and unions within a database \n- Create relationships between tables using primary and foreign keys \n- Demonstrate the ability to complete a database normalization project\n\nYou’ll gain experience with the following tools and software: \n \n- MySQL DBMS \n- Joins and Unions \n- SQL statements, clauses and data types \n- Primary and foreign keys \n- Database normalization"
  },
  {
    "url": "https://www.coursera.org/learn/database-structures-and-management-with-mysql-es",
    "name": "Estructuras y gestión de bases de datos con MySQL",
    "what_you_learn": "Utilizar MySQL DBMS para construir y modificar bases de datos relacionales con SQL.\nUtilizar MySQL DBMS para construir y modificar bases de datos relacionales con SQL.\nCrear relaciones entre tablas utilizando claves primarias y externas.\nCrear relaciones entre tablas utilizando claves primarias y externas.",
    "skills": "Database Management, Data Integrity, Stored Procedure, Relational Databases, SQL, Databases, Data Manipulation, Database Design, Database Architecture and Administration, MySQL, Query Languages",
    "instructors": [
      "~30575670"
    ],
    "content": "Desarrollar un conocimiento práctico del sistema de gestión de bases de datos MySQL (DBMS). Adquirir conocimientos de SGBD, como creación, consulta y manipulación de datos. Adquirirá más experiencia con sentencias SQL, cláusulas y tipos de datos.Al final de este curso, usted será capaz de: \n \n- Utilizar el SGBD MySQL para construir y modificar bases de datos relacionales con SQL \n- Agregar registros a una base de datos MySQL \n- Realizar consultas intrincadas sobre registros de bases de datos con filtros y agrupaciones \n- Crear uniones y uniones simples dentro de una base de datos \n- Crear relaciones entre tablas utilizando claves primarias y externas \n- Demostrar la capacidad de completar un proyecto de normalización de bases de datos\n\nObtendrá experiencia con las siguientes herramientas y software: \n \n- MySQL DBMS \n- Uniones y uniones \n- Sentencias SQL, cláusulas y tipos de datos \n- Claves primarias y externas \n- Normalización de bases de datos"
  },
  {
    "url": "https://www.coursera.org/learn/databricks-to-local-llms",
    "name": "Databricks to Local LLMs",
    "what_you_learn": "Use Databricks for data engineering and ML workloads\nUse Databricks for data engineering and ML workloads\nCreate and design ML pipelines\nCreate and design ML pipelines\nUse Llamafile and other local LLMs like Mixtral\nUse Llamafile and other local LLMs like Mixtral",
    "skills": "Apache Spark, Data Pipelines, Databricks, LLM Application, Responsible AI, MLOps (Machine Learning Operations), Generative AI, Machine Learning, Data Transformation, Extract, Transform, Load, Data Science, Data Lakes, Data Analysis, CI/CD, Large Language Modeling, View all skills",
    "instructors": [
      "derek-wales",
      "~81359500",
      "noahgift"
    ],
    "content": "By the end of this course, a learner will master Databricks to perform data engineering and data analytics tasks for data science workflows.  Additionally, a student will learn to master running local large language models like Mixtral via Hugging Face Candle and Mozilla llamafile."
  },
  {
    "url": "https://www.coursera.org/learn/dataplex-google-cloud",
    "name": "Dataplex by Google Cloud",
    "what_you_learn": "Understand the key features and functionalities of Google Cloud Dataplex.\nUnderstand the key features and functionalities of Google Cloud Dataplex.\nSet up and effectively manage data lakes and warehouses within Dataplex.\nSet up and effectively manage data lakes and warehouses within Dataplex.\nImplement data processing workflows and integrate analytics tools in Dataplex.\nImplement data processing workflows and integrate analytics tools in Dataplex.",
    "skills": "Data Quality, Analytics, Data Lakes, Data Processing, Metadata Management, Identity and Access Management, Data Integration, Data Governance, Google Cloud Platform, Data Warehousing, Data Management, Data Pipelines, Data Security, Automation, View all skills",
    "instructors": [
      "board-infinity"
    ],
    "content": "Welcome to \"Managing Data Lakes & Pipelines with Google Cloud Dataplex\",  a comprehensive course designed to provide a thorough understanding of Google Cloud Dataplex, a platform for managing, monitoring, and analyzing data across various data systems in Google Cloud. Spanning two modules, the course begins with the fundamentals of Dataplex, including its setup, configuration, and basic functionalities. It then progresses to more advanced topics like data processing, analytics integration, task automation, and best practices in data management. This course is ideal for data professionals and cloud enthusiasts seeking to leverage Dataplex for efficient data handling, analysis, and governance in the cloud environment.Module 1: Getting Started with Google Cloud Dataplex introduces the key concepts, setup, and basic operations of Google Cloud Dataplex. This module offers an overview of Dataplex, highlighting its benefits and functionalities. It guides you through setting up and configuring Dataplex, understanding the roles of data lakes and warehouses. Additionally, you'll learn about data ingestion, integration, managing and organizing data, as well as basic security and access control within Dataplex. This module is crucial for those starting their journey in cloud-based data management and analytics.\n\n\"Module 2: Implementing Data Management with Dataplex\" delves deeper into practical aspects of data processing, analytics, and management within Google Cloud Dataplex. This module focuses on leveraging Dataplex for efficient data processing workflows and integrating analytics tools. It also covers automating data tasks for enhanced productivity. Further, it emphasizes best practices for data management, monitoring and optimizing data performance, and understanding compliance and governance issues in Dataplex. Ideal for those seeking to optimize their data management strategies, this module provides advanced insights and skills in Dataplex.\n\nThe course is well-suited for anyone looking to deepen their understanding of managing and analyzing data in a cloud environment, particularly using Google Cloud Dataplex.\n\nDisclaimer: This course is an independent educational resource developed by Board Infinity and is not affiliated with, endorsed by, sponsored by, or officially associated with Alphabet or any of its subsidiaries or affiliates. This course is not an official preparation material of Alphabet. All trademarks, service marks, and company names mentioned are the property of their respective owners and are used for identification purposes only."
  },
  {
    "url": "https://www.coursera.org/learn/datasciencemathskills",
    "name": "Data Science Math Skills",
    "what_you_learn": "",
    "skills": "Data Analysis, Algebra, Calculus, Descriptive Statistics, Data Science, Arithmetic, Bayesian Statistics, Graphing, Probability",
    "instructors": [
      "~23311056",
      "daniel-egger"
    ],
    "content": "Data science courses contain math—no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time.Learners who complete this course will master the vocabulary, notation, concepts, and algebra rules that all data scientists must know before moving on to more advanced material.\n\nTopics include:\n~Set theory, including Venn diagrams\n~Properties of the real number line\n~Interval notation and algebra with inequalities\n~Uses for summation and Sigma notation\n~Math on the Cartesian (x,y) plane, slope and distance formulas\n~Graphing and describing functions and their inverses on the x-y plane,\n~The concept of instantaneous rate of change and tangent lines to a curve\n~Exponents, logarithms, and the natural log function.\n~Probability theory, including Bayes’ theorem.\n\nWhile this course is intended as a general introduction to the math skills needed for data science, it can be considered a prerequisite for learners interested in the course, \"Mastering Data Analysis in Excel,\" which is part of the Excel to MySQL Data Science Specialization.  Learners who master Data Science Math Skills will be fully prepared for success with the more advanced math concepts introduced in \"Mastering Data Analysis in Excel.\" \n\nGood luck and we hope you enjoy the course!"
  },
  {
    "url": "https://www.coursera.org/learn/datascimed",
    "name": "Data Science in Stratified Healthcare and Precision Medicine",
    "what_you_learn": "",
    "skills": "Medical Imaging, Process Driven Development, Machine Learning, Data Analysis, Big Data, Biomedical Technology, Molecular Biology, Graph Theory, Health Informatics, Statistical Modeling, Precision Medicine, Text Mining, Probability & Statistics, Network Analysis, Bioinformatics, Natural Language Processing, Image Analysis, Python Programming, Data Science, View all skills",
    "instructors": [
      "franceswong",
      "aretimanataki"
    ],
    "content": "An increasing volume of data is becoming available in biomedicine and healthcare, from genomic data, to electronic patient records and data collected by wearable devices. Recent advances in data science are transforming the life sciences, leading to precision medicine and stratified healthcare.In this course, you will learn about some of the different types of data and computational methods involved in stratified healthcare and precision medicine.  You will have a hands-on experience of working with such data.  And you will learn from leaders in the field about successful case studies. \n\nTopics include: (i) Sequence Processing, (ii) Image Analysis, (iii) Network Modelling, (iv) Probabilistic Modelling, (v) Machine Learning, (vi) Natural Language Processing, (vii) Process Modelling and (viii) Graph Data.\n\nWatch the course promo video here: http://edin.ac/2pn350P"
  },
  {
    "url": "https://www.coursera.org/learn/datavisualization",
    "name": "Data Visualization",
    "what_you_learn": "",
    "skills": "Data Visualization, Tableau Software, Data Presentation, Scatter Plots, Dashboard, Graphing, Data Storytelling, Data Visualization Software, Data Mapping, Plot (Graphics), Interactive Data Visualization, View all skills",
    "instructors": [
      "john-hart"
    ],
    "content": "This course will teach you how to make more effective visualizations of data. Not only will you gain deeper insight into the data, but you will also learn how to better communicate that insight to others. You will learn new ways to display data, applying some fundamental principles of design and human cognition to choose the most effective way to display different kinds of data. This course not only teaches you how to use popular applications like Tableau to connect to data warehouses to extract and visualize relevant data, but also teaches you how Tableau works so you can use the same techniques to make effective data visualizations on your own with any visualization system."
  },
  {
    "url": "https://www.coursera.org/learn/dataviz-dashboards",
    "name": "Creating Dashboards and Storytelling with Tableau",
    "what_you_learn": "Combine the data and follow the best practices to present your story\nCombine the data and follow the best practices to present your story\nCreate calculated fields for KPIs to build a figure that will be used to measure progress in the data\nCreate calculated fields for KPIs to build a figure that will be used to measure progress in the data\nAssemble a dashboard\nAssemble a dashboard\nAnalyze concepts and techniques for compelling storytelling with data\nAnalyze concepts and techniques for compelling storytelling with data",
    "skills": "Data Visualization, Data Presentation, Storyboarding, Data Visualization Software, Dashboard, Data Quality, Data Manipulation, Tableau Software, Requirements Analysis, Data Storytelling, Data Cleansing, Stakeholder Analysis, Stakeholder Management, View all skills",
    "instructors": [
      "hunter-whitney",
      "govind-acharya"
    ],
    "content": "In this course, you’ll learn how to create Tableau dashboards that connect data to decision-making. Starting with stakeholder planning and data requirements, you’ll define goals, success metrics, and key questions. Then, you’ll clean and prepare a real-world tech salary dataset using Tableau’s filtering, aliasing, and data type tools. You’ll turn these insights into impactful dashboards using calculated fields, grouping, and interactivity. Finally, you’ll explore how to interpret and present dashboards effectively through Socratic dialogue—critiquing design choices, analyzing KPIs, and refining your data story. By the end, you’ll be able to deliver dashboards that are insightful, persuasive, and tailored to audience needs."
  },
  {
    "url": "https://www.coursera.org/learn/dataviz-design",
    "name": "Essential Design Principles for Tableau",
    "what_you_learn": "Examine and improve an ineffective visualization\nExamine and improve an ineffective visualization\nExamine and improve an ineffective visualization\nExamine and improve an ineffective visualization\nApply visualization best practices\nApply visualization best practices\nCreate and design visualizations that work best for the target audience\nCreate and design visualizations that work best for the target audience",
    "skills": "Design Elements And Principles, Tableau Software, Data Visualization Software, Data Visualization, Human Factors, Data Analysis, Data Storytelling, Data Presentation, Data Ethics, Color Theory, Exploratory Data Analysis, User Centered Design, View all skills",
    "instructors": [
      "hunter-whitney",
      "govind-acharya"
    ],
    "content": "In this course, you will analyze and apply essential design principles to your Tableau visualizations. This course assumes you understand the tools within Tableau and have some knowledge of the fundamental concepts of data visualization. You will define and examine the similarities and differences of exploratory and explanatory analysis as well as begin to ask the right questions about what’s needed in a visualization. You will assess how data and design work together, including how to choose the appropriate visual representation for your data, and the difference between effective and ineffective visuals. You will apply effective best practice design principles to your data visualizations and be able to illustrate examples of strategic use of contrast to highlight important elements. You will evaluate pre-attentive attributes and why they are important in visualizations. You will exam the importance of using the \"right\" amount of color and in the right place and be able to apply design principles to de-clutter your data visualization."
  },
  {
    "url": "https://www.coursera.org/learn/dataviz-project",
    "name": "Data Visualization with Tableau Project",
    "what_you_learn": "Develop a project proposal\nDevelop a project proposal\nAssess the quality of the data and perform exploratory analysis\nAssess the quality of the data and perform exploratory analysis\nCreate KPIs and dashboards and assess your analysis\nCreate KPIs and dashboards and assess your analysis\nCreate your data story and write a narrative to accompany your visualization\nCreate your data story and write a narrative to accompany your visualization",
    "skills": "Tableau Software, Data Presentation, Data Visualization, Data Import/Export, Data Storytelling, Data Cleansing, Design, Data Analysis, Exploratory Data Analysis, Proposal Development, Dashboard, Data Quality, Visual Design, Data Literacy, Data Visualization Software, Interactive Data Visualization, View all skills",
    "instructors": [
      "hunter-whitney",
      "suk-brar"
    ],
    "content": "In this project-based course, you will follow your own interests to create a portfolio worthy single-frame viz or multi-frame data story that will be shared on Tableau Public. You will use all the skills taught in this Specialization to complete this project step-by-step, with guidance from your instructors along the way. You will first create a project proposal to identify your goals for the project, including the question you wish to answer or explore with data. You will then find data that will provide the information you are seeking. You will then import that data into Tableau and  prepare it for analysis. Next you will create a dashboard that will allow you to explore the data in depth and identify meaningful insights. You will then give structure to your data story by writing the story arc in narrative form. Finally, you will consult your design checklist to craft the final viz or data story in Tableau. This is your opportunity to show the world what you’re capable of - so think big, and have confidence in your skills!"
  },
  {
    "url": "https://www.coursera.org/learn/dataviz-visual-analytics",
    "name": "Visual Analytics with Tableau",
    "what_you_learn": "Create a chart using Tableau\nCreate a chart using Tableau\nCreate dates using calculated fields\nCreate dates using calculated fields\nCustomize table calculations\nCustomize table calculations\nCustomize and create dual layer maps\nCustomize and create dual layer maps",
    "skills": "Scatter Plots, Data Mapping, Histogram, Data Storytelling, Data Analysis Expressions (DAX), Interactive Data Visualization, Tree Maps, Pivot Tables And Charts, Forecasting, Heat Maps, Data Visualization, Geospatial Mapping, Data Visualization Software, Advanced Analytics, Tableau Software, Analytics, View all skills",
    "instructors": [
      "suk-brar",
      "peter-chen"
    ],
    "content": "In this third course of the specialization, we’ll drill deeper into the tools Tableau offers in the areas of charting, dates, table calculations and mapping. We’ll explore the best choices for charts, based on the type of data you are using. We’ll look at specific types of charts including scatter plots, Gantt charts, histograms, bullet charts and several others, and we’ll address charting guidelines. We’ll define discrete and continuous dates, and examine when to use each one to explain your data.  You’ll learn how to create custom and quick table calculations and how to create parameters. We’ll also introduce mapping and explore how Tableau can use different types of geographic data, how to connect to multiple data sources and how to create custom maps."
  },
  {
    "url": "https://www.coursera.org/learn/davinci-resolve-15-tips-from-a-pro-colorist",
    "name": "DaVinci Resolve: 15 Tips from a Pro Colorist",
    "what_you_learn": "",
    "skills": "Cloud-Based Integration, Post-Production, Editing, Collaborative Software, Color Theory, Video Editing, Image Quality",
    "instructors": [
      "~186501695"
    ],
    "content": "In this condensed course, I give you 15 Top time-tested tips used by professionals in DaVinci Resolve.This course is for everyone, whether you're an experienced filmmaker or a beginner, you'll find great use with all of these insider tips. \n\nThis course is for anyone wanting to learn new tools in Resolve to make their grades better and their editing much more efficient. \n\nIn this course we'll cover:\n* Contrast Pivot\n* HDR Tools\n* HDR Exposure\n* HDR Lights\n* HDR Black Offset\n* Power Bins\n* Power Grades\n* Cut Page\n* Voice Isolation and much more!\n\nAfter this course, you'll have the confidence and knowledge to jump into your next project and efficiently start creating using Da Vinci Resolve!\n\nAbout Your Teacher:\nFred Trevino is a colorist at Beambox Studio and a Skillshare Top Teacher, grading projects for filmmakers and clients around the world. He has worked on over 60 feature films as well as hundreds of music videos, shorts, documentaries, commercials, and web spots.\n\nFred’s corporate clients include HBO, ESPN, Shiseido, Under Armour, Sundance Channel, TruTV, and Pepsi. His work has screened at major festivals like Sundance, Cannes, and Slamdance. Based in New York City, he also enjoys street photography.\n\nFred’s courses guide learners from beginner-level color grading to advanced industry techniques, including creating cinematic looks, matching shots, and professional workflows in DaVinci Resolve."
  },
  {
    "url": "https://www.coursera.org/learn/davinci-resolve-19-masterclass-advanced-effects--exporting",
    "name": "DaVinci Resolve 19 Masterclass: Advanced Effects & Exporting",
    "what_you_learn": "",
    "skills": "Motion Graphics, Animations, Data Import/Export, Color Theory, Post-Production, Video Editing, Image Quality, Timelines, Video Production",
    "instructors": [
      "~186501695"
    ],
    "content": "Instructor: Adi SinghUnlock the full creative power of DaVinci Resolve 19 with this advanced course focused on visual effects, cinematic polish, and expert exporting. You’ll dive deep into Fusion tools like attaching text to objects, greenscreen compositing, locked-on stabilization, travel map animations, and cut-out effects. You’ll also explore premium tools in the Studio version including Magic Mask, Halation, Noise Reduction, Film Look Creator, and Film Grain.\n\nOn the Color Page, you’ll continue developing your grading skills with techniques like layering nodes, creating power grades, and generating high-quality screenshots for thumbnails or delivery. Finally, wrap your workflow with advanced export settings to ensure your project looks flawless on any platform.\nFor your final project, you’ll create and export a polished 60–90 second video that uses at least one advanced visual or color effect. If you're ready to push creative boundaries and master Resolve’s most powerful tools, this course is your final step to becoming a true post-production pro.\n\nInstructor bio:\nAdi is a videographer, content creator, and educator whose journey began in 2015 with a camera purchased to document travels in New Zealand. What started as a passion quickly grew into a career — today, Adi runs a video production company and a thriving YouTube channel, sharing creative knowledge with a global audience.\n\nHaving built his own filmmaking career through online learning and self-teaching, Adi is passionate about giving back by teaching others. His courses are designed to make videography approachable and practical, helping learners gain the skills and confidence to create professional-quality content."
  },
  {
    "url": "https://www.coursera.org/learn/davinci-resolve-19-masterclass-audio--visual-polish",
    "name": "DaVinci Resolve 19 Masterclass: Audio & Visual Polish",
    "what_you_learn": "",
    "skills": "Editing, Video Editing, Post-Production, Color Theory, Timelines, Storytelling, Image Quality, Web Content Accessibility Guidelines, Music",
    "instructors": [
      "~186501695"
    ],
    "content": "Instructor: Adi SinghTake your video editing to the next level by mastering the art of audio and visual refinement in DaVinci Resolve 19. This intermediate course focuses on polishing your projects with professional-grade tools and techniques. You’ll learn how to clean up audio using tools like voice isolation and music remixer, and enhance clarity with audio transcription and retime scaling features. Then, step into the powerful Color Page to explore core grading tools like node trees, color wheels, curves, white balance, and primary corrections for vibrant, cinematic visuals.\n\nWe’ll also walk through how to apply targeted adjustments using tools like the qualifier and power windows, plus you’ll learn to color grade footage from Sony, Canon, and Apple log profiles. By the end, you’ll elevate an edited video by applying both audio corrections and professional color grading techniques in a cohesive, hands-on project. If you want your videos to look and sound like they were made by a pro—this course is for you.\n\nInstructor bio:\nAdi is a videographer, content creator, and educator whose journey began in 2015 with a camera purchased to document travels in New Zealand. What started as a passion quickly grew into a career — today, Adi runs a video production company and a thriving YouTube channel, sharing creative knowledge with a global audience.\n\nHaving built his own filmmaking career through online learning and self-teaching, Adi is passionate about giving back by teaching others. His courses are designed to make videography approachable and practical, helping learners gain the skills and confidence to create professional-quality content."
  },
  {
    "url": "https://www.coursera.org/learn/davinci-resolve-19-masterclass-video-editing-basics",
    "name": "DaVinci Resolve 19 Masterclass: Video Editing Basics",
    "what_you_learn": "",
    "skills": "Configuration Management, Color Matching, Motion Graphics, Timelines, Editing, File Management, Video Editing, Data Import/Export, Animations",
    "instructors": [
      "~186501695"
    ],
    "content": "Instructor: Adi SinghStart your journey into the world of video editing with DaVinci Resolve 19—the go-to tool for creators, editors, and filmmakers. In this beginner-friendly course, you’ll learn the essential skills to confidently navigate the software, set up your projects, and edit your first video from start to finish. We’ll cover everything from project and color management settings to trimming clips, working with timelines, using transitions, and adding text animations. You'll also explore productivity-boosting features like smart bins, proxy media, and keyboard shortcuts that streamline your workflow.\n\nBy the end of the course, you'll have edited and exported your own 30–60 second video using provided footage, complete with clean cuts, smooth transitions, and a professional touch. Whether you’re brand new to video editing or switching to Resolve from another platform, this course provides the strong foundation you need to bring your creative vision to life.\n\nInstructor bio:\nAdi is a videographer, content creator, and educator whose journey began in 2015 with a camera purchased to document travels in New Zealand. What started as a passion quickly grew into a career — today, Adi runs a video production company and a thriving YouTube channel, sharing creative knowledge with a global audience.\n\nHaving built his own filmmaking career through online learning and self-teaching, Adi is passionate about giving back by teaching others. His courses are designed to make videography approachable and practical, helping learners gain the skills and confidence to create professional-quality content."
  },
  {
    "url": "https://www.coursera.org/learn/deaf-culture",
    "name": "American Deaf Culture",
    "what_you_learn": "",
    "skills": "Special Education, Social Justice, Communication Disorders, Non-Verbal Communication, Cultural Diversity, Social Sciences, Education and Training, Disabilities, Language Learning, Sociology, Diversity Awareness, Culture, Civil Law, View all skills",
    "instructors": [
      "tbrittain"
    ],
    "content": "This is a six-week course providing a historical overview of the American Deaf community and its evolving culture.  Theoretical frameworks from sociology are explored.  Deafness as a culture and not a disability is explained as participants are guided into the world of Deaf culture."
  },
  {
    "url": "https://www.coursera.org/learn/decentralized-apps-on-blockchain",
    "name": "Decentralized Applications (Dapps)",
    "what_you_learn": "This third course of the Blockchain specialization prepares you to design and develop end-to-end decentralized applications (Dapps).\nThis third course of the Blockchain specialization prepares you to design and develop end-to-end decentralized applications (Dapps).",
    "skills": "Software Development Tools, Software Architecture, Application Design, Integrated Development Environments, Test Driven Development (TDD), Web Applications, Blockchain, Application Development, Software Testing, View all skills",
    "instructors": [
      "~5767003"
    ],
    "content": "This third course of the Blockchain specialization prepares you to design and develop end-to-end decentralized applications (Dapps) – which provide anyone with access to the blockchain’s features and services. You will use Truffle IDE, smart contracts, a simple web client and a MetaMask client. You will learn about the architecture of a Dapp: the front-end client interface, backed by the blockchain and smart contracts. The course covers the basic design of a Dapp, Truffle development process and commands (init, develop, test and migrate), test-driven development of Dapp, Dapp application models and emerging standards that are essential for predictable Dapp behavior.Main concepts are delivered through videos, demos and hands-on exercises."
  },
  {
    "url": "https://www.coursera.org/learn/decentralized-finance-deep-dive-duke",
    "name": "Decentralized Finance (DeFi) Deep Dive",
    "what_you_learn": "Mechanics of credit and lending protocols; Decentralized exchange implementations; Derivatives and tokenization protocols.\nMechanics of credit and lending protocols; Decentralized exchange implementations; Derivatives and tokenization protocols.",
    "skills": "Digital Assets, Risk Management, Derivatives, Market Data, Asset Management, Commercial Lending, Lending and Underwriting, FinTech, Market Liquidity, Financial Trading, Portfolio Management, Transaction Processing, Securities (Finance), Blockchain, View all skills",
    "instructors": [
      "~46121307"
    ],
    "content": "DeFi and the Future of Finance is a set of four courses that focus on decentralized finance. The third course is called DeFi Deep Dive. It is essential that you do the first two courses I. DeFi Infrastructure and II. DeFi Primitives before doing this course. It is the longest of the four courses and focuses on some of the leading protocols in the DeFi space. We will look at Credit and Lending (and feature MakerDAO, Compound and Aave), Decentralized Exchange with an analysis of how protocols like Uniswap and Balancer works, Derivatives (featuring Yield Protocol, dYdX and Synthetix) and Tokenization with an analysis of Set Protocol as well as wrapped bitcoin. For many of these leading protocols, we include detailed examples of how the mechanics work. For example, we show how to use a dYdX flash swap to execute an arbitrage transaction (take advantage of different prices on different exchanges for the same asset)."
  },
  {
    "url": "https://www.coursera.org/learn/decentralized-finance-infrastructure-duke",
    "name": "Decentralized Finance (DeFi) Infrastructure",
    "what_you_learn": "Articulate the history and origins of decentralized finance\nArticulate the history and origins of decentralized finance\nDefine the key components of decentralized finance's infrastructure\nDefine the key components of decentralized finance's infrastructure\nExplain which problems decentralized finance is designed to solve and how\nExplain which problems decentralized finance is designed to solve and how\nIdentify myths or common misconceptions about decentralized finance\nIdentify myths or common misconceptions about decentralized finance",
    "skills": "Encryption, Financial Inclusion, Financial Regulation, Computer Security, Payment Systems, Interoperability, Digital Assets, Blockchain, Cryptography, FinTech, Banking, Governance, Financial Systems",
    "instructors": [
      "~46121307"
    ],
    "content": "Decentralized Finance: The Future of Finance is a set of four courses taught by Campbell R. Harvey (Professor of Finance at the Fuqua School of Business, Duke University, and a Research Associate of the National Bureau of Economic Research) that focus on decentralized finance (DeFi). In this first course, we begin by exploring the origins of DeFi and take a broad historical view from the earliest barter economies, such as the first peer-to-peer exchanges of bartering, to present day. The course also looks at historical examples of money having value even though it is not officially backed.We then focus on the key infrastructure components: blockchain, cryptocurrency, smart contracts, oracles, stablecoins and decentralized applications (or dApps). This includes discussion of the mechanics of the Ethereum and Bitcoin blockchains including cryptographic hashing.  \n\nNext, we focus on the specific problems that DeFi is designed to solve: inefficiency (costly, slow, and insecure today), limited access (1.7 billion are unbanked), opacity (we need to trust regulators to monitor banks and the regulators have mixed records), centralized control (financial system is oligopolistic imposing higher fees than we would have in a competitive market) and lack of interoperability (it is difficult to move funds from one financial institution to another today). The course closes by exploring many of the myths about the crypto space."
  },
  {
    "url": "https://www.coursera.org/learn/decentralized-finance-primitives-duke",
    "name": "Decentralized Finance (DeFi) Primitives",
    "what_you_learn": "Token design and NFTs\nToken design and NFTs\nMechanics of supply adjustment\nMechanics of supply adjustment\nDecentralized exchange\nDecentralized exchange",
    "skills": "FinTech, Key Management, Transaction Processing, Payment Systems, Financial Trading, Digital Assets, Cryptography, Loans, Market Liquidity",
    "instructors": [
      "~46121307"
    ],
    "content": "DeFi and the Future of Finance is a set of four courses that focus on decentralized finance. The second course is called DeFi Primitives. It is recommended that you take the first course, DeFi Infrastructure, before this course. In this course, we talk about transaction mechanics and introduce both fungible and non-fungible tokens – or NFTs. The course explores the important issue of custody (holding private keys). The course then explores supply adjustment which includes the minting and burning of tokens. The mechanics of bonding curves are introduced. The course then explores the role of direct as well as indirect  incentives in the DeFi system.  We then analyze swaps or decentralized exchange. We begin by contrasting DEX with centralized exchange (e.g., Coinbase or Binance). The course details the mechanics of Automated Market Makers and provides a number of detailed examples. There is a discussion of impermanent loss as well as (legal) front-running. We end the course by exploring both collateralized and flash loans."
  },
  {
    "url": "https://www.coursera.org/learn/decision-making",
    "name": "Data-driven Decision Making",
    "what_you_learn": "",
    "skills": "Data-Driven Decision-Making, Data Visualization Software, Case Studies, Data Analysis, Big Data, Data Presentation, Data Visualization, Business Intelligence, Business Analytics, Data Collection, Analytics, Statistical Programming, Microsoft Excel, View all skills",
    "instructors": [
      "~19932496"
    ],
    "content": "Welcome to Data-driven Decision Making. In this course, you'll get an introduction to Data Analytics and its role in business decisions. You'll learn why data is important and how it has evolved. You'll be introduced to “Big Data” and how it is used. You'll also be introduced to a framework for conducting Data Analysis and what tools and techniques are commonly used. Finally, you'll have a chance to put your knowledge to work in a simulated business setting.This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017."
  },
  {
    "url": "https://www.coursera.org/learn/decision-making-and-governance-of-natural-disaster-risk",
    "name": "Decision Making and Governance of Natural Disaster Risk",
    "what_you_learn": "Identify technical and economic feasibility concepts of infrastructure projects.\nIdentify technical and economic feasibility concepts of infrastructure projects.\nDistinguish the different existing quantitative indicators to prioritize investments and their calculations.\nDistinguish the different existing quantitative indicators to prioritize investments and their calculations.\nIdentify key components of risk governance, as well as steps for an informed public investment system.\nIdentify key components of risk governance, as well as steps for an informed public investment system.",
    "skills": "Risk Management, Quantitative Research, Feasibility Studies, Prioritization, Business Risk Management, Public Policies, Risk Analysis, Governance, Project Risk Management, Decision Making, Cost Benefit Analysis, Economic Development, Climate Change Adaptation, View all skills",
    "instructors": [
      "rguerrero",
      "doriss",
      "slacambra",
      "cusechemelo"
    ],
    "content": "This course will teach you how to manage disaster risks in infrastructure projects. You will learn about the technical and economic feasibility of projects, as well as how to prioritize investments using quantitative indicators and their calculation. You will also learn about the concepts of efficiency and equity, and how to incorporate them into risk analysis.Additionally, you will understand the key components of risk governance, as well as the steps for an informed public investment system.\n\nThis course is ideal for individuals interested in risk management, project planning, and climate change. It will also be useful for those working in government, non-governmental organizations, or the private sector.\n\n**This course is part of a Specialization. Before starting it, we recommend taking Course 2: Qualitative and Quantitative Analysis of Disaster Risk."
  },
  {
    "url": "https://www.coursera.org/learn/decision-making-how-to-choose-the-right-problem-to-solve",
    "name": "Decision Making - How to Choose the Right Problem to Solve",
    "what_you_learn": "Evaluate personal skills for problem solving and describe how problems exist in wider contexts\nEvaluate personal skills for problem solving and describe how problems exist in wider contexts\nDevelop an idea to approach a real life problem and explore methods to minimise risk and turn ideas into plans\nDevelop an idea to approach a real life problem and explore methods to minimise risk and turn ideas into plans\nExplain the importance of the wider impact when proposing solutions and produce a plan that persuades others your solution will work\nExplain the importance of the wider impact when proposing solutions and produce a plan that persuades others your solution will work",
    "skills": "Prioritization, Strategic Decision-Making, Peer Review, Analysis, Critical Thinking, Estimation, Persuasive Communication, Problem Solving, Decision Making, Brainstorming, Professional Development, Risk Analysis, View all skills",
    "instructors": [
      "~128077952"
    ],
    "content": "Life is full of problems. The question is, which problems do you try to solve first and how?Learn powerful decision-making methods and how to cultivate problem-solving skills for a range of issues we all face in the workplace and beyond. In this course, you’ll evaluate your current problem-solving approach and learn techniques that will sharpen your analytical and critical skills required to help you quickly resolve issues. \n\nDefining a problem is the first step to developing a solution and so you will explore methods that will help you define the real issues. You will then experiment with decision-making techniques such as a SWOT analysis to help you quickly evaluate your options clearly and set priorities when everything seems urgent. Once you can identify a problem and understand it, you’ll learn how to explore the benefits and drawbacks of various solutions and methods to minimise risks.\n\nThis course is one of many, offered by Click Start, a UK training programme designed to help young people develop digital skills. Click Start offers a limited number of scholarships giving free access to young people in the UK. Check the FAQs to see more detail and follow the link to check if you are eligible for free access today.\n\nYou will then apply all the skills you learnt and discover how to create a detailed plan to persuade others that your ideas will work. By the end of this course, you’ll be able to tackle real-world problems and have the confidence to pitch your ideas and get your colleagues on board."
  },
  {
    "url": "https://www.coursera.org/learn/decisionmaking",
    "name": "Decision-Making",
    "what_you_learn": "",
    "skills": "Resourcefulness, Ethical Standards And Conduct, Complex Problem Solving, Risk Analysis, Decision Making, Analysis, Business Ethics, Critical Thinking and Problem Solving, Strategic Decision-Making, Creative Problem-Solving, View all skills",
    "instructors": [
      "~123403555"
    ],
    "content": "Do you want to more effectively handle complex challenges? In this Decision-making specialization, learn how to solve problems, make decisions and think creatively to tackle your problems head-on with decisive action!"
  },
  {
    "url": "https://www.coursera.org/learn/decisions-decisions-dashboards-and-reports",
    "name": "Decisions, Decisions: Dashboards and Reports",
    "what_you_learn": "Design BI visualizations\nDesign BI visualizations\nPractice using BI reporting and dashboard tools\nPractice using BI reporting and dashboard tools\nCreate presentations to share key BI insights with stakeholders\nCreate presentations to share key BI insights with stakeholders\nDevelop professional materials for your job search\nDevelop professional materials for your job search",
    "skills": "Data Storytelling, Business Reporting, Presentations, Stakeholder Communications, Dashboard, Performance Tuning, Data Visualization, Business Intelligence, Interviewing Skills, Data Visualization Software, Tableau Software, Data Presentation, View all skills",
    "instructors": [
      "google-career-certificates"
    ],
    "content": "You’re almost there! This is the third course in the Google Business Intelligence Certificate. In this course, you’ll apply your understanding of stakeholder needs, plan and create BI visuals, and design reporting tools, including dashboards. You’ll also explore how to answer business questions with flexible and interactive dashboards that can monitor data over long periods of time.Google employees who currently work in BI will guide you through this course by providing hands-on activities that simulate job tasks, sharing examples from their day-to-day work, and helping you build business intelligence skills to prepare for a career in the field. \n\nLearners who complete the four courses in this certificate program will have the skills needed to apply for business intelligence jobs. This certificate program assumes prior knowledge of foundational analytical principles, skills, and tools covered in the Google Data Analytics Certificate.  \n\nBy the end of this course, you will:\n-Explain how BI visualizations answer business questions\n-Identify complications that may arise during the creation of BI visualizations\n-Produce charts that represent BI data monitored over time\n-Use dashboard and reporting tools\n-Build dashboards using best practices to meet stakeholder needs\n-Iterate on a dashboard to meet changing project requirements\n-Design BI presentations to share insights with stakeholders\n-Create or update a resume and prepare for BI interviews"
  },
  {
    "url": "https://www.coursera.org/learn/decoding-nutrition-labels",
    "name": "Decoding Nutrition Labels",
    "what_you_learn": "The history of when food labels were first required.\nThe history of when food labels were first required.\nCurrent FDA approved food labels in addition to providing all the hidden details and information most people miss.\nCurrent FDA approved food labels in addition to providing all the hidden details and information most people miss.\nWhy food labels are important information for you, the consumer, the energy content and nutrition content the food you are consuming.\nWhy food labels are important information for you, the consumer, the energy content and nutrition content the food you are consuming.",
    "skills": "Nutrition and Diet, Food Quality Assurance And Control, Nutrition Education, Nutritional Assessment",
    "instructors": [
      "~172804225"
    ],
    "content": "On their surface, food labels might seem simple. However, when digging deeper into the history of when, why, and how they came about, and how they have evolved into their current form, you learn a lot about how our food system actually works."
  },
  {
    "url": "https://www.coursera.org/learn/deductive-reasoning",
    "name": "Think Again II: How to Reason Deductively",
    "what_you_learn": "",
    "skills": "Logical Reasoning, Mathematical Modeling, Deductive Reasoning, Computational Logic, Scientific Methods",
    "instructors": [
      "~935146",
      "~932346"
    ],
    "content": "Deductive arguments are supposed to be valid in the sense that the premises guarantee that the conclusion is true. In this course, you will learn how to use truth-tables and Venn diagrams to represent the information contained in the premises and conclusion of an argument so that you can determine whether or not the argument is deductively valid.Suggested Readings:\nStudents who want more detailed explanations or additional exercises or who want to explore these topics in more depth should consult Understanding Arguments: An Introduction to Informal Logic, Ninth Edition, Concise, Chapters 6 and 7 by Walter Sinnott-Armstrong and Robert Fogelin.\n\nCourse Format:\nEach week will be divided into multiple video segments that can be viewed separately or in groups. There will be short ungraded quizzes after each segment (to check comprehension) and a longer graded quiz at the end of the course."
  },
  {
    "url": "https://www.coursera.org/learn/deep-excavations-and-support-system",
    "name": "Deep Excavations and Support Systems",
    "what_you_learn": "Types of Pre- Excavation support systems – Rock Anchors, Umbrella Arch method, Pre-Grouting, Freezing\nTypes of Pre- Excavation support systems – Rock Anchors, Umbrella Arch method, Pre-Grouting, Freezing\nDiaphram walls, Secant pile walls, Contigious pile walls, Soldier piles,Diaphrgam walls\nDiaphram walls, Secant pile walls, Contigious pile walls, Soldier piles,Diaphrgam walls\nSignificance of Pre Excavation Support systems  and Overveiw of Plaxis 2D,Wallap, RocLab and RS2\nSignificance of Pre Excavation Support systems  and Overveiw of Plaxis 2D,Wallap, RocLab and RS2",
    "skills": "Construction, Engineering Practices, Finite Element Methods, Engineering, Scientific, and Technical Instruments, Structural Analysis, Building Codes, Civil Engineering, Construction Engineering, Engineering Calculations, Engineering Design Process, Mathematical Software, Engineering Analysis, Environmental Engineering, Structural Engineering, Laboratory Testing, Simulation and Simulation Software, View all skills",
    "instructors": [
      "~113266557"
    ],
    "content": "The course on \"Deep Excavations and Support Systems\" offers a comprehensive journey through the intricacies of underground construction and soil retention. Beginning with an exploration of tunnels, caverns, and shafts, the course covers diverse applications and construction methods, emphasizing stress distribution complexities and the pivotal role of site investigation. It then delves into Pre-Excavation Support Systems, dissecting rock mass classification, excavation methods, and various support techniques like Ground Freezing and Face Grouting. The Retaining Systems module follows, providing insights into structures for soil stabilization, including Contiguous Pile, Secant Pile, Soldier Pile, Sheet Pile, and D-Wall. The final module, \"Concepts and Tools in Embedded Retaining Systems,\" addresses design parameters, lateral earth pressures, and numerical modeling, integrating practical applications and relevant codes. This comprehensive course equips learners with the knowledge and skills needed for efficient, safe, and successful deep excavation projects. This course is majorly for consumption in the Indian subcontinent and the target audience are undergraduate and post graduate students, faculties and freshers who has entered the industry as young professionals.Target Learners \n\nThis course is majorly for the leaners in the Indian Subcontinent\n\tUndergraduate students in Civil Engineering \n\tpost graduate students in geotechnical Engineering\n\tfaculties and freshers who has entered the industry as young professionals"
  },
  {
    "url": "https://www.coursera.org/learn/deep-learning-computer-vision",
    "name": "Deep Learning Applications for Computer Vision",
    "what_you_learn": "Learners will be able to explain what Computer Vision is and give examples of Computer Vision tasks.\nLearners will be able to explain what Computer Vision is and give examples of Computer Vision tasks.\nLearners will be able to describe the process behind classic algorithmic solutions to Computer Vision tasks and explain their pros and cons.\nLearners will be able to describe the process behind classic algorithmic solutions to Computer Vision tasks and explain their pros and cons.\nLearners will be able to use hands-on modern machine learning tools and python libraries.\nLearners will be able to use hands-on modern machine learning tools and python libraries.",
    "skills": "Deep Learning, Machine Learning, Tensorflow, Supervised Learning, Image Analysis, Artificial Neural Networks, Performance Tuning, Artificial Intelligence and Machine Learning (AI/ML), Computer Vision, Applied Machine Learning, View all skills",
    "instructors": [
      "ioana-fleming"
    ],
    "content": "In this course, you’ll be learning about Computer Vision as a field of study and research. First we’ll be exploring several Computer Vision tasks and suggested approaches, from the classic Computer Vision perspective. Then we’ll introduce Deep Learning methods and apply them to some of the same problems. We will analyze the results and discuss advantages and drawbacks of both types of methods. We'll use tutorials to let you explore hands-on some of the modern machine learning tools and software libraries. Examples of Computer Vision tasks where Deep Learning can be applied include: image classification, image classification with localization, object detection, object segmentation, facial recognition, and activity or pose estimation.This course can be taken for academic credit as part of CU Boulder’s MS in Data Science or MS in Computer Science degrees offered on the Coursera platform. These fully accredited graduate degrees offer targeted courses, short 8-week sessions, and pay-as-you-go tuition. Admission is based on performance in three preliminary courses, not academic history. CU degrees on Coursera are ideal for recent graduates or working professionals. Learn more: \n\nMS in Data Science: https://www.coursera.org/degrees/master-of-science-data-science-boulder \n\nMS in Computer Science: https://coursera.org/degrees/ms-computer-science-boulder"
  },
  {
    "url": "https://www.coursera.org/learn/deep-learning-natural-language-processing",
    "name": "Deep Learning for Natural Language Processing",
    "what_you_learn": "Define feedforward networks, recurrent neural networks, attention, and transformers.\nDefine feedforward networks, recurrent neural networks, attention, and transformers.\nImplement and train feedforward networks, recurrent neural networks, attention, and transformers.\nImplement and train feedforward networks, recurrent neural networks, attention, and transformers.\nDescribe the idea behind transfer learning and frequently used transfer learning algorithms.\nDescribe the idea behind transfer learning and frequently used transfer learning algorithms.\nDesign and implement their own neural network architectures for natural language processing tasks.\nDesign and implement their own neural network architectures for natural language processing tasks.",
    "skills": "LLM Application, Prompt Engineering, Keras (Neural Network Library), Deep Learning, Artificial Neural Networks, Artificial Intelligence, PyTorch (Machine Learning Library), Machine Learning Algorithms, Natural Language Processing, Generative AI, Network Architecture, Large Language Modeling, View all skills",
    "instructors": [
      "~101848291"
    ],
    "content": "Deep learning has revolutionized the field of natural language processing and led to many state-of-the-art results. This course introduces students to neural network models and training algorithms frequently used in natural language processing. At the end of this course, learners will be able to explain and implement feedforward networks, recurrent neural networks, and transformers. They will also have an understanding of transfer learning and the inner workings of large language models.This course can be taken for academic credit as part of CU Boulder’s MS in Data Science or MS in Computer Science degrees offered on the Coursera platform. These fully accredited graduate degrees offer targeted courses, short 8-week sessions, and pay-as-you-go tuition. Admission is based on performance in three preliminary courses, not academic history. CU degrees on Coursera are ideal for recent graduates or working professionals. Learn more: \n\nMS in Data Science: https://www.coursera.org/degrees/master-of-science-data-science-boulder \n\nMS in Computer Science: https://coursera.org/degrees/ms-computer-science-boulder"
  },
  {
    "url": "https://www.coursera.org/learn/deep-learning-reinforcement-learning",
    "name": "Deep Learning and Reinforcement Learning",
    "what_you_learn": "",
    "skills": "Generative Model Architectures, Reinforcement Learning, Machine Learning Algorithms, Applied Machine Learning, Machine Learning, Deep Learning, Unsupervised Learning, Image Analysis, Keras (Neural Network Library), Computer Vision, Artificial Neural Networks, Natural Language Processing, Artificial Intelligence, Dimensionality Reduction, View all skills",
    "instructors": [
      "~106389453",
      "miguelmaldonado",
      "~28511493",
      "mark-grover",
      "~106623368"
    ],
    "content": "This course introduces you to two of the most sought-after disciplines in Machine Learning: Deep Learning and Reinforcement Learning. Deep Learning is a subset of Machine Learning that has applications in both Supervised and Unsupervised Learning, and is frequently used to power most of the AI applications that we use on a daily basis. First you will learn about the theory behind Neural Networks, which are the basis of Deep Learning, as well as several modern architectures of Deep Learning. Once you have developed a few  Deep Learning models, the course will focus on Reinforcement Learning, a type of Machine Learning that has caught up more attention recently. Although currently Reinforcement Learning has only a few practical applications, it is a promising area of research in AI that might become relevant in the near future.After this course, if you have followed the courses of the IBM Specialization in order, you will have considerable practice and a solid understanding in the main types of Machine Learning which are: Supervised Learning, Unsupervised Learning, Deep Learning, and Reinforcement Learning.\n\nBy the end of this course you should be able to:\nExplain the kinds of problems suitable for Unsupervised Learning approaches\nExplain the curse of dimensionality, and how it makes clustering difficult with many features\nDescribe and use common clustering and dimensionality-reduction algorithms\nTry clustering points where appropriate, compare the performance of per-cluster models\nUnderstand metrics relevant for characterizing clusters\n\nWho should take this course?\nThis course targets aspiring data scientists interested in acquiring hands-on experience with Deep Learning and Reinforcement Learning.\n \nWhat skills should you have?\nTo make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Unsupervised Learning, Supervised Learning, Calculus, Linear Algebra, Probability, and Statistics."
  },
  {
    "url": "https://www.coursera.org/learn/deep-neural-network",
    "name": "Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization",
    "what_you_learn": "",
    "skills": "Applied Machine Learning, Supervised Learning, Tensorflow, Machine Learning Algorithms, Performance Tuning, Deep Learning, Artificial Intelligence and Machine Learning (AI/ML), Artificial Neural Networks, View all skills",
    "instructors": [
      "andrewng",
      "younes",
      "kian-katanforoosh"
    ],
    "content": "In the second course of the Deep Learning Specialization, you will open the deep learning black box to understand the processes that drive performance and generate good results systematically.By the end, you will learn the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence; and implement a neural network in TensorFlow.\n\nThe Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI."
  },
  {
    "url": "https://www.coursera.org/learn/deep-neural-networks-with-pytorch",
    "name": "Introduction to Neural Networks and PyTorch",
    "what_you_learn": "Job-ready PyTorch skills employers need in just 6 weeks\nJob-ready PyTorch skills employers need in just 6 weeks\nHow to implement and train linear regression models from scratch using PyTorch’s functionalities\nHow to implement and train linear regression models from scratch using PyTorch’s functionalities\nKey concepts of logistic regression and how to apply them to classification problems\nKey concepts of logistic regression and how to apply them to classification problems\nHow to handle data and train models using gradient descent for optimization\nHow to handle data and train models using gradient descent for optimization",
    "skills": "Artificial Neural Networks, PyTorch (Machine Learning Library), Machine Learning, Deep Learning, Regression Analysis, Probability & Statistics, Data Manipulation, Predictive Modeling, Tensorflow",
    "instructors": [
      "~28511493"
    ],
    "content": "PyTorch is one of the top 10 highest paid skills in tech (Indeed). As the use of PyTorch for neural networks rockets, professionals with PyTorch skills are in high demand. This course is ideal for AI engineers looking to gain job-ready skills in PyTorch that will catch the eye of an employer.AI developers use PyTorch to design, train, and optimize neural networks to enable computers to perform tasks such as image recognition, natural language processing, and predictive analytics.  During this course, you’ll learn about 2-D Tensors and derivatives in PyTorch. You’ll look at linear regression prediction and training and calculate loss using PyTorch. You’ll explore batch processing techniques for efficient model training, model parameters, calculating cost, and performing gradient descent in PyTorch. Plus, you’ll look at linear classifiers and logistic regression.   \n\nThroughout, you’ll apply your new skills in hands-on labs, and at the end, you’ll complete a project you can talk about in interviews.  If you’re an aspiring AI engineer with basic knowledge of Python and mathematical concepts, who wants to get hands-on with PyTorch, enroll today and get set to power your AI career forward!"
  },
  {
    "url": "https://www.coursera.org/learn/deep-time-discovering-an-ancient-earth",
    "name": "Deep Time: Discovering an Ancient Earth",
    "what_you_learn": "Communicate and teach the underpinnings of geology and deep time.\nCommunicate and teach the underpinnings of geology and deep time.\nEvaluate the evidence supporting the age of the earth, and review the geologic story of the Rocky Mountains.\nEvaluate the evidence supporting the age of the earth, and review the geologic story of the Rocky Mountains.\nApply geological data, models, and investigations.\nApply geological data, models, and investigations.",
    "skills": "World History, Scientific Methods, Environment, Ancient History, General Science and Research, Laboratory Testing, Physical Science, Research, Timelines, Peer Review",
    "instructors": [
      "~70470918"
    ],
    "content": "Ever since our ancestors ventured onto the African savanna, human beings have searched, explored, and wondered about the world.  Nowadays, and certainly for most, science is the vehicle that takes us along a path towards understanding nature.  It can bring us from sub-atomic realms to the most distant galaxies.  Largely through the discipline of geology, science allows us to push back the mists of time and peer into a past measured in billions of years, and aptly referred to as “Deep Time.”Climb on board! \n\nThis is a journey of discovery—we'll learn about the origins of science and geology itself, to our planet’s oceans, atmosphere, and crust.  The focus then turns to how geologists have probed the rise and fall of the Rocky Mountains, and we conclude by considering not only the power of science but also acknowledging its inherent price and responsibility.\n\nCertificate earners demonstrate proficiency through a few short assessments and discussion prompts and are prepared to teach or apply the material."
  },
  {
    "url": "https://www.coursera.org/learn/definicin-y-medicin",
    "name": "Definición y Medición",
    "what_you_learn": "",
    "skills": "Process Capability, Project Management, Value Engineering, Statistical Analysis, Lean Methodologies, Data Collection, Process Mapping, Process Improvement, Root Cause Analysis, Key Performance Indicators (KPIs), Six Sigma Methodology, Problem Management, View all skills",
    "instructors": [
      "mazarang",
      "escalante"
    ],
    "content": "En este curso conoceremos la importancia del Mapeo de Flujo de Valor la cual es una herramienta que nos sirve para ver y entender un proceso e identificar sus desperdicios, permitiendo detectar fuentes de ventaja competitiva, ya que nos permite ayudar a establecer un lenguaje común entre todos los usuarios y comunicar ideas de mejora enfocado al uso de un plan priorizando los esfuerzos de mejoramiento. Es importante mencionar que el flujo de valor es la técnica de dibujar un “mapa” o diagrama de flujo que nos permite mostrar los materiales e información desde el proveedor hasta el cliente y que busca reducir y eliminar desperdicios pudiendo ser útil en la planeación estratégica y la gestión del cambio.Existen diferentes formatos de diagrama de flujo como el SIPOC siendo de los más utilizados y una vez que se concluye su uso, nos muestra todos los proveedores, los procesos y los clientes, para proceder a seleccionar la ruta crítica a mapear para el VSM con el objetivo de mejorar el proceso o el sistema en base al plan estratégico de la empresa.\n\nPodemos resumir que, en primer lugar, debemos definir cuál es el problema que queremos resolver, tenemos que ponernos en situación, saber dónde estamos. Esto es importante, ya que será difícil continuar si fallamos en el primer paso. La definición del mismo es fundamental para establecer unos correctos KPIs que nos permitan tener un mejor conocimiento de la situación. Una vez que sabemos dónde estamos, deberemos saber a dónde vamos. El camino tiene que ser medible, y por ello, definir unas métricas a seguir y que nos ayuden a conocer la situación en la que se encuentra el problema que queremos resolver. Debemos medir estos indicadores y establecer finalmente una ruta de seguimiento que nos permita más adelante poder analizar la situación.\n\nAl terminar el segundo curso de Definición y Medición:\n\n•\tIdentificarás las áreas de oportunidad y desperdicios en el mapa del estado actual.\n•\tGenerarás la creación de pasos para el mapa del estado futuro de acuerdo con las características de pensamiento esbelto.\n•\tDefinirás los proyectos de mejora a través del mapa del estado futuro."
  },
  {
    "url": "https://www.coursera.org/learn/defining-describing-and-visualizing-data",
    "name": "Defining, Describing, and Visualizing Data",
    "what_you_learn": "Classify types of data with scales of measurement\nClassify types of data with scales of measurement\nCalculate descriptive statistics and create graphical representations using R software\nCalculate descriptive statistics and create graphical representations using R software\nSolve problems and make decisions using probability distributions\nSolve problems and make decisions using probability distributions",
    "skills": "Data Analysis, Data Import/Export, Taxonomy, Statistics, Probability & Statistics, Probability, Descriptive Statistics, Probability Distribution, R Programming, Data Visualization, Data Manipulation, R (Software), Histogram, Data-Driven Decision-Making, Statistical Software, Statistical Analysis, View all skills",
    "instructors": [
      "~8162272"
    ],
    "content": "As leaders in your chosen field, you need to not only know how to ask the right questions but also answer them using data-based methods. Through this class, you will be able to get to the bottom of what you really want to know, describe the associated data related to that question, and visualize the information from that data to understand and explain the results.This course can be taken for academic credit as part of CU Boulder’s Master of Engineering in Engineering Management (ME-EM) degree offered on the Coursera platform. The ME-EM is designed to help engineers, scientists, and technical professionals move into leadership and management roles in the engineering and technical sectors. With performance-based admissions and no application process, the ME-EM is ideal for individuals with a broad range of undergraduate education and/or professional experience. Learn more about the ME-EM program at https://www.coursera.org/degrees/me-engineering-management-boulder."
  },
  {
    "url": "https://www.coursera.org/learn/delega-tareas-sin-sentir-que-pierdes-el-control",
    "name": "Delega tareas sin sentir que pierdes el control",
    "what_you_learn": "Delegar tareas eficazmente para mejorar la productividad y empoderar al equipo de trabajo.\nDelegar tareas eficazmente para mejorar la productividad y empoderar al equipo de trabajo.",
    "skills": "Productivity, Organizational Leadership, Empowerment, Verification And Validation, Leadership, Team Building, Team Leadership, Trustworthiness, Strategic Leadership, Employee Training, Performance Analysis, Delegation Skills, Team Management, Organizational Effectiveness, Prioritization, View all skills",
    "instructors": [
      "~161798616"
    ],
    "content": "Este curso te enseñará a delegar tareas de manera efectiva, para mejorar la productividad y empoderar a tu equipo de trabajo. Dirigido a mujeres líderes organizacionales que deseen fortalecer su capacidad de liderazgo y establecer relaciones poderosas con sus equipos de trabajo, el curso ofrece un enfoque práctico y estratégico para dominar el arte de delegar tareas sin perder el control. Aquí aprenderás a identificar las tareas adecuadas para delegar, analizar las aptitudes de tu equipo, y proporcionar la información necesaria para asegurar una ejecución impecable. Además, descubrirás cómo organizar prioridades, capacitar a tus colaboradores, y verificar resultados de manera efectiva. Al implementar estas estrategias, no solo aumentarás tu eficiencia, sino que también fomentarás un ambiente de confianza y colaboración, potenciando el crecimiento y desarrollo de tu equipo."
  },
  {
    "url": "https://www.coursera.org/learn/deliver-the-news",
    "name": "Effectively delivering the news to your audience",
    "what_you_learn": "",
    "skills": "Research, Media and Communications, Photo/Video Production and Technology, Report Writing, Driving engagement, Journalism, Multimedia, Ethical Standards And Conduct, Storytelling, Oral Expression, Video Production, Writing, Interviewing Skills, Content Creation, View all skills",
    "instructors": [
      "~15384580",
      "jwswrites",
      "joegrimm",
      "~16003827",
      "joannecgerstner",
      "davidpoulson"
    ],
    "content": "Being a successful journalist is more than hunting down information. How journalists process the information, then put it together, are key steps for news reports. You will learn the process, planning, requirements of how journalists develop their news reports. There are many ways to report news reports, and you will learn different forms of how to perform reporting and writing to serve different audiences. This course also explains the different formats within journalism, beyond the written word and how they are best utilized."
  },
  {
    "url": "https://www.coursera.org/learn/delivering-quality-work-with-agility",
    "name": "Delivering Quality Work with Agility",
    "what_you_learn": "Deliver high quality work that solves a problem and reduces effort for the person or group requesting it\nDeliver high quality work that solves a problem and reduces effort for the person or group requesting it\nApply the quality work process to all requests through clear communication and focus on clients\nApply the quality work process to all requests through clear communication and focus on clients\nTake ownership of your assignments and apply the five-step method that will help you deliver quality work\nTake ownership of your assignments and apply the five-step method that will help you deliver quality work\nWork with agility while applying the quality work process to become a trusted advisor to your clients and colleagues\nWork with agility while applying the quality work process to become a trusted advisor to your clients and colleagues",
    "skills": "Workflow Management, Client Services, Reliability, Quality Management, Ability To Meet Deadlines, Adaptability, Business Research, Communication, Accountability, Time Management, Communication Planning, Professional Development, Professionalism, Detail Oriented, Problem Solving, Continuous Improvement Process, Agile Methodology, View all skills",
    "instructors": [
      "ibm-skills-network"
    ],
    "content": "When you hand in work in a professional workspace, employers expect it to be good quality work and done in a timely manner. By taking this short course you will learn about consistency and how to deliver quality work and experiences to clients.In order to deliver good quality work you need to know how to do efficiently do research and how to deliver it. This short course will teach you exactly that, and even more skills that are essential to being able to deliver quality work. The course is designed to teach you how to do this using a five-step process.  \n\nThe skills that this course teaches are fundamental skills that you will need in order to be successful in your professional life. The content you learn in this course will be applicable to your everyday work-life and will be a stepping stone in your path to success.\n\nThis course is part of the People and Soft Skills for Professional and Personal Success Specialization from IBM."
  },
  {
    "url": "https://www.coursera.org/learn/delivery-problem",
    "name": "Delivery Problem",
    "what_you_learn": "",
    "skills": "Mathematical Modeling, Theoretical Computer Science, Data-oriented programming, Graph Theory, Operations Research, Computational Thinking, Python Programming, Algorithms, Combinatorics",
    "instructors": [
      "podolskii",
      "kulikov"
    ],
    "content": "In this online course we’ll implement (in Python) together efficient programs for a problem needed by delivery companies all over the world millions times per day — the travelling salesman problem. The goal in this problem is to visit all the given places as quickly as possible. How to find an optimal solution to this problem quickly? We still don’t have provably efficient algorithms for this difficult computational problem and this is the essence of the P versus NP problem, the most important open question in Computer Science. Still, we’ll implement several solutions for real world instances of the travelling salesman problem.While designing these solutions, we will rely heavily on the material learned in the courses of the specialization: proof techniques, combinatorics, probability, graph theory. We’ll see several examples of using discrete mathematics ideas to get more and more efficient solutions."
  },
  {
    "url": "https://www.coursera.org/learn/dell-hardware-tech-support",
    "name": "Dell Technologies Technical Support for Hardware",
    "what_you_learn": "",
    "skills": "Servers, Network Infrastructure, Data Storage Technologies, IT Infrastructure, Hardware Troubleshooting, Desktop Support, Data Storage, Digital Transformation, Technical Support, Networking Hardware, System Support, Network Security, Computer Hardware, View all skills",
    "instructors": [
      "~133352909"
    ],
    "content": "This course is designed to provide aspiring IT professionals with a comprehensive understanding of hardware device components and the skills needed to troubleshoot common hardware issues in both client and enterprise environments.This course will equip learners with the knowledge to confidently approach hardware-related challenges, ensuring they can maintain and repair devices effectively to minimize downtime. Through detailed lessons, hands-on exercises, and real-world scenarios, participants will gain a solid grasp of the inner workings of hardware components and learn systematic troubleshooting techniques to address issues that arise.\n\nThis course is designed for learners seeking to gain a foundational understanding of hardware troubleshooting. No previous experience is necessary. By the end of this course, participants will have a well-rounded understanding of both client and enterprise hardware, enabling them to diagnose issues accurately and perform necessary repairs or upgrades to maintain system integrity and performance.\n\n This course is a part of the Dell Technologies Technical Customer Support Specialist professional certificate curriculum."
  },
  {
    "url": "https://www.coursera.org/learn/dell-tech-support-career-intro",
    "name": "Dell Technologies Technical Support Career Introduction",
    "what_you_learn": "",
    "skills": "Willingness To Learn, Help Desk Support, End User Training and Support, Lifelong Learning, Teamwork, Problem Solving, Relationship Building, Communication, Professional Development, Open Mindset, Growth Mindedness, Active Listening, Desktop Support, Product Support, Interpersonal Communications, Time Management, System Support, Technical Support, View all skills",
    "instructors": [
      "~133352909"
    ],
    "content": "This course is designed to equip aspiring tech support professionals with the knowledge, skills, and strategies needed to thrive in the fast-paced world of technical support. This course is perfect for individuals looking to start a career in tech support or seasoned professionals aiming to refine their skills and advance their careers. No previous background experience or training is necessary to be successful.Through a series of comprehensive modules, participants will learn about the crucial roles and responsibilities of tech support professionals, the key factors that contribute to success in the field, effective strategies for acing job interviews, and methods for staying current with industry trends. By the end of the course, learners will have a clear understanding of what it takes to excel in tech support and how to position themselves as top candidates in this competitive industry."
  },
  {
    "url": "https://www.coursera.org/learn/dell-technical-support-for-networking-and-security",
    "name": "Dell Technologies Networking & Security Technical Support",
    "what_you_learn": "",
    "skills": "Computer Networking, Network Administration, Networking Hardware, Network Architecture, Network Protocols, General Networking, Computer Security Incident Management, Technical Support, Cyber Security Policies, Threat Detection, Cyber Attacks, Network Troubleshooting, Incident Response, Network Security, Cybersecurity, View all skills",
    "instructors": [
      "~133352909"
    ],
    "content": "This course is designed for aspiring IT professionals, network administrators, and cybersecurity enthusiasts. The course aims to equip learners with the skills necessary to effectively troubleshoot network connectivity issues and to understand the critical nature of cybersecurity in today's digital landscape.Over the course of various modules, participants will delve into the complexities of network configurations, and common connectivity challenges. They will also explore the significance of cybersecurity, learn to identify common security threats, and understand the best practices for safeguarding information. Through a blend of theoretical knowledge and practical application, this course will prepare learners to tackle real-world networking and security scenarios confidently.\n\nThis course is designed for learners seeking to gain a foundational understanding of networking and cybersecurity. No previous experience is necessary. With a strong emphasis on practical skills and real-world application, participants will be well-prepared to address the challenges of network connectivity and security. \n\nThis course is a part of the Dell Technologies Technical Customer Support Specialist professional certificate curriculum."
  },
  {
    "url": "https://www.coursera.org/learn/demanda-de-transporte",
    "name": "Introducción a los modelos de demanda de transporte",
    "what_you_learn": "",
    "skills": "Probability Distribution, Surveys, Transportation Operations, Statistical Methods, Mathematical Modeling, Regression Analysis, Predictive Modeling, Spatial Analysis, Quantitative Research, Data Collection, Supply And Demand, View all skills",
    "instructors": [
      "~11965499",
      "~18225839",
      "~15207263"
    ],
    "content": "¿Cuántos viajan? ¿Por dónde? ¿En qué modo?En general, los proyectos de transporte (tanto de infraestructura como gestión) poseen plazos y costos de realización sumamente elevados. Por estos motivos, la evaluación de este tipo de proyectos requiere de una adecuada estimación de la demanda para su correcto dimensionamiento.\n\nEn este curso aprenderás:\n\n- Las técnicas básicas (estadísticas y de trabajo en terreno) necesarias para recolectar información adecuada, corregirla y expandirla, para su utilización en modelar la demanda por transporte.\n\n- Los principios básicos y las técnicas clásicas utilizadas en la práctica para modelar la demanda de transporte a través del “modelo clásico” de cinco etapas: generación de viajes, distribución de viajes, elección de horario, elección de modo de transporte, y elección de ruta de viaje.\n\n- Las herramientas básicas disponibles para calibrar los principales modelos agregados de demanda por transporte y aplicarlos para efectuar predicciones.\n\n- Las herramientas estadísticas y computacionales básicas para estimar dos modelos paradigmáticos de elección discreta (Logit Multinomial y Logit Jerárquico) utilizando información a nivel desagregado, y aplicarlos para efectuar predicciones."
  },
  {
    "url": "https://www.coursera.org/learn/dementia-care",
    "name": "Living with Dementia: Impact on Individuals, Caregivers, Communities and Societies",
    "what_you_learn": "",
    "skills": "Caregiving, Health Policy, Home Health Care and Assisted Living, Mental and Behavioral Health, Gerontology, Long Term Care, Patient-centered Care, Geriatrics, Community Development, Stress Management, Care Management, Social Determinants Of Health, View all skills",
    "instructors": [
      "lauragitlin",
      "nancyhodgson"
    ],
    "content": "Health professionals and students, family caregivers, friends of and affected individuals, and others interested in learning about dementia and quality care will benefit from completing the course. Led by Drs. Nancy Hodgson and Laura Gitlin, participants will acquire foundational knowledge in the care of persons with Alzheimer’s Disease and other neurocognitive disorders."
  },
  {
    "url": "https://www.coursera.org/learn/dementia-healthcare",
    "name": "Knowledge and Skills for Dementia Care: the SSLD Approach",
    "what_you_learn": "",
    "skills": "Long Term Care, Nursing Homes, Geriatrics, Informed Consent, Psychosocial Assessments, Home Health Care, Needs Assessment, Substance Abuse, Behavior Management, Caregiving, Cultural Sensitivity, Psychiatric And Mental Health Nursing, Dignity in Care, Care Management, Gerontology, Mental and Behavioral Health, Patient-centered Care, View all skills",
    "instructors": [
      "tsangkatat"
    ],
    "content": "This course is designed and produced by Professor Ka Tat Tsang of the Factor-Inwentash Faculty of Social Work in collaboration with the Institute for Life Course and Aging at the University of Toronto.This course aims to inform learners about dementia and dementia care from an SSLD perspective, including, community care, in-home support, and long-term care. This course will cover the continuum of senior services and support across different settings, including, private caregiving, community services, and institutionalized residential care. Course components are designed to equip learners with practical knowledge regarding dementia and dementia care. This course also features top-notch researchers and practitioners who will be sharing their expertise and experience on recent research developments about dementia and other related topics, including, advance care planning, elder abuse, management of behavioural and psychological symptoms associated with dementia, sexuality and intimacy, consent and capacity, legal issues, principles of designed space and aging-in-place, substance use and addiction in older adults with dementia, senior care models, etc. \n\nUpon the completion of this course, learners will possess a holistic understanding of the needs and characteristics of older adults living with dementia, and will also be equipped with the knowledge and skills needed to enhance their competency in providing care."
  },
  {
    "url": "https://www.coursera.org/learn/democracia",
    "name": "Democracia y decisiones públicas. Introducción al análisis de políticas públicas",
    "what_you_learn": "",
    "skills": "Social Studies, Research Methodologies, Policy Analysis, Political Sciences, Governance, Public Administration, Program Evaluation, Case Studies, Public Policies",
    "instructors": [
      "quim-brugue",
      "joan-subirats-h",
      "marc-pares",
      "ismael-blanco",
      "raquel-gallego",
      "margarita-leon",
      "jaume-blasco"
    ],
    "content": "¿Qué son las políticas públicas? Son la plasmación más concreta de la política. Lo que los gobiernos hacen, y dejan de hacer, para hacer frente a los problemas colectivos. Este curso trata sobre cómo se decide qué problemas abordar y qué soluciones adoptar. Un proceso primordialmente político y social que suele escapar al análisis puramente racional.A lo largo del curso analizaremos por qué algunos problemas adquieren la categoría de problemas públicos mientras que otros no llegan a captar la atención, describiremos la pugna política que suele haber tras la descripción e interpretación de los problemas, identificaremos el complejo entramado de actores dispuestos a influir en la adopción de las políticas públicas, y cómo las discrepancias se suelen extender más allá de la toma de decisiones y hasta la aplicación práctica de la política pública. Trataremos también sobre las grandes dificultades que padecen gobiernos y actores sociales para llegar a saber si las políticas que se llevan a cabo son realmente útiles y cómo aprender a mejorar su rendimiento.\n\n Los objetivos de este curso son:\n1.\tMostrar a los alumnos un número de casos reales que ilustran la complejidad de los procesos de adopción de las políticas públicas, y cómo estos procesos pueden ser incoherentes con los modelos racionales de toma de decisiones.\n2.\tTransmitir a los alumnos los fundamentos e instrumental del análisis de políticas públicas para que puedan afrontar creativamente problemas del mundo real.\n3.\tContribuir a que los alumnos sean ciudadanos conocedores del funcionamiento de los sistemas democráticos.\n\n\nPor ello, el curso se dirige a todas las personas interesadas en los problemas colectivos, así como a aquellas que quieran convertirse en participantes influyentes en el proceso de formación de las políticas, ya sea como analistas, funcionarios públicos, trabajadores del tercer sector, o como ciudadanos comprometidos en causas políticas. También se dirige a estudiantes que se dispongan a iniciar estudios de grado o postgrado en administración pública, gestión pública o análisis de políticas públicas."
  },
  {
    "url": "https://www.coursera.org/learn/demystifying-ev-batteries-tech--management",
    "name": "Demystifying EV Batteries: Tech & Management",
    "what_you_learn": "Recognize the foundational concepts and science behind an electric vehicle battery pack, including its layout and key components.\nRecognize the foundational concepts and science behind an electric vehicle battery pack, including its layout and key components.\nAnalyze the different battery chemistries and battery sizes according to each electric vehicle application.\nAnalyze the different battery chemistries and battery sizes according to each electric vehicle application.\nIllustrate how an intelligent BMS functions to ensure battery pack safety and optimal EV performance.\nIllustrate how an intelligent BMS functions to ensure battery pack safety and optimal EV performance.\nAssess battery pack degradation and remember best practices for maximizing electric vehicle battery lifetime.\nAssess battery pack degradation and remember best practices for maximizing electric vehicle battery lifetime.",
    "skills": "Sustainable Technologies, Electrical Systems, Performance Tuning, Chemistry, Continuous Monitoring, System Monitoring, Thermal Management, Capacity Management, Performance Analysis, Electrical Power",
    "instructors": [
      "~141793623",
      "~139312198"
    ],
    "content": "In a world transitioning to sustainable transportation, understanding Electric Vehicle (EV) battery technology is paramount. This course is your gateway to uncovering the technology behind electric vehicle batteries, making you an informed and empowered part of the electric mobility revolution.This is a foundational course that will cover a range of concepts and applications related to Electric Vehicle (EV) Batteries, such as chemistry, capacity, energy, power, and cycle life.  We will review Battery Management systems, including metrics and intelligent management techniques.  The learners will also acquire knowledge related to performance optimization, charging and discharging methods, infrastructure, and factors affecting battery health. \n\nUpon completing this course, you will be able to get a strong foundation on the fundamentals of battery technology used in electric vehicles. This will enable you to review battery technology projects and their application in the real world. You will gain know-how in optimal battery charging and discharging practices for efficiency and longevity. These skills will empower learners to make informed decisions, maximize the performance and lifespan of electric vehicle batteries, and contribute to the sustainable use of electric vehicles. \n\nThis program is designed for anyone who is interested in battery technology used for electric vehicle applications. This includes engineers working in product development to faculty and students from academia.   \n\nLearners should ideally be aware of the basic structure and architecture of an electric vehicle. It is also recommended for the learner to be aware of basic physics and chemistry to understand the technical terms covered in the course."
  },
  {
    "url": "https://www.coursera.org/learn/denommer-le-monde",
    "name": "Dénommer le monde : la politique des toponymes",
    "what_you_learn": "La création toponymique en situations complexes :  multilingue, commémorative coloniale et postcoloniale, frontalières et bien d'autres.\nLa création toponymique en situations complexes :  multilingue, commémorative coloniale et postcoloniale, frontalières et bien d'autres.\nLes pratiques d'attribution d'adresses et les principaux défis contemporains dans les zones rurales du Nord et les zones urbaines du Sud.\nLes pratiques d'attribution d'adresses et les principaux défis contemporains dans les zones rurales du Nord et les zones urbaines du Sud.",
    "skills": "Social Sciences, Geographic Information Systems, Political Sciences, Policy Analysis, World History, Social Justice, Data Mapping, Case Studies, Social Studies, Cultural Diversity, Economics, Policy, and Social Studies, International Relations, Sustainable Development, Cultural Sensitivity, Storytelling, View all skills",
    "instructors": [
      "frederic-giraut"
    ],
    "content": "Intéressé-e par la grande bataille des noms de lieux ?Explorez la dénomination des lieux à travers divers contextes et échelles, en analysant les motivations politiques et les impacts sociaux. Dans ce cours interdisciplinaire, vous aborderez des thèmes identitaires, environnementaux, de justice culturelle et sociale, d’urbanisme ainsi que de genre et de patri-matrimoine, en croisant des disciplines telles que la linguistique, la géographie, l'histoire et plus encore.\n\nÀ travers des entretiens avec des experts en toponymie, des lectures approfondies et des exercices pratiques, vous développerez une compréhension des enjeux liés à la dénomination et à la renomination des lieux. À la fin du cours, vous serez apte à analyser des situations de dénomination, à intégrer des éléments tels que le genre et les savoirs autochtones dans la toponymie, et à participer à la cartographie collaborative de nouveaux objets géographiques et de leurs noms.\n\nSi la passion pour les noms de lieux vous anime, que ce soit sur le plan professionnel ou intellectuel, ce MOOC proposé par la Chaire Unesco en toponymie inclusive de l'Université de Genève est une opportunité à ne pas manquer.\n\n--\nCe cours mobilise les expert.es suivant.es et bénéficie de leurs contributions : Ekaterina Mikhailova ; Maria Isabel Alvarez Fernandez ; Michel Ben Arrous ; Sebastien Boillat ; Irène Hirt ; Melissa Wanjiru ; Virginie Duquette ; Jani Vuolteenaho ; Alexandra Mallah ; Pauline Mettan ; Laurent Matthey ; Hy Dao."
  },
  {
    "url": "https://www.coursera.org/learn/dense-gases-liquids-solids",
    "name": "Dense Gases, Liquids and Solids",
    "what_you_learn": "Analyze the impact of intermolecular forces on the transition of gases to liquids as density increases\nAnalyze the impact of intermolecular forces on the transition of gases to liquids as density increases\nEvaluate the stability of a thermodynamic system as it transitions from gas to liquid state in response to small perturbations\nEvaluate the stability of a thermodynamic system as it transitions from gas to liquid state in response to small perturbations\nAssess the role of the radial distribution function (RDF) in determining thermodynamic properties of liquids\nAssess the role of the radial distribution function (RDF) in determining thermodynamic properties of liquids\nDescribe the behavior of crystalline solids using simple statistical thermodynamics\nDescribe the behavior of crystalline solids using simple statistical thermodynamics",
    "skills": "Mathematical Modeling, Calculus, Simulations, Thermal Management, Engineering Calculations, Engineering Analysis, Chemical Engineering, Physics, Mechanical Engineering, Estimation, Materials science",
    "instructors": [
      "john-w-daily"
    ],
    "content": "Course 4 of Statistical Thermodynamics addresses dense gases, liquids, and solids. As the density of a gas is increased, intermolecular forces begin to affect behavior. For small departures from ideal gas behavior, known as the dense gas limit, one can estimate the change in properties using the concept of a configuration integral, a modification to the partition function. This leads to the development of equations of state that are expansions in density from the ideal gas limit. Inter molecular potential energy functions are introduced and it is explored how they impact P-V-T behavior. As the density is increased, there is a transition to the liquid state. We explore whether this transition is smooth or abrupt by examining the stability of a thermodynamic system to small perturbations. We then present a brief discussion regarding the determination of the thermodynamic properties of liquids using concept of the radial distribution function (RDF), and how the function relates to thermodynamic properties. Finally, we explore two simple models of crystalline solids."
  },
  {
    "url": "https://www.coursera.org/learn/density-functional-theory",
    "name": "Density Functional Theory",
    "what_you_learn": "Foundation (mathematical and historical) of DFT, approximation strategies.\nFoundation (mathematical and historical) of DFT, approximation strategies.\nQuality and accuracy of different approximations, practical procedure to solve the equations.\nQuality and accuracy of different approximations, practical procedure to solve the equations.\nReady to be operative and use DFT for your own research\nReady to be operative and use DFT for your own research",
    "skills": "Calculus, Applied Mathematics, Physics, Chemistry, Materials science, Numerical Analysis, Differential Equations",
    "instructors": [
      "~36494143",
      "francesco"
    ],
    "content": "The aim of this course is to give a thorough introduction to Density Functional Theory (DFT). DFT is today the most widely used method to study interacting electrons, and its applicability ranges from atoms to solid systems, from nuclei to quantum fluids.In this course, we introduce the most important concepts underlying DFT, its foundation, and basic ideas. We will in particular stress the features and reasons that lead DFT to become the dominant method for simulating quantum mechanical systems. \n\nThe course is intended for students and researchers with knowledge of basic quantum mechanics. No experience in simulation or solid-state physics is required. We try to give a concise mathematical background when particular concepts are needed."
  },
  {
    "url": "https://www.coursera.org/learn/dental-medicine-penn",
    "name": "Introduction to Dental Medicine",
    "what_you_learn": "",
    "skills": "Patient Evaluation, Dental Care, Dental Procedures, Periodontology, Pain Management, Oral Cancer Screening, Medical History Documentation, Clinical Assessment, Dental Hygiene, Anatomy, Oral Health",
    "instructors": [
      "~6317837",
      "estoopler",
      "urihy"
    ],
    "content": "The mouth is the window into human health.  This course provides an overview of dental medicine to engage, educate, excite and assist you in improving the oral health of your patients and members of your community. We will review topics in dental medicine including scope of the field, what to expect in function, and some of the many ways that dysfunction may present for different patients. This will include discussions of mouth, jaw, and tooth anatomy, pathology, and treatment. We will talk about differences between patients and the unique roles that different members of the dental field may play in treatment depending on the patient and condition. This course starts from basic concepts and proceeds to review trends in current research and technology. We offer scientific background, some skills for patient evaluation and interview, and some suggestions for further learning for those interested in or involved in dental education."
  },
  {
    "url": "https://www.coursera.org/learn/dentistry101",
    "name": "Dentistry 101",
    "what_you_learn": "Explore the role of dentists as healthcare professionals and the promotion of wellness in society.\nExplore the role of dentists as healthcare professionals and the promotion of wellness in society.\nUnderstand specialty areas of dentistry.Explore the application process to dental school.\nUnderstand specialty areas of dentistry.Explore the application process to dental school.",
    "skills": "Medical Science and Research, Research, Oral and Dental Care, Public Health, Dental Care, Higher Education, Oral Health, Dentistry",
    "instructors": [
      "rtaichman",
      "rcastilho"
    ],
    "content": "Dentistry 101 is an introduction to the exciting and diverse field of dentistry through the lens of its many practitioners. If you’re interested in exploring dentistry as a profession, or if you’re ready to pursue a career in it and want to prepare yourself for dental school and the profession that lies ahead, Dentistry 101 will help you better envision the paths you can take.If you complete Dentistry 101, you'll have a well-rounded introductory understanding of the field of dentistry, and you'll get glimpses of the profession that aren't always easily available. You'll also be better informed about, and more prepared for, the dental school admissions process if you choose to pursue it."
  },
  {
    "url": "https://www.coursera.org/learn/deploy-and-maintain-power-bi-assets-and-capstone-project",
    "name": "Deploy and Maintain Power BI Assets and Capstone project",
    "what_you_learn": "How to create and publish an app in Power BI.\nHow to create and publish an app in Power BI.\nHow to implement dynamic reports in Power BI.\nHow to implement dynamic reports in Power BI.\nHow to implement security measures and alerting in a Power BI report or dashboard.\nHow to implement security measures and alerting in a Power BI report or dashboard.",
    "skills": "Role-Based Access Control (RBAC), Power BI, Microsoft SQL Servers, Dashboard, Data Visualization Software, Data Modeling, Data Security, Data Analysis Expressions (DAX), Data Analysis, Data Management, SQL, View all skills",
    "instructors": [
      "microsoft"
    ],
    "content": "This course forms part of the Microsoft Power BI Analyst Professional Certificate. This Professional Certificate consists of a series of courses that offers a good starting point for a career in data analysis using Microsoft Power BI.In this course, you’ll  learn how to deploy and maintain assets in Power BI. Through hands-on exercises, you’ll explore the process of creating, implementing, and managing Power BI workspaces.You’ll also implement security and monitoring to protect data in organizations. At the end of the course, you will complete a capstone project to  showcase all your new Power BI and data analytical skills. \n\nAfter completing this course, you'll be able to:  \n\n●\tDescribe how SQL is used in enterprise data analysis. \n●\tCreate and publish an app in Power BI.\n●\tAudit usage in Reports and Dashboard.\n●\tManage and refresh datasets. \n●\tImplement dynamic reports in Power BI. \n●\tImplement security measures and alerting in a Power BI report or dashboard.\n●\tEstablish Row Level Security in a Power BI model.\n\nThis is also a great way to prepare for the Microsoft PL-300 exam. By passing the PL-300 exam, you’ll earn the Microsoft Power BI Data Analyst certification."
  },
  {
    "url": "https://www.coursera.org/learn/deploy-and-monitor-in-google-cloud-for-aws-professionals",
    "name": "Deploy and Monitor in Google Cloud for AWS Professionals",
    "what_you_learn": "Describe use cases for Cloud Source Repositories and Cloud Functions.\nDescribe use cases for Cloud Source Repositories and Cloud Functions.\nCreate charts, alerts, and uptime checks for resources with Cloud Monitoring.\nCreate charts, alerts, and uptime checks for resources with Cloud Monitoring.\nCompare Cloud Monitoring with Amazon CloudWatch.\nCompare Cloud Monitoring with Amazon CloudWatch.\nDescribe how Cloud Run differs from AWS Fargate\nDescribe how Cloud Run differs from AWS Fargate",
    "skills": "System Monitoring, Application Performance Management, Cloud Applications, Cloud Services, Scalability, Google Cloud Platform, Amazon CloudWatch, Containerization, Amazon Web Services, Application Deployment, Kubernetes, Serverless Computing, View all skills",
    "instructors": [
      "google-cloud-training"
    ],
    "content": "This is the fourth course of a four-course series for cloud architects and engineers with existing AWS knowledge. It compares Google Cloud and AWS solutions and guides professionals on their use.This course focuses on deploying and monitoring applications in Google Cloud. The learners apply the knowledge of monitoring and application deployment processes in AWS to explore the differences with Google Cloud. Learners get hands-on practice building and managing Google Cloud resources."
  },
  {
    "url": "https://www.coursera.org/learn/deploy-containers-with-azure-kubernetes-service",
    "name": "Deploy containers by using Azure Kubernetes Service",
    "what_you_learn": "",
    "skills": "Application Deployment, Security Controls, Microsoft Azure, General Networking, YAML, CI/CD, Containerization, Docker (Software), Kubernetes",
    "instructors": [
      "microsoft"
    ],
    "content": "Upon completion of this course, yoy will be adequately prepared to take Microsoft's Deploy containers by using Azure Kubernetes Service Applied Skill assessment. This course covers all necessary content and provides essential practice to boost your confidence and ensure success in the final assessment.Azure Kubernetes Service (AKS) isn't just a tool; it’s the strategic catalyst for orchestrating containers. Imagine it as the keystone that seamlessly aligns microservices, scales with precision, and ensures high availability. This short course will provide hands-on experience creating, deploying, pushing, and deleting the most commonly used functionalities of Azure Kubernetes Services (AKS). deploying these core Azure networking services. Through hands-on learning, you'll gain the expertise needed to navigate AKS with confidence for your real-world environment.\n\nBy the end of this 2-hour long course, you will be able to:\n•        Prepare the Microsoft Azure Lab Environment \n•        Create an Azure Kubernetes Service (AKS) Cluster and Nodes\n•        Deploy Pods and Build a Docker Image \n•        Build an Azure Kubernetes Container (AKS) and Push Images to the Registry \n\nThis course is unique because the customized hands-on learning experiences are tailored to the learner for success in using Azure Kubernetes Services and introduce some useful tools to gain the possible results. \n\nTo be successful in this short course and the labs in it, you should have:\n    Expertise navigating the Azure Portal to create resources.\n    Familiarity with security concepts like identity management, permissions, and encryption.\n    Understand Networking terminologies such as Virtual Networks, IP Addressing, Firewalls and DNS.\n   A basic knowledge of Kubernetes and Azure Kubernetes Services concepts\n\nNote: To perform the labs, you will need an active Azure subscription."
  }
]